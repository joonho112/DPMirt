[{"path":"https://joonho112.github.io/DPMirt/articles/introduction.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"DPMirt: Bayesian Semiparametric Item Response Theory","text":"using Item Response Theory models educational psychological assessment, researchers almost always assume latent traits—abilities, proficiencies, attitudes measured—follow normal distribution. assumption deeply embedded standard IRT software rarely receives explicit scrutiny. Yet populations study often far normal. Consider students preparing high-stakes graduation exam: one group mastered curriculum, another group still struggling foundational concepts. consider clinical sample respondents fall typical range, meaningful minority exhibits extreme scores. settings, forcing bell curve onto latent trait distribution distorts individual ability estimates, misleads ranking decisions, produces inaccurate pictures population. DPMirt addresses problem replacing parametric normal prior Dirichlet Process Mixture (DPM) prior latent trait distribution. DPM prior Bayesian nonparametric tool lets data inform shape ability distribution—whether turns unimodal, bimodal, skewed, something else entirely—without requiring researcher choose specific parametric form advance. package wraps NIMBLE probabilistic programming engine provides complete workflow data simulation model fitting, posterior summarization, diagnostics. vignette introduces motivation, architecture, model family DPMirt, provides road map rest documentation.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/articles/introduction.html","id":"the-scenario","dir":"Articles","previous_headings":"Motivating Example: Why Normality Matters","what":"The scenario","title":"DPMirt: Bayesian Semiparametric Item Response Theory","text":"Imagine curriculum-based mathematics assessment administered heterogeneous student population. Advanced-track students additional year instruction, general-track students still building fluency. true ability distribution genuinely bimodal—two overlapping groups distinct centers. examine scenario using pre-computed simulation results shipped package. data generated Rasch model 25 items 200 persons drawn bimodal ability distribution (mixture two normal components centered θ=−1.5\\theta = -1.5 θ=1.5\\theta = 1.5). Two models fit responses: one standard normal prior one DPM prior.","code":"sim <- readRDS(find_extdata(\"vignette_sim_bimodal.rds\")) fit_normal <- readRDS(find_extdata(\"vignette_fit_rasch_normal_bimodal.rds\")) fit_dpm <- readRDS(find_extdata(\"vignette_fit_rasch_dpm_bimodal.rds\"))"},{"path":"https://joonho112.github.io/DPMirt/articles/introduction.html","id":"the-comparison","dir":"Articles","previous_headings":"Motivating Example: Why Normality Matters","what":"The comparison","title":"DPMirt: Bayesian Semiparametric Item Response Theory","text":"figure overlays three densities: true generating distribution (gray), posterior mean estimates normal-prior model (blue), posterior mean estimates DPM-prior model (orange). Recovered ability distributions normal DPM priors bimodal population. normal prior shrinks estimates toward center, masking true bimodality. DPM prior recovers two-group structure.","code":"if (requireNamespace(\"ggplot2\", quietly = TRUE)) {   library(ggplot2)    true_theta <- sim$theta   pm_normal  <- colMeans(fit_normal$theta_samp)   pm_dpm     <- colMeans(fit_dpm$theta_samp)    plot_df <- data.frame(     value  = c(true_theta, pm_normal, pm_dpm),     source = factor(rep(c(\"True\", \"Normal Prior (PM)\", \"DPM Prior (PM)\"),                         each = length(true_theta)),                     levels = c(\"True\", \"Normal Prior (PM)\", \"DPM Prior (PM)\"))   )    fill_vals  <- c(\"True\" = unname(palette_dpmirt[\"true\"]),                    \"Normal Prior (PM)\" = unname(palette_dpmirt[\"normal\"]),                    \"DPM Prior (PM)\" = unname(palette_dpmirt[\"dpm\"]))    ggplot(plot_df, aes(x = value, fill = source, color = source)) +     geom_density(alpha = 0.35, linewidth = 0.8) +     scale_fill_manual(values = fill_vals) +     scale_color_manual(values = fill_vals) +     labs(x = expression(theta), y = \"Density\",          title = \"Normal vs. DPM Prior: Recovering a Bimodal Population\",          subtitle = \"Rasch model, 25 items, 200 persons\") +     theme_minimal() +     theme(legend.position = \"bottom\", legend.title = element_blank(),           plot.title = element_text(face = \"bold\")) } #> Warning: package 'ggplot2' was built under R version 4.5.2"},{"path":"https://joonho112.github.io/DPMirt/articles/introduction.html","id":"what-went-wrong-with-the-normal-prior","dir":"Articles","previous_headings":"Motivating Example: Why Normality Matters","what":"What went wrong with the normal prior?","title":"DPMirt: Bayesian Semiparametric Item Response Theory","text":"normal-prior model mechanism represent bimodality. posterior mean estimates pulled toward single central peak—phenomenon called underdispersion overshrinkage. two modes true distribution collapse one, tails artificially thin. Key insight. true ability distribution departs normality, normal-prior IRT model simply produce noisier estimates—produces systematically biased estimates. High-ability students pulled downward; low-ability students pulled upward; entire empirical distribution function distorted. practical consequences. school district uses cutoff identify students enrichment program, normal-prior estimates undercount eligible students high-ability group. DPM prior, adapting data-generating shape, substantially reduces bias.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/introduction.html","id":"what-dpmirt-does","dir":"Articles","previous_headings":"","what":"What DPMirt Does","title":"DPMirt: Bayesian Semiparametric Item Response Theory","text":"DPMirt provides complete toolkit Bayesian semiparametric IRT, organized five functional layers: DPMirt package architecture users interact primarily User Interface layer. single call dpmirt() handles entire pipeline—building NIMBLE model code, compilation, MCMC sampling, post-hoc rescaling, WAIC computation—returning fitted model object ready summarization plotting. users need control, Step--Step layer exposes stage separate function, following compile-, sample-many pattern avoids redundant C++ compilation.","code":"arch_df <- data.frame(   Layer = c(\"User Interface\", \"Step-by-Step\",             \"Diagnostics & Visualization\", \"Simulation\", \"Integration\"),   Purpose = c(\"One-step fitting\",               \"Fine-grained control over each pipeline stage\",               \"MCMC assessment and result visualization\",               \"Data generation and loss evaluation\",               \"External package interoperability\"),   `Key Functions` = c(     \"dpmirt()\",     \"dpmirt_spec(), dpmirt_compile(), dpmirt_sample(), dpmirt_rescale(), dpmirt_estimates()\",     \"dpmirt_diagnostics(), plot(), dpmirt_plot_density(), dpmirt_plot_caterpillar()\",     \"dpmirt_simulate(), dpmirt_loss()\",     \"dpmirt_alpha_prior(), dpmirt_compare()\"),   check.names = FALSE ) knitr::kable(arch_df, col.names = c(\"Layer\", \"Purpose\", \"Key Functions\"),              caption = \"DPMirt package architecture\")"},{"path":"https://joonho112.github.io/DPMirt/articles/introduction.html","id":"three-inferential-goals","dir":"Articles","previous_headings":"","what":"Three Inferential Goals","title":"DPMirt: Bayesian Semiparametric Item Response Theory","text":"One central insights motivating DPMirt single “best” point estimate latent traits. Different applied questions demand different posterior summaries, choice estimator driven inferential goal—convention. Lee & Wind formalized three distinct goals latent trait estimation: Three inferential goals latent trait estimation (Lee & Wind) Key insight. single estimator simultaneously optimizes three goals. posterior mean (PM) minimizes individual mean squared error produces underdispersed empirical distribution, distorting rankings distribution estimates. Constrained Bayes (CB) corrects distribution ranks. triple-goal (GR) estimator Shen Louis (1998) simultaneously targets accurate ranking distribution recovery. DPMirt computes three estimators stored posterior samples, enabling researchers choose summary matches applied question. benefit using DPM prior compounds right estimator choice: DPM prior provides faithful posterior, CB GR estimators can extract accurate summaries.","code":"goals_df <- data.frame(   Goal = c(\"1. Individual traits\", \"2. Ranking\", \"3. Distribution\"),   Target = c(\"$\\\\theta_p$\",              \"$R_p = \\\\text{rank}(\\\\theta_p)$\",              \"$G_N(t) = N^{-1} \\\\sum I(\\\\theta_p \\\\le t)$\"),   Loss = c(\"MSEL\", \"MSELR\", \"ISE / KS\"),   Example = c(\"What is this student's ability?\",               \"Which 5 students need intervention?\",               \"What percentage exceed the cutoff?\"),   Estimator = c(\"Posterior Mean (PM)\", \"Triple-Goal (GR)\",                 \"Constrained Bayes (CB) / Triple-Goal (GR)\") ) knitr::kable(goals_df,   col.names = c(\"Goal\", \"Target\", \"Loss Function\",                 \"Example Question\", \"Optimal Estimator\"),   caption = \"Three inferential goals for latent trait estimation (Lee & Wind)\",   escape = FALSE)"},{"path":"https://joonho112.github.io/DPMirt/articles/introduction.html","id":"model-family","dir":"Articles","previous_headings":"","what":"Model Family","title":"DPMirt: Bayesian Semiparametric Item Response Theory","text":"DPMirt supports complete family unidimensional IRT models, crossing three item models two latent trait priors: Supported model family (* = default identification strategy) Parameterizations. IRT form uses logit(πip)=λi(θp−βi)\\text{logit}(\\pi_{ip}) = \\lambda_i (\\theta_p - \\beta_i); slope-intercept (SI) form uses logit(πip)=γi+λiθp\\text{logit}(\\pi_{ip}) = \\gamma_i + \\lambda_i \\theta_p. available 2PL 3PL; Rasch model uses IRT form . Identification. IRT models require constraints resolve location (, 2PL/3PL, scale) indeterminacy. DPMirt supports constraining item parameters, constraining abilities, leaving model unconstrained post-hoc rescaling. unconstrained + rescaling approach default 2PL/3PL, following Paganin et al. (2023). DPM prior. Uses Chinese Restaurant Process (CRP) representation cluster atoms Normal-Inverse-Gamma base measure. concentration parameter α\\alpha receives Gamma hyperprior—either default Gamma(1,3)\\text{Gamma}(1, 3) principled choice via DPprior.","code":"model_df <- data.frame(   Model = c(\"Rasch\", \"Rasch\", \"2PL\", \"2PL\", \"3PL\", \"3PL\"),   Prior = c(\"Normal\", \"DPM\", \"Normal\", \"DPM\", \"Normal\", \"DPM\"),   Parameters = c(     \"$\\\\beta_i$\", \"$\\\\beta_i$\",     \"$\\\\beta_i, \\\\lambda_i$\", \"$\\\\beta_i, \\\\lambda_i$\",     \"$\\\\beta_i, \\\\lambda_i, \\\\delta_i$\",     \"$\\\\beta_i, \\\\lambda_i, \\\\delta_i$\"),   Parameterizations = c(\"IRT\", \"IRT\", \"IRT, SI\", \"IRT, SI\",                          \"IRT, SI\", \"IRT, SI\"),   Identification = c(     \"Constrained item*, ability, unconstrained\",     \"Constrained item*, unconstrained\",     \"Unconstrained*, ability, constrained item\",     \"Unconstrained*\",     \"Unconstrained*, ability\",     \"Unconstrained*\") ) knitr::kable(model_df,   col.names = c(\"Model\", \"Prior\", \"Item Parameters\",                 \"Parameterizations\", \"Identification\"),   caption = \"Supported model family (* = default identification strategy)\",   escape = FALSE)"},{"path":"https://joonho112.github.io/DPMirt/articles/introduction.html","id":"backbone-references","dir":"Articles","previous_headings":"","what":"Backbone References","title":"DPMirt: Bayesian Semiparametric Item Response Theory","text":"DPMirt builds three lines methodological work, credited . Paganin et al. (2023) established computational framework: NIMBLE model code, custom MCMC samplers, post-hoc rescaling functions, DP measure sampling routines. unconstrained + rescaling identification strategy centered sampler SI parameterization form backbone DPMirt’s NIMBLE engine. package wraps validated codebase user-friendly API programmatic model code generation. Lee & Wind formalized three inferential goals—individual trait estimation, ranking, distribution recovery—evaluated PM, CB, GR estimators across full Rasch/2PL/3PL model family parametric semiparametric priors. key finding test reliability dominant moderator: high reliability, combination DPM prior GR estimator yields substantial gains ranking distribution recovery. Lee (2026) developed DPprior package principled specification Gamma hyperprior α\\alpha. Rather arbitrary default, researchers express beliefs expected latent subgroups uncertainty, DPprior translates calibrated Gamma(aa, bb) hyperparameters. especially important sample size moderate item quality limited, prior α\\alpha can substantially influence posterior inference.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/introduction.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"DPMirt: Bayesian Semiparametric Item Response Theory","text":"DPMirt requires NIMBLE MCMC backend. NIMBLE turn requires working C++ compiler (Rtools Windows, Xcode Command Line Tools macOS, build-essential Linux). recommend also installing optional packages: installation, load package:","code":"# From GitHub (development version) # install.packages(\"remotes\") remotes::install_github(\"joonho112/DPMirt\")  # Verify that NIMBLE is working library(nimble) nimbleOptions(verbose = FALSE) # Visualization (highly recommended) install.packages(\"ggplot2\")  # Principled alpha elicitation remotes::install_github(\"joonho112/DPprior\")  # Reliability-targeted simulation remotes::install_github(\"joonho112/IRTsimrel\") library(DPMirt)"},{"path":"https://joonho112.github.io/DPMirt/articles/introduction.html","id":"road-map-to-the-vignettes","dir":"Articles","previous_headings":"","what":"Road Map to the Vignettes","title":"DPMirt: Bayesian Semiparametric Item Response Theory","text":"DPMirt documentation organized two tracks. Applied researchers follow progressive path quick first fit complete model workflow. Methodological researchers can dive mathematical computational details.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/introduction.html","id":"applied-researchers-track","dir":"Articles","previous_headings":"Road Map to the Vignettes","what":"Applied Researchers Track","title":"DPMirt: Bayesian Semiparametric Item Response Theory","text":"Applied researchers track Recommended path new users: Quick Start →\\rightarrow Models Workflow →\\rightarrow Posterior Summaries. Prior Elicitation Simulation Study vignettes can read order .","code":"applied_df <- data.frame(   Vignette = c(\"[Quick Start](quick-start.html)\",                \"[Models and Workflow](models-and-workflow.html)\",                \"[Posterior Summaries](posterior-summaries.html)\",                \"[Prior Elicitation](prior-elicitation.html)\",                \"[Simulation Study](simulation-study.html)\"),   Purpose = c(\"Your first IRT fit in 5 minutes\",               \"Complete guide to all models and the step-by-step pipeline\",               \"PM, CB, GR: when each estimator is optimal\",               \"Principled DPM hyperprior selection via DPprior\",               \"Replicating the evaluation framework from Lee & Wind\"),   Time = c(\"5 min\", \"30--40 min\", \"25--30 min\", \"20--25 min\", \"30--40 min\") ) knitr::kable(applied_df, col.names = c(\"Vignette\", \"Purpose\", \"Time\"),              caption = \"Applied researchers track\")"},{"path":"https://joonho112.github.io/DPMirt/articles/introduction.html","id":"methodological-researchers-track","dir":"Articles","previous_headings":"Road Map to the Vignettes","what":"Methodological Researchers Track","title":"DPMirt: Bayesian Semiparametric Item Response Theory","text":"Methodological researchers track Recommended path methodologists: Start Mathematical Foundations, consult NIMBLE Internals. Applied Track vignettes provide complementary hands-demonstrations.","code":"methods_df <- data.frame(   Vignette = c(\"[Mathematical Foundations](theory-irt-dpm.html)\",                \"[NIMBLE Internals](nimble-internals.html)\"),   Purpose = c(     \"IRT model theory, DPM priors, identification, and posterior summary derivations\",     \"Custom samplers, compile-once pattern, and advanced NIMBLE configuration\"),   Time = c(\"45--60 min\", \"30--40 min\") ) knitr::kable(methods_df, col.names = c(\"Vignette\", \"Purpose\", \"Time\"),              caption = \"Methodological researchers track\")"},{"path":"https://joonho112.github.io/DPMirt/articles/introduction.html","id":"reading-paths-by-question","dir":"Articles","previous_headings":"Road Map to the Vignettes","what":"Reading paths by question","title":"DPMirt: Bayesian Semiparametric Item Response Theory","text":"“just want fit model quickly.” →\\rightarrowQuick Start “use normal DPM prior?” →\\rightarrowModels Workflow, Section 2 “estimator report—PM, CB, GR?” →\\rightarrowPosterior Summaries “choose concentration parameter alpha?” →\\rightarrowPrior Elicitation “want run simulation study comparing priors.” →\\rightarrowSimulation Study “DPM-IRT model work mathematically?” →\\rightarrowMathematical Foundations “need customize NIMBLE sampler configuration.” →\\rightarrowNIMBLE Internals","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/introduction.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"DPMirt: Bayesian Semiparametric Item Response Theory","text":"Ghosh, M. (1992). Constrained Bayes estimation applications. Journal American Statistical Association, 87(418), 533–540. Lee, J. & Wind, S. Targeting toward inferential goals Bayesian Rasch models estimating person-specific latent traits. OSF Preprint. https://doi.org/10.31219/osf.io/qrw4n Lee, J. (2026). Design-conditional prior elicitation Dirichlet Process mixtures: unified framework cluster counts weight control. arXiv preprint arXiv:2602.06301. https://arxiv.org/abs/2602.06301 Paganin, S., Paciorek, C. J., Wehrhahn, C., Rodríguez, ., Rabe-Hesketh, S., & de Valpine, P. (2023). Computational strategies estimation performance Bayesian semiparametric item response theory models. Journal Educational Behavioral Statistics, 48(2), 147–188. https://doi.org/10.3102/10769986221136105 Shen, W., & Louis, T. . (1998). Triple-goal estimates two-stage hierarchical models. Journal Royal Statistical Society: Series B, 60(2), 455–471. questions, bug reports, feature requests, please visit GitHub repository.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/models-and-workflow.html","id":"overview","dir":"Articles","previous_headings":"","what":"1. Overview","title":"The Complete Guide to Models and Workflows","text":"DPMirt provides two ways fit Bayesian IRT models. One-step workflow. Call dpmirt() get fully processed dpmirt_fit object one function call. Best standard analyses defaults appropriate. Step--step workflow. Walk pipeline explicitly: dpmirt_spec() →\\rightarrowdpmirt_compile() →\\rightarrowdpmirt_sample() →\\rightarrowdpmirt_rescale() →\\rightarrowdpmirt_estimates(). Best need inspect intermediate objects, run multiple chains single compiled model (compile-, sample-many), modify MCMC configuration sampling. workflows produce statistical results.","code":""},{"path":[]},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/articles/models-and-workflow.html","id":"examples","dir":"Articles","previous_headings":"2. The One-Step Workflow","what":"2.2 Examples","title":"The Complete Guide to Models and Workflows","text":"call takes roughly 1–3 minutes (dominated NIMBLE compilation first use). show code load pre-computed results. Rasch – Normal prior Rasch – DPM prior 2PL – DPM prior returned dpmirt_fit object gives compact overview printed, summary() adds item-level estimates DPM cluster diagnostics:","code":"fit_rasch_n <- dpmirt(   sim$response, model = \"rasch\", prior = \"normal\",   niter = 10000, nburnin = 2000, seed = 100 ) fit_rasch_n <- readRDS(find_extdata(\"vignette_fit_rasch_normal.rds\")) fit_rasch_dpm <- dpmirt(   sim$response, model = \"rasch\", prior = \"dpm\",   niter = 10000, nburnin = 2000, seed = 200 ) fit_rasch_dpm <- readRDS(find_extdata(\"vignette_fit_rasch_dpm.rds\")) fit_2pl <- dpmirt(   sim$response, model = \"2pl\", prior = \"dpm\",   niter = 15000, nburnin = 5000, seed = 300 ) fit_2pl <- readRDS(find_extdata(\"vignette_fit_2pl_dpm.rds\")) fit_rasch_n #> DPMirt Model Fit #> ================ #> Model:            RASCH  #> Prior:            normal  #> Identification:   constrained_item  #> Persons (N):      200  #> Items (I):        25  #> MCMC:            10000 iterations (2000 burnin, thin=1) #> WAIC:             6079.03  #> Total time:       55.4 sec  #> Min ESS (items):  1714  #> Min ESS (theta):  1372 summary(fit_rasch_dpm) #> DPMirt Model Summary #> ==================== #>  #> Model Configuration: #>   Model:            RASCH  #>   Prior:            dpm  #>   Identification:   constrained_item  #>   Rescaled:         TRUE  #>  #> Data: #>   Persons (N): 200  #>   Items (I):   25  #>  #> MCMC Settings: #>   Iterations:  10000  #>   Burn-in:     2000  #>   Thinning:    1  #>   Chains:      1  #>  #> Timing: #>   Compilation:  21.3 sec  #>   Sampling:     37.0 sec  #>   Total:        1.5 min  #>  #> Item Difficulty (beta) Summary: #>            Mean    SD #> beta[1]   0.139 0.148 #> beta[2]  -1.028 0.159 #> beta[3]   0.527 0.156 #> beta[4]  -0.692 0.156 #> beta[5]   0.195 0.150 #> beta[6]   0.508 0.155 #> beta[7]  -0.350 0.151 #> beta[8]  -0.377 0.153 #> beta[9]   0.487 0.154 #> beta[10] -0.844 0.161 #> beta[11]  0.767 0.159 #> beta[12]  0.333 0.150 #> beta[13]  0.140 0.152 #> beta[14] -0.251 0.152 #> beta[15]  0.029 0.145 #> beta[16] -0.039 0.147 #> beta[17] -0.178 0.152 #> beta[18]  0.382 0.155 #> beta[19]  1.003 0.166 #> beta[20]  0.897 0.164 #> beta[21] -0.116 0.150 #> beta[22] -0.688 0.153 #> beta[23]  0.688 0.156 #> beta[24] -0.182 0.151 #> beta[25] -1.350 0.173 #>  #> Person Ability (theta) Summary: #>   Range: [ -2.127 ,  1.72 ] #>   Mean:   -0.075  #>   SD:     0.814  #>  #> Model Comparison: #>   WAIC:  6078.17  #>  #> DPM Diagnostics: #>   Alpha (concentration): #>     Posterior mean:  0.271  #>     95% CI: [ 0.007 ,  0.982 ] #>   Number of clusters: #>     Posterior mean:  2.3  #>     Mode:           1  #>     Range: [ 1 ,  13 ] #>   DP density:    computed (500 grid points)"},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/articles/models-and-workflow.html","id":"specification","dir":"Articles","previous_headings":"3. The Step-by-Step Workflow","what":"3.1 Specification","title":"The Complete Guide to Models and Workflows","text":"dpmirt_spec() translates model request complete NIMBLE specification: programmatically generated model code, constants, data, initial values, monitor lists. Inspect returned dpmirt_spec object: spec pure R data (C++ pointers), can safely saved disk saveRDS() loaded new session.","code":"spec <- dpmirt_spec(   data = sim$response, model = \"rasch\",   prior = \"dpm\", identification = \"constrained_item\" ) spec$code       # nimbleCode object str(spec$constants) spec$monitors   # beta, alpha, zi, muTilde, s2Tilde, logprob nodes spec$monitors2  # eta (thinned separately via thin2)"},{"path":"https://joonho112.github.io/DPMirt/articles/models-and-workflow.html","id":"compilation","dir":"Articles","previous_headings":"3. The Step-by-Step Workflow","what":"3.2 Compilation","title":"The Complete Guide to Models and Workflows","text":"dpmirt_compile() feeds spec NIMBLE’s compiler, producing C++ objects run sampler native speed. Timing warning. Compilation typically takes 30–120 seconds. needs done per model specification. Session-bound caveat. compiled object contains external C++ pointers serialized saveRDS(). restart R, re-run dpmirt_compile() saved spec.","code":"compiled <- dpmirt_compile(spec)"},{"path":"https://joonho112.github.io/DPMirt/articles/models-and-workflow.html","id":"sampling","dir":"Articles","previous_headings":"3. The Step-by-Step Workflow","what":"3.3 Sampling","title":"The Complete Guide to Models and Workflows","text":"dpmirt_sample() runs MCMC compiled model. compilation already done, step fast repeatable. Compile-, sample-many. Draw multiple independent chains compiled model without paying compilation cost time: convenience, dpmirt() also supports multi-chain runs directly via nchains argument.","code":"samples <- dpmirt_sample(   compiled, niter = 10000, nburnin = 2000,   thin = 1, thin2 = 1, seed = 42 ) chains <- lapply(1:4, function(i) {   dpmirt_sample(compiled, niter = 10000, nburnin = 2000, seed = i) })"},{"path":"https://joonho112.github.io/DPMirt/articles/models-and-workflow.html","id":"rescaling","dir":"Articles","previous_headings":"3. The Step-by-Step Workflow","what":"3.4 Rescaling","title":"The Complete Guide to Models and Workflows","text":"dpmirt_rescale() applies post-hoc identification rescaling raw posterior samples returns dpmirt_fit object can passed directly dpmirt_estimates(), dpmirt_resume(), downstream functions. Rasch model: βi*=βi−β‾,θj*=θj−β‾ \\beta_i^* = \\beta_i - \\bar{\\beta}, \\qquad \\theta_j^* = \\theta_j - \\bar{\\beta} 2PL/3PL (IRT parameterization): s=(∏=1Iλi)−1/,βi*=βi−β‾s,λi*=λi⋅s,θj*=θj−β‾s s = \\left(\\prod_{=1}^{} \\lambda_i\\right)^{-1/}, \\quad \\beta_i^* = \\frac{\\beta_i - \\bar{\\beta}}{s}, \\quad \\lambda_i^* = \\lambda_i \\cdot s, \\quad \\theta_j^* = \\frac{\\theta_j - \\bar{\\beta}}{s} model uses \"constrained_item\" \"constrained_ability\" identification, rescaling -op — parameters already identified -model constraints.","code":"fit <- dpmirt_rescale(samples)  # fit is a dpmirt_fit: pass directly to estimates or resume est <- dpmirt_estimates(fit)"},{"path":"https://joonho112.github.io/DPMirt/articles/models-and-workflow.html","id":"estimates","dir":"Articles","previous_headings":"3. The Step-by-Step Workflow","what":"3.5 Estimates","title":"The Complete Guide to Models and Workflows","text":"dpmirt_estimates() computes person item point estimates using three posterior summary methods.","code":"est <- dpmirt_estimates(fit_rasch_dpm, methods = c(\"pm\", \"cb\", \"gr\")) head(est$theta, 8) #>           theta_pm theta_psd    theta_cb     theta_gr      rbar rhat #> eta[1] -1.64208358 0.4850620 -1.82658631 -1.898414370  14.10438    6 #> eta[2]  0.08246350 0.3785971  0.10105187  0.130777459 110.04200  114 #> eta[3]  0.05810186 0.3859230  0.07382128  0.001450727 108.21700  103 #> eta[4]  1.15463248 0.4241983  1.29948472  1.393735077 179.26688  192 #> eta[5] -0.68190514 0.3877922 -0.75333256 -0.665180404  53.89862   52 #> eta[6]  0.81760681 0.3950633  0.92276925  0.811079297 162.99625  167 #> eta[7]  1.72015915 0.4758415  1.93161057  2.206872410 194.11588  200 #> eta[8] -0.06517854 0.3837235 -0.06397722 -0.057278283  98.39575   98 #>        theta_lower theta_upper #> eta[1] -2.71809760 -0.76137677 #> eta[2] -0.63931121  0.81955388 #> eta[3] -0.68900612  0.82161938 #> eta[4]  0.34563696  2.00481098 #> eta[5] -1.44006283  0.07806641 #> eta[6]  0.05942028  1.60027832 #> eta[7]  0.84623291  2.75717002 #> eta[8] -0.84149547  0.68498198 head(est$beta, 8) #>            beta_pm  beta_psd    beta_cb     beta_gr     rbar rhat beta_lower #> beta[1]  0.1393281 0.1481244  0.1437448  0.09951606 14.54713   14 -0.1448619 #> beta[2] -1.0281008 0.1593125 -1.0606917 -1.05388296  2.26200    2 -1.3531175 #> beta[3]  0.5266330 0.1558563  0.5433273  0.59943417 19.94138   21  0.2277232 #> beta[4] -0.6922001 0.1558382 -0.7141429 -0.73611032  4.36675    4 -0.9959212 #> beta[5]  0.1946660 0.1501926  0.2008369  0.23378009 15.36788   16 -0.1017568 #> beta[6]  0.5082932 0.1550549  0.5244062  0.52121043 19.70375   20  0.2010165 #> beta[7] -0.3503717 0.1511989 -0.3614786 -0.36061570  7.43475    7 -0.6562346 #> beta[8] -0.3770295 0.1534740 -0.3889813 -0.46590990  7.14050    6 -0.6858021 #>          beta_upper #> beta[1]  0.44597696 #> beta[2] -0.72312083 #> beta[3]  0.84615054 #> beta[4] -0.39020070 #> beta[5]  0.48423148 #> beta[6]  0.80991762 #> beta[7] -0.06704874 #> beta[8] -0.08586970"},{"path":"https://joonho112.github.io/DPMirt/articles/models-and-workflow.html","id":"model-specifications","dir":"Articles","previous_headings":"","what":"4. Model Specifications","title":"The Complete Guide to Models and Workflows","text":"models use logistic link πij=P(Yij=1∣θj,itemi)\\pi_{ij} = P(Y_{ij} = 1 \\mid \\theta_j, \\text{item}_i).","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/models-and-workflow.html","id":"rasch-model","dir":"Articles","previous_headings":"4. Model Specifications","what":"4.1 Rasch Model","title":"The Complete Guide to Models and Workflows","text":"logit(πij)=θj−βi \\text{logit}(\\pi_{ij}) = \\theta_j - \\beta_i Rasch model single item parameter — difficulty βi\\beta_i. response probability depends difference person ability item difficulty. Identification. Location indeterminacy (adding constant cc θ\\theta β\\beta leaves likelihood unchanged). Default: \"constrained_item\" (mean-centers β\\beta MCMC). use. parsimonious IRT model. Assumes equal discrimination guessing. Stable item estimates even modest sample sizes.","code":"fit_rasch <- dpmirt(data, model = \"rasch\", prior = \"normal\")"},{"path":"https://joonho112.github.io/DPMirt/articles/models-and-workflow.html","id":"two-parameter-logistic-2pl","dir":"Articles","previous_headings":"4. Model Specifications","what":"4.2 Two-Parameter Logistic (2PL)","title":"The Complete Guide to Models and Workflows","text":"Adds discrimination parameter λi\\lambda_i. Two equivalent parameterizations available. IRT parameterization: logit(πij)=λi(θj−βi)\\text{logit}(\\pi_{ij}) = \\lambda_i(\\theta_j - \\beta_i) Slope–intercept (SI) parameterization: logit(πij)=λiθj+γi\\text{logit}(\\pi_{ij}) = \\lambda_i \\theta_j + \\gamma_i γi=−λiβi\\gamma_i = -\\lambda_i \\beta_i intercept. SI parameterization reduces posterior correlations discrimination intercept, improving MCMC mixing. DPMirt automatically enables centered sampler SI (Paganin et al., 2023). Identification. location scale indeterminacy. Default: \"unconstrained\" + post-hoc rescaling.","code":"fit_2pl_irt <- dpmirt(data, model = \"2pl\", prior = \"dpm\") fit_2pl_si  <- dpmirt(data, model = \"2pl\", prior = \"dpm\",                        parameterization = \"si\")"},{"path":"https://joonho112.github.io/DPMirt/articles/models-and-workflow.html","id":"three-parameter-logistic-3pl","dir":"Articles","previous_headings":"4. Model Specifications","what":"4.3 Three-Parameter Logistic (3PL)","title":"The Complete Guide to Models and Workflows","text":"Adds lower-asymptote (guessing) parameter δi∈(0,1)\\delta_i \\(0, 1): πij=δi+(1−δi)logistic(λi(θj−βi)) \\pi_{ij} = \\delta_i + (1 - \\delta_i)\\,\\text{logistic}\\!\\big(\\lambda_i(\\theta_j - \\beta_i)\\big) DPMirt places Beta(4,12)\\text{Beta}(4, 12) prior δi\\delta_i (prior mean ≈0.25\\approx 0.25, concentrating mass 0.1–0.4). Practical recommendations: Use longer chains (20,000+ iterations, 5,000+ burn-). appropriate multiple-choice items genuine guessing. IRT SI parameterizations supported.","code":"fit_3pl <- dpmirt(   data, model = \"3pl\", prior = \"dpm\",   niter = 20000, nburnin = 5000, seed = 400 )"},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/articles/models-and-workflow.html","id":"normal-parametric-prior","dir":"Articles","previous_headings":"5. Priors: Parametric vs Semiparametric","what":"5.1 Normal (Parametric) Prior","title":"The Complete Guide to Models and Workflows","text":"θj∼N(μ,σ2),μ∼N(0,3),σ2∼Inv-Gamma(2.01,1.01) \\theta_j \\sim N(\\mu, \\sigma^2), \\qquad \\mu \\sim N(0, 3), \\qquad \\sigma^2 \\sim \\text{Inv-Gamma}(2.01, 1.01) Standard assumption IRT software. Works well ability distribution approximately unimodal symmetric.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/models-and-workflow.html","id":"dpm-semiparametric-prior","dir":"Articles","previous_headings":"5. Priors: Parametric vs Semiparametric","what":"5.2 DPM (Semiparametric) Prior","title":"The Complete Guide to Models and Workflows","text":"DPM prior uses Chinese Restaurant Process (CRP) representation: zj∣α∼CRP(α),θj∣zj∼N(μ̃zj,σ̃zj2) z_j \\mid \\alpha \\sim \\text{CRP}(\\alpha), \\qquad \\theta_j \\mid z_j \\sim N\\!\\big(\\tilde{\\mu}_{z_j},\\; \\tilde{\\sigma}^2_{z_j}\\big) cluster mm draws base measure G0G_0: μ̃m∼N(0,σμ2),σ̃m2∼Inv-Gamma(ν1,ν2) \\tilde{\\mu}_m \\sim N(0, \\sigma^2_\\mu), \\qquad \\tilde{\\sigma}^2_m \\sim \\text{Inv-Gamma}(\\nu_1, \\nu_2) concentration parameter α\\alpha controls expected number clusters.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/models-and-workflow.html","id":"hyperparameter-defaults","dir":"Articles","previous_headings":"5. Priors: Parametric vs Semiparametric","what":"5.3 Hyperparameter Defaults","title":"The Complete Guide to Models and Workflows","text":"can modified via base_measure:","code":"fit <- dpmirt(data, model = \"rasch\", prior = \"dpm\",               base_measure = list(s2_mu = 4, nu1 = 2.5, nu2 = 1.5),               M = 100)"},{"path":"https://joonho112.github.io/DPMirt/articles/models-and-workflow.html","id":"when-to-choose-the-dpm-prior","dir":"Articles","previous_headings":"5. Priors: Parametric vs Semiparametric","what":"5.4 When to Choose the DPM Prior","title":"The Complete Guide to Models and Workflows","text":"Non-normal populations. Heterogeneous test-taker groups (e.g., mixing advanced introductory students). Multimodal distributions. Floor/ceiling effects distinct subgroups. Exploratory analysis. little prior information ability distribution shape. Shrinkage calibration. DPM prior produces less severe shrinkage true distribution non-Normal. true distribution Normal, DPM converges single cluster reproduces Normal-prior results modest computation-time increase.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/models-and-workflow.html","id":"normal-vs--dpm-when-normality-fails","dir":"Articles","previous_headings":"5. Priors: Parametric vs Semiparametric","what":"5.5 Normal vs. DPM: When Normality Fails","title":"The Complete Guide to Models and Workflows","text":"guidelines easier appreciate concrete example. pre-computed bimodal simulation ships package: 200 persons drawn two-group mixture (θ∼0.5N(−1.5,0.5)+0.5N(1.5,0.5)\\theta \\sim 0.5\\,N(-1.5, 0.5) + 0.5\\,N(1.5, 0.5)) assessed 25 Rasch items (w‾≈0.8\\bar{w} \\approx 0.8). WAIC provides model-level comparison: example two WAIC values nearly identical (|ΔWAIC|<2|\\Delta\\text{WAIC}| < 2), expected: WAIC measures predictive accuracy binary responses, priors predict item responses equally well. DPM’s real advantage shows recovered ability distribution — difference WAIC capture density plot makes visually obvious. True bimodal density (gray) versus posterior mean estimates Normal (blue) DPM (orange) priors. Normal prior forces unimodal fit; DPM prior recovers modes. Take-away. true distribution departs normality, DPM prior produces posterior mean estimates track true distributional shape far accurately Normal prior. WAIC may detect advantage evaluates item-response prediction, ability-distribution recovery. practical guidance choosing posterior summary best serves inferential goal, see vignette(\"posterior-summaries\"). Practical recommendation. applied researchers suspect non-normality, fit priors compare using (1) WAIC item-response prediction (2) density plot posterior mean estimates distributional recovery. population truly non-normal reliability least moderate (w‾≥0.7\\bar{w} \\ge 0.7), density comparison typically reveal DPM’s advantage even WAIC values similar.","code":"sim_bm    <- readRDS(find_extdata(\"vignette_sim_bimodal.rds\")) fit_bm_n  <- readRDS(find_extdata(\"vignette_fit_rasch_normal_bimodal.rds\")) fit_bm_d  <- readRDS(find_extdata(\"vignette_fit_rasch_dpm_bimodal.rds\")) dpmirt_compare(fit_bm_n, fit_bm_d) #>          model     waic delta_waic #> 1 RASCH-normal 4009.778   0.000000 #> 2    RASCH-dpm 4010.544   0.766108 true_theta <- sim_bm$theta pm_normal  <- colMeans(fit_bm_n$theta_samp) pm_dpm     <- colMeans(fit_bm_d$theta_samp)  df_bm <- data.frame(   value  = c(true_theta, pm_normal, pm_dpm),   source = factor(rep(c(\"True\", \"Normal (PM)\", \"DPM (PM)\"),                       each = length(true_theta)),                   levels = c(\"True\", \"Normal (PM)\", \"DPM (PM)\")) )  ggplot(df_bm, aes(x = value, fill = source, colour = source)) +   geom_density(alpha = 0.25, linewidth = 0.8) +   scale_fill_manual(values = c(\"True\"         = pal$reference,                                 \"Normal (PM)\" = pal$parametric,                                 \"DPM (PM)\"    = pal$semiparametric)) +   scale_colour_manual(values = c(\"True\"         = pal$reference,                                   \"Normal (PM)\" = pal$parametric,                                   \"DPM (PM)\"    = pal$semiparametric)) +   labs(title = \"Recovering a Bimodal Population\",        x = expression(theta), y = \"Density\") +   theme_bw() +   theme(legend.position = \"top\", legend.title = element_blank())"},{"path":"https://joonho112.github.io/DPMirt/articles/models-and-workflow.html","id":"identification-strategies","dir":"Articles","previous_headings":"","what":"6. Identification Strategies","title":"The Complete Guide to Models and Workflows","text":"Paganin’s finding. unconstrained + post-hoc rescaling approach yields efficient MCMC sampler DPM-IRT models. constrained_ability incompatible DPM prior (DPMirt raise error) since DPM’s purpose learn ability distribution data. choose. DPM models, use defaults (\"constrained_item\" Rasch, \"unconstrained\" 2PL/3PL). Normal-prior models three valid; \"constrained_ability\" gives strongest N(0,1)N(0,1) shrinkage.","code":"# Rasch with unconstrained + post-hoc rescaling fit <- dpmirt(data, model = \"rasch\", prior = \"normal\",               identification = \"unconstrained\")  # 2PL with in-model constrained_item centering fit <- dpmirt(data, model = \"2pl\", prior = \"normal\",               identification = \"constrained_item\")"},{"path":"https://joonho112.github.io/DPMirt/articles/models-and-workflow.html","id":"chain-continuation","dir":"Articles","previous_headings":"","what":"7. Chain Continuation","title":"The Complete Guide to Models and Workflows","text":"initial run needs iterations, dpmirt_resume() continues sampler current state without recompilation. step--step workflow: dpmirt_resume() requires compiled model’s C++ pointers alive (R session). pointers expired, recompile. returned dpmirt_samples object can passed dpmirt_rescale() (returns dpmirt_fit) dpmirt_estimates().","code":"# Initial fit fit <- dpmirt(data, model = \"rasch\", prior = \"dpm\",               niter = 5000, nburnin = 1000, seed = 42)  # Trace looks non-stationary... plot(fit, type = \"trace\")  # Resume: add 10,000 more iterations (no burn-in needed) resumed <- dpmirt_resume(fit, niter_more = 10000) samples <- dpmirt_sample(compiled, niter = 5000, nburnin = 1000) resumed <- dpmirt_resume(compiled, niter_more = 10000)"},{"path":"https://joonho112.github.io/DPMirt/articles/models-and-workflow.html","id":"model-comparison-with-waic","dir":"Articles","previous_headings":"","what":"8. Model Comparison with WAIC","title":"The Complete Guide to Models and Workflows","text":"Every dpmirt_fit stores WAIC (Watanabe–Akaike Information Criterion) value, computed automatically sampling. Lower WAIC indicates better --sample prediction. delta_waic column shows difference best model. can compare number fits: Interpreting WAIC differences. |ΔWAIC|<2|\\Delta\\text{WAIC}| < 2: Models essentially equivalent. 2<|ΔWAIC|<102 < |\\Delta\\text{WAIC}| < 10: Moderate preference. |ΔWAIC|>10|\\Delta\\text{WAIC}| > 10: Strong preference.","code":"comparison <- dpmirt_compare(fit_rasch_n, fit_rasch_dpm) comparison comparison <- dpmirt_compare(fit_rasch_n, fit_rasch_dpm) knitr::kable(comparison, digits = 2, row.names = FALSE) dpmirt_compare(fit_rasch_n, fit_rasch_dpm, fit_2pl)"},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/articles/models-and-workflow.html","id":"matrix-format-default","dir":"Articles","previous_headings":"9. Data Formats","what":"Matrix Format (Default)","title":"The Complete Guide to Models and Workflows","text":"Binary matrix persons rows items columns. Missing responses coded NA.","code":"head(sim$response[, 1:6]) #>      [,1] [,2] [,3] [,4] [,5] [,6] #> [1,]    1    0    1    1    0    1 #> [2,]    0    1    0    1    1    0"},{"path":"https://joonho112.github.io/DPMirt/articles/models-and-workflow.html","id":"long-format","dir":"Articles","previous_headings":"9. Data Formats","what":"Long Format","title":"The Complete Guide to Models and Workflows","text":"data.frame columns person, item, response. DPMirt detects format automatically converts internally. long--matrix conversion produces large sparse matrix, verify dimensions dpmirt_spec() running full pipeline.","code":"head(response_long) #>   person item response #> 1      1    1        1 #> 2      1    2        0 fit <- dpmirt(response_long, model = \"rasch\", prior = \"normal\")"},{"path":"https://joonho112.github.io/DPMirt/articles/models-and-workflow.html","id":"visualizations","dir":"Articles","previous_headings":"","what":"10. Visualizations","title":"The Complete Guide to Models and Workflows","text":"DPMirt provides 12 plot types via plot(fit, type = ...). ggplot2 installed used automatically; otherwise base R graphics produced. Posterior density person abilities. Item difficulty estimates posterior intervals. Log-likelihood trace. Item Characteristic Curves items 1–6. Wright map.","code":"plot(fit_rasch_dpm, type = \"density\") plot(fit_rasch_dpm, type = \"items\") plot(fit_rasch_dpm, type = \"trace\") plot(fit_rasch_dpm, type = \"icc\", items = 1:6) plot(fit_rasch_dpm, type = \"wright_map\")"},{"path":"https://joonho112.github.io/DPMirt/articles/models-and-workflow.html","id":"summary-and-whats-next","dir":"Articles","previous_headings":"","what":"11. Summary and What’s Next?","title":"The Complete Guide to Models and Workflows","text":"vignette covered full model workflow space DPMirt: Two workflow modes: one-step dpmirt() step--step pipeline compile-sampling. Three IRT models: Rasch, 2PL, 3PL, Normal DPM priors. Two parameterizations 2PL/3PL: IRT slope–intercept. Three identification strategies: constrained_ability, constrained_item, unconstrained + post-hoc rescaling. Chain continuation dpmirt_resume(). Model comparison WAIC via dpmirt_compare(). Twelve built-plot types posterior visualization.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/nimble-internals.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Under the Hood: NIMBLE Backend and Advanced Usage","text":"DPMirt built top NIMBLE probabilistic programming framework (de Valpine et al., 2017). vignette users want : Understand DPMirt generates NIMBLE model code. Inspect modify custom NIMBLE components (distributions samplers). Leverage compile-, sample-many pattern efficient multi-chain exploratory workflows. Understand post-hoc rescaling resolves identification indeterminacy. Reconstruct DP mixture density posterior samples. users never need level detail — dpmirt() function handles everything automatically. want write custom samplers, hook compiled MCMC, adapt DPMirt new model, start.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/articles/nimble-internals.html","id":"why-programmatic","dir":"Articles","previous_headings":"Programmatic Code Generation","what":"Why Programmatic?","title":"Under the Hood: NIMBLE Backend and Advanced Usage","text":"Paganin et al. (2023) provide 20 separate NIMBLE code files, one model–prior–identification combination. DPMirt instead generates NIMBLE code programmatically via dpmirt_spec(), dispatching three configuration axes: yields 3×2×3=183 \\times 2 \\times 3 = 18 potential combinations (valid), generated single specification call.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/nimble-internals.html","id":"inspecting-a-specification","dir":"Articles","previous_headings":"Programmatic Code Generation","what":"Inspecting a Specification","title":"Under the Hood: NIMBLE Backend and Advanced Usage","text":"dpmirt_spec() function lightweight — builds NIMBLE code, constants, data, initial values, monitor configuration without compiling anything. fast (1 second) produces fully inspectable object:","code":"# Generate some example data sim <- dpmirt_simulate(200, 25, model = \"rasch\", latent_shape = \"bimodal\",                        seed = 42)  # Create a specification (no compilation) spec <- dpmirt_spec(   sim$response,   model  = \"rasch\",   prior  = \"dpm\",   alpha_prior = c(a = 1, b = 3),   base_measure = list(s2_mu = 2, nu1 = 2.01, nu2 = 1.01) )  print(spec) #> DPMirt Model Specification #> ========================== #> Model:            RASCH  #> Prior:            dpm  #> Identification:   constrained_item  #> Persons (N):      200  #> Items (I):        25  #> Max clusters (M): 50  #> Alpha prior:      Gamma(1, 3) #> Monitors:         beta, alpha, zi, muTilde, s2Tilde, myLogProbAll, myLogProbSome, myLogLik  #> Monitors2:        eta"},{"path":"https://joonho112.github.io/DPMirt/articles/nimble-internals.html","id":"inspecting-the-generated-code","dir":"Articles","previous_headings":"Programmatic Code Generation","what":"Inspecting the Generated Code","title":"Under the Hood: NIMBLE Backend and Advanced Usage","text":"code element nimbleCode object can print manipulate:","code":"spec$code #> { #>     for (j in 1:N) { #>         for (i in 1:I) { #>             y[j, i] ~ dbern(pi[j, i]) #>             logit(pi[j, i]) <- eta[j] - beta[i] #>         } #>     } #>     for (i in 1:I) { #>         beta.tmp[i] ~ dnorm(0, var = sigma2_beta) #>     } #>     beta[1:I] <- beta.tmp[1:I] - mean(beta.tmp[1:I]) #>     zi[1:N] ~ dCRP(alpha, size = N) #>     alpha ~ dgamma(a, b) #>     for (j in 1:N) { #>         eta[j] ~ dnorm(mu_j[j], var = s2_j[j]) #>         mu_j[j] <- muTilde[zi[j]] #>         s2_j[j] <- s2Tilde[zi[j]] #>     } #>     for (m in 1:M) { #>         muTilde[m] ~ dnorm(0, var = s2_mu) #>         s2Tilde[m] ~ dinvgamma(nu1, nu2) #>     } #>     myLogProbAll ~ dnorm(0, 1) #>     myLogProbSome ~ dnorm(0, 1) #>     myLogLik ~ dnorm(0, 1) #> }"},{"path":"https://joonho112.github.io/DPMirt/articles/nimble-internals.html","id":"inspecting-constants-and-monitors","dir":"Articles","previous_headings":"Programmatic Code Generation","what":"Inspecting Constants and Monitors","title":"Under the Hood: NIMBLE Backend and Advanced Usage","text":"","code":"# Constants passed to the NIMBLE model str(spec$constants) #> List of 9 #>  $ N          : int 200 #>  $ I          : int 25 #>  $ sigma2_beta: num 3 #>  $ M          : int 50 #>  $ a          : Named num 1 #>   ..- attr(*, \"names\")= chr \"a\" #>  $ b          : Named num 3 #>   ..- attr(*, \"names\")= chr \"b\" #>  $ s2_mu      : num 2 #>  $ nu1        : num 2.01 #>  $ nu2        : num 1.01 # What gets tracked during MCMC cat(\"Primary monitors:\", paste(spec$monitors, collapse = \", \"), \"\\n\") #> Primary monitors: beta, alpha, zi, muTilde, s2Tilde, myLogProbAll, myLogProbSome, myLogLik cat(\"Thinned monitors:\", paste(spec$monitors2, collapse = \", \"), \"\\n\") #> Thinned monitors: eta"},{"path":"https://joonho112.github.io/DPMirt/articles/nimble-internals.html","id":"annotated-walkthrough-rasch-dpm-unconstrained","dir":"Articles","previous_headings":"Programmatic Code Generation","what":"Annotated Walkthrough: Rasch-DPM-Unconstrained","title":"Under the Hood: NIMBLE Backend and Advanced Usage","text":"generated code Rasch model DPM prior unconstrained identification structure (shown pseudocode clarity): Key design choices: CRP representation: dCRP(alpha, size = N) uses Chinese Restaurant Process assign person cluster. NIMBLE handles stick-breaking conversion internally. Truncation: M = 50 clusters (configurable) pre-allocated. CRP can use fewer never . Dummy monitoring nodes: myLogProbAll, myLogProbSome, myLogLik declared dummy dnorm(0,1) nodes. default samplers replaced logProb_summer MCMC configuration (see ).","code":"nimbleCode({   # --- Likelihood ---   for (i in 1:I) {     for (j in 1:N) {       y[j, i] ~ dbern(pi[j, i])       logit(pi[j, i]) <- eta[j] - beta[i]      # Rasch ICC     }   }    # --- Item parameters: free (rescaled post-hoc) ---   for (i in 1:I) {     beta[i] ~ dnorm(0, var = sigma2_beta)        # Prior on difficulties   }    # --- DPM prior for abilities via CRP ---   zi[1:N] ~ dCRP(alpha, size = N)                # Cluster assignments   alpha ~ dgamma(a, b)                           # Concentration parameter    for (j in 1:N) {     eta[j] ~ dnorm(mu_j[j], var = s2_j[j])      # Person ability     mu_j[j]  <- muTilde[zi[j]]                   # Cluster mean     s2_j[j]  <- s2Tilde[zi[j]]                   # Cluster variance   }    for (m in 1:M) {     muTilde[m]  ~ dnorm(0, var = s2_mu)          # Base measure: mean     s2Tilde[m]  ~ dinvgamma(nu1, nu2)            # Base measure: variance   }    # --- Log-probability monitoring nodes ---   myLogProbAll  ~ dnorm(0, 1)                    # Replaced by logProb_summer   myLogProbSome ~ dnorm(0, 1)   myLogLik      ~ dnorm(0, 1) })"},{"path":"https://joonho112.github.io/DPMirt/articles/nimble-internals.html","id":"custom-nimble-components","dir":"Articles","previous_headings":"","what":"Custom NIMBLE Components","title":"Under the Hood: NIMBLE Backend and Advanced Usage","text":"DPMirt registers three custom NIMBLE components, adapted Paganin et al. (2023) implemented using lazy-initialization pattern avoid executing nimbleFunction() package load time. Custom NIMBLE components registered DPMirt.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/nimble-internals.html","id":"dbernoullivector","dir":"Articles","previous_headings":"Custom NIMBLE Components","what":"dBernoulliVector","title":"Under the Hood: NIMBLE Backend and Advanced Usage","text":"constrained_item identification 2PL/3PL models, likelihood person’s entire response vector evaluated jointly: necessary constraint beta[1:] <- beta.tmp[1:] - mean(beta.tmp[1:]) creates deterministic dependency across items, requiring vectorized likelihood. density function sums element-wise Bernoulli log-probabilities:","code":"y[j, 1:I] ~ dBernoulliVector(prob = pi[j, 1:I]) # Simplified version of the registered nimbleFunction dBernoulliVector <- function(x, prob, log = 0) {   logProb <- sum(dbinom(x, size = 1, prob = prob, log = TRUE))   if (log) return(logProb) else return(exp(logProb)) }"},{"path":"https://joonho112.github.io/DPMirt/articles/nimble-internals.html","id":"logprob_summer","dir":"Articles","previous_headings":"Custom NIMBLE Components","what":"logProb_summer","title":"Under the Hood: NIMBLE Backend and Advanced Usage","text":"pseudo-sampler propose new values — computes stores log-probability set nodes MCMC iteration. Three instances configured: myLogLik trace used : - Visual convergence checking (trace plots). - WAIC computation (NIMBLE’s built-WAIC available).","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/nimble-internals.html","id":"sampler_centered","dir":"Articles","previous_headings":"Custom NIMBLE Components","what":"sampler_centered","title":"Under the Hood: NIMBLE Backend and Advanced Usage","text":"centered sampler critical efficient mixing slope-intercept (SI) parameterization 2PL 3PL models. addresses strong posterior correlation log⁡λi\\log\\lambda_i γi\\gamma_i making joint proposal: Propose log⁡λi′=log⁡λi+ϵ\\log\\lambda'_i = \\log\\lambda_i + \\epsilon, ϵ∼N(0,scale2)\\epsilon \\sim N(0, \\text{scale}^2). Center γi′=γi+η‾⋅(exp⁡(log⁡λi)−exp⁡(log⁡λi′))\\gamma'_i = \\gamma_i + \\bar\\eta \\cdot (\\exp(\\log\\lambda_i) - \\exp(\\log\\lambda'_i)). Accept/reject via Metropolis-Hastings. centering mean η‾\\bar\\eta updated iteration mean(eta). Adaptive scaling targets acceptance rate 0.44 (optimal univariate random-walk MH). used? 2PL/3PL models SI parameterization identification = \"unconstrained\" \"constrained_ability\". IRT parameterization, NIMBLE’s default samplers sufficient correlation structure different. dpmirt_compile() function automatically enables centered sampler use_centered_sampler = \"auto\" (default).","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/nimble-internals.html","id":"compile-once-sample-many-pattern","dir":"Articles","previous_headings":"","what":"Compile-Once, Sample-Many Pattern","title":"Under the Hood: NIMBLE Backend and Advanced Usage","text":"NIMBLE compilation translates model MCMC configuration C++ code, compiles , loads resulting shared library. expensive step pipeline. DPMirt separates compilation sampling, allowing compile run multiple chains, extend runs, experiment different MCMC lengths — without recompiling.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/nimble-internals.html","id":"architecture","dir":"Articles","previous_headings":"Compile-Once, Sample-Many Pattern","what":"Architecture","title":"Under the Hood: NIMBLE Backend and Advanced Usage","text":"","code":"dpmirt_spec()  ──>  dpmirt_compile()  ──>  dpmirt_sample()   [< 1 sec]        [30-120 sec]           [10-60 sec per call]                          │                          ├── dpmirt_sample(seed = 1)                          ├── dpmirt_sample(seed = 2)                          ├── dpmirt_sample(seed = 3)                          └── dpmirt_sample(seed = 4)"},{"path":"https://joonho112.github.io/DPMirt/articles/nimble-internals.html","id":"timing-table","dir":"Articles","previous_headings":"Compile-Once, Sample-Many Pattern","what":"Timing Table","title":"Under the Hood: NIMBLE Backend and Advanced Usage","text":"Typical timing pipeline stage (Rasch, N=200, =25).","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/nimble-internals.html","id":"step-by-step-workflow","dir":"Articles","previous_headings":"Compile-Once, Sample-Many Pattern","what":"Step-by-Step Workflow","title":"Under the Hood: NIMBLE Backend and Advanced Usage","text":"","code":"# Step 1: Specification (fast) spec <- dpmirt_spec(sim$response, model = \"rasch\", prior = \"dpm\")  # Step 2: Compilation (expensive --- do this once) compiled <- dpmirt_compile(spec, verbose = TRUE)  # Step 3: Multiple chains (fast --- reuse compiled object) chains <- lapply(1:4, function(i) {   dpmirt_sample(compiled, niter = 10000, nburnin = 2000, seed = i) })  # Step 4: Chain continuation (extend without recompiling) # Option A: low-level via dpmirt_sample with reset = FALSE extended <- dpmirt_sample(compiled, niter = 5000, nburnin = 0,                            reset = FALSE)  # Option B: higher-level via dpmirt_resume (preferred) # extended <- dpmirt_resume(compiled, niter = 5000)"},{"path":"https://joonho112.github.io/DPMirt/articles/nimble-internals.html","id":"custom-sampler-configuration","dir":"Articles","previous_headings":"Compile-Once, Sample-Many Pattern","what":"Custom Sampler Configuration","title":"Under the Hood: NIMBLE Backend and Advanced Usage","text":"advanced users, dpmirt_compile() accepts custom sampler configuration function: Serialization caveat: Compiled NIMBLE objects contain external C++ pointers serialized across R sessions. call saveRDS(compiled, ...) readRDS(...) new session, pointers dead MCMC operations fail. Instead, save dpmirt_spec object recompile:","code":"# Define a custom sampler configuration function my_config <- function(conf, model, spec) {   # Remove all default samplers for eta   for (j in seq_len(spec$config$N)) {     conf$removeSamplers(paste0(\"eta[\", j, \"]\"))   }    # Add slice samplers instead of the default RW   for (j in seq_len(spec$config$N)) {     conf$addSampler(       target = paste0(\"eta[\", j, \"]\"),       type   = \"slice\"     )   }    conf }  compiled <- dpmirt_compile(spec, sampler_config = my_config) # CORRECT: Save spec, recompile in new session saveRDS(spec, \"my_spec.rds\") # ... in new R session ... spec <- readRDS(\"my_spec.rds\") compiled <- dpmirt_compile(spec)"},{"path":"https://joonho112.github.io/DPMirt/articles/nimble-internals.html","id":"accessing-nimble-objects-directly","dir":"Articles","previous_headings":"Compile-Once, Sample-Many Pattern","what":"Accessing NIMBLE Objects Directly","title":"Under the Hood: NIMBLE Backend and Advanced Usage","text":"compiled object provides direct access underlying NIMBLE objects advanced manipulation:","code":"# The compiled NIMBLE model (C object) compiled$Cmodel  # The compiled MCMC (C object) compiled$Cmcmc  # List all node names compiled$Cmodel$getNodeNames()  # Get current values of a parameter compiled$Cmodel$eta  # Calculate log-probability of the current model state compiled$Cmodel$calculate()  # Inspect sampler configuration compiled$mcmc_conf$printSamplers()"},{"path":"https://joonho112.github.io/DPMirt/articles/nimble-internals.html","id":"post-hoc-rescaling-implementation","dir":"Articles","previous_headings":"","what":"Post-hoc Rescaling Implementation","title":"Under the Hood: NIMBLE Backend and Advanced Usage","text":"IRT models identification indeterminacy: without constraints, likelihood invariant certain transformations parameters. DPMirt’s default approach leave model unconstrained MCMC apply rescaling posterior samples afterwards.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/nimble-internals.html","id":"rasch-location-shift-only","dir":"Articles","previous_headings":"Post-hoc Rescaling Implementation","what":"Rasch: Location Shift Only","title":"Under the Hood: NIMBLE Backend and Advanced Usage","text":"Rasch model location indeterminacy. MCMC iteration ss, rescaling : βi,s*=βi,s−β‾s,θp,s*=θp,s−β‾s \\beta^*_{,s} = \\beta_{,s} - \\bar{\\beta}_s, \\qquad \\theta^*_{p,s} = \\theta_{p,s} - \\bar{\\beta}_s β‾s=1I∑=1Iβi,s\\bar{\\beta}_s = \\frac{1}{}\\sum_{=1}^\\beta_{,s}. Invariant check: rescaling, |β‾s*|<ϵ|\\bar{\\beta}^*_s| < \\epsilon every iteration.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/nimble-internals.html","id":"pl-irt-location-scale","dir":"Articles","previous_headings":"Post-hoc Rescaling Implementation","what":"2PL IRT: Location + Scale","title":"Under the Hood: NIMBLE Backend and Advanced Usage","text":"2PL model location scale indeterminacy. iteration ss: locations=β‾s,scales=(∏=1Iλi,s)−1/\\text{location}_s = \\bar{\\beta}_s, \\qquad \\text{scale}_s = \\left(\\prod_{=1}^\\lambda_{,s}\\right)^{-1/} βi,s*=βi,s−locationsscales,λi,s*=λi,s⋅scales,θp,s*=θp,s−locationsscales \\beta^*_{,s} = \\frac{\\beta_{,s} - \\text{location}_s}{\\text{scale}_s}, \\qquad \\lambda^*_{,s} = \\lambda_{,s} \\cdot \\text{scale}_s, \\qquad \\theta^*_{p,s} = \\frac{\\theta_{p,s} - \\text{location}_s}{\\text{scale}_s} Invariant checks: - |β‾s*|<ϵ|\\bar{\\beta}^*_s| < \\epsilon - |geom_mean(λs*)−1|<ϵ|\\text{geom\\_mean}(\\lambda^*_s) - 1| < \\epsilon","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/nimble-internals.html","id":"pl-si-different-sign-convention","dir":"Articles","previous_headings":"Post-hoc Rescaling Implementation","what":"2PL SI: Different Sign Convention","title":"Under the Hood: NIMBLE Backend and Advanced Usage","text":"slope-intercept parameterization (logit(p)=λθ+γ\\text{logit}(p) = \\lambda\\theta + \\gamma), location shift opposite sign γ=−λβ\\gamma = -\\lambda\\beta: locations=∑iγi,s∑iλi,s \\text{location}_s = \\frac{\\sum_i \\gamma_{,s}}{\\sum_i \\lambda_{,s}} γi,s*=γi,s−λi,s⋅locations,θp,s*=θp,s+locationsscales \\gamma^*_{,s} = \\gamma_{,s} - \\lambda_{,s} \\cdot \\text{location}_s, \\qquad \\theta^*_{p,s} = \\frac{\\theta_{p,s} + \\text{location}_s}{\\text{scale}_s} Note ++ sign theta rescaling (vs. −- IRT parameterization).","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/nimble-internals.html","id":"why-post-hoc","dir":"Articles","previous_headings":"Post-hoc Rescaling Implementation","what":"Why Post-hoc?","title":"Under the Hood: NIMBLE Backend and Advanced Usage","text":"Post-hoc rescaling two advantages -MCMC constraints: Simpler MCMC: unconstrained model simpler posterior geometry, avoiding need constrained samplers. Flexibility: Different identification conventions can applied posterior samples without re-running MCMC. disadvantage raw (unrescaled) samples may poor mixing location/scale dimensions poorly identified. practice, DPMirt’s default priors provide sufficient regularization.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/nimble-internals.html","id":"dp-density-reconstruction","dir":"Articles","previous_headings":"","what":"DP Density Reconstruction","title":"Under the Hood: NIMBLE Backend and Advanced Usage","text":"DPM models, DPMirt can reconstruct posterior predictive density latent trait. follows Paganin et al.’s getSamplesDPmeasure() approach.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/nimble-internals.html","id":"algorithm","dir":"Articles","previous_headings":"DP Density Reconstruction","what":"Algorithm","title":"Under the Hood: NIMBLE Backend and Advanced Usage","text":"post-burn-MCMC iteration ss: Extract stick-breaking weights ws,1,…,ws,Ksw_{s,1}, \\ldots, w_{s,K_s} atoms (μ̃s,k,σ̃s,k2)(\\tilde\\mu_{s,k}, \\tilde\\sigma^2_{s,k}) CRP posterior via NIMBLE’s getSamplesDPmeasure(). Evaluate finite mixture density grid: fs(x)=∑k=1Ksws,k⋅ϕ(x;μ̃s,k,σ̃s,k2) f_s(x) = \\sum_{k=1}^{K_s} w_{s,k} \\cdot \\phi\\!\\left(x;\\, \\tilde\\mu_{s,k},\\, \\tilde\\sigma^2_{s,k}\\right) ϕ(x;μ,σ2)\\phi(x; \\mu, \\sigma^2) Normal density. Average iterations posterior predictive mean: f̂(x)=1S∑s=1Sfs(x) \\hat{f}(x) = \\frac{1}{S}\\sum_{s=1}^S f_s(x) Pointwise credible bands: Take quantiles across iterations grid point.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/nimble-internals.html","id":"rescaling-adjustment","dir":"Articles","previous_headings":"DP Density Reconstruction","what":"Rescaling Adjustment","title":"Under the Hood: NIMBLE Backend and Advanced Usage","text":"unconstrained models, DP density raw (unrescaled) scale. evaluate rescaled theta scale, grid shifted iteration-specific location shift: f̂rescaled(x)=fs(x+locations) \\hat{f}_{\\text{rescaled}}(x) = f_s(x + \\text{location}_s) Jacobian 1 location shift, density adjustment needed.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/nimble-internals.html","id":"using-dpmirt_dp_density","dir":"Articles","previous_headings":"DP Density Reconstruction","what":"Using dpmirt_dp_density()","title":"Under the Hood: NIMBLE Backend and Advanced Usage","text":"","code":"# Compute DP density from a fitted DPM model dp_dens <- dpmirt_dp_density(   fit,   grid               = seq(-6, 6, length.out = 500),   credible_interval  = 0.95,   apply_rescaling    = TRUE )  # Access the results dp_dens$grid            # Evaluation points dp_dens$density_mean    # Posterior mean density dp_dens$density_lower   # 2.5th percentile (lower band) dp_dens$density_upper   # 97.5th percentile (upper band) dp_dens$density_samples # Full matrix: niter x n_grid"},{"path":"https://joonho112.github.io/DPMirt/articles/nimble-internals.html","id":"visualization","dir":"Articles","previous_headings":"DP Density Reconstruction","what":"Visualization","title":"Under the Hood: NIMBLE Backend and Advanced Usage","text":"Note computation cost: dpmirt_dp_density() internally rebuilds recompiles NIMBLE model call getSamplesDPmeasure(). adds 30–60 seconds. dpmirt() function runs automatically compute_dp_density = TRUE (default DPM models). want skip , set compute_dp_density = FALSE call dpmirt_dp_density(fit) later.","code":"# Plot with credible band plot(dp_dens$grid, dp_dens$density_mean, type = \"l\", lwd = 2,      col = pal$semiparametric,      xlab = expression(theta), ylab = \"Density\",      main = \"DP Mixture Posterior Density\")  polygon(c(dp_dens$grid, rev(dp_dens$grid)),         c(dp_dens$density_lower, rev(dp_dens$density_upper)),         col = adjustcolor(pal$semiparametric, alpha.f = 0.2),         border = NA)  # Reference: N(0,1) curve(dnorm, add = TRUE, lty = 2, col = pal$reference, lwd = 1.5)  legend(\"topright\",        legend = c(\"DP posterior mean\", \"95% credible band\", \"N(0,1)\"),        col = c(pal$semiparametric, pal$semiparametric, pal$reference),        lwd = c(2, NA, 1.5), lty = c(1, NA, 2),        fill = c(NA, adjustcolor(pal$semiparametric, 0.2), NA),        border = c(NA, NA, NA), bty = \"n\")"},{"path":"https://joonho112.github.io/DPMirt/articles/nimble-internals.html","id":"mcmc-pipeline-internals","dir":"Articles","previous_headings":"","what":"MCMC Pipeline Internals","title":"Under the Hood: NIMBLE Backend and Advanced Usage","text":"following diagram shows complete data flow raw data final dpmirt_fit object:","code":"data (N x I matrix)   |   v dpmirt_spec()   |-- code:       nimbleCode object   |-- constants:  N, I, M, hyperparams   |-- data:       list(y = ...)   |-- inits:      smart init from k-means   |-- monitors:   c(\"beta\", \"alpha\", \"zi\", ...)   |-- monitors2:  c(\"eta\")   v dpmirt_compile()   |-- nimbleModel()      --> Rmodel   |-- configureMCMC()    --> add logProb_summer, centered sampler   |-- buildMCMC()        --> Rmcmc   |-- compileNimble()    --> Cmodel, Cmcmc   v dpmirt_sample()   |-- runMCMC()          --> samples (niter x params), samples2 (niter x N)   v dpmirt_rescale()   |-- .rescale_rasch()   or .rescale_irt() or .rescale_si()   |-- theta_samp, beta_samp, lambda_samp (all rescaled)   v dpmirt_fit object   |-- theta_samp, beta_samp, ...   |-- ess, waic, loglik_trace   |-- cluster_info (DPM only)   |-- dp_density (DPM only, optional)"},{"path":"https://joonho112.github.io/DPMirt/articles/nimble-internals.html","id":"initial-values-k-means-strategy","dir":"Articles","previous_headings":"MCMC Pipeline Internals","what":"Initial Values: K-means Strategy","title":"Under the Hood: NIMBLE Backend and Advanced Usage","text":"DPMirt uses k-means clustering strategy (following Paganin et al.) initializing DPM cluster assignments: Compute standardized sum scores person. Run k-means k=min⁡(5,⌊N/4⌋)k = \\min(5, \\lfloor N/4 \\rfloor) clusters. Use cluster assignments initial values zi[1:N]. provides reasonable starting point reduces burn-needed CRP find good configuration.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/nimble-internals.html","id":"monitor-thinning","dir":"Articles","previous_headings":"MCMC Pipeline Internals","what":"Monitor Thinning","title":"Under the Hood: NIMBLE Backend and Advanced Usage","text":"DPMirt supports differential thinning: monitors (beta, lambda, alpha, zi, muTilde, s2Tilde, logprob): Thinned rate thin (default 1 = every iteration). monitors2 (eta/theta): Thinned rate thin2 (default = thin). Since theta NN dimensions (one per person), can dominate memory large samples. Setting thin2 > thin reduces storage:","code":"# Thin theta more aggressively than item parameters fit <- dpmirt(   data,   model = \"rasch\",   prior = \"dpm\",   niter = 20000,   thin  = 1,     # Keep every iteration for items   thin2 = 5      # Keep every 5th iteration for theta )"},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/articles/nimble-internals.html","id":"writing-a-custom-sampler","dir":"Articles","previous_headings":"Extending DPMirt","what":"Writing a Custom Sampler","title":"Under the Hood: NIMBLE Backend and Advanced Usage","text":"replace supplement DPMirt’s default samplers:","code":"# Example: Block sampler for all item difficulties my_block_beta_config <- function(conf, model, spec) {   I <- spec$config$I    # Remove individual beta samplers   for (i in seq_len(I)) {     conf$removeSamplers(paste0(\"beta[\", i, \"]\"))   }    # Add a single block (AF_slice) sampler   conf$addSampler(     target = paste0(\"beta[1:\", I, \"]\"),     type   = \"AF_slice\"   )    conf }  compiled <- dpmirt_compile(spec, sampler_config = my_block_beta_config)"},{"path":"https://joonho112.github.io/DPMirt/articles/nimble-internals.html","id":"adding-a-new-model","dir":"Articles","previous_headings":"Extending DPMirt","what":"Adding a New Model","title":"Under the Hood: NIMBLE Backend and Advanced Usage","text":"add new model type (e.g., multidimensional IRT model), : Add new code builder function R/model_spec.R (e.g., .build_mirt_code()). Register .build_nimble_code() dispatcher. Update .generate_inits() new parameter structure. Update .setup_monitors() new parameters. Add rescaling logic R/rescale.R needed.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/nimble-internals.html","id":"extracting-raw-nimble-objects","dir":"Articles","previous_headings":"Extending DPMirt","what":"Extracting Raw NIMBLE Objects","title":"Under the Hood: NIMBLE Backend and Advanced Usage","text":"maximum flexibility, can extract underlying NIMBLE objects dpmirt_compiled object:","code":"# Get the compiled model Cmodel <- compiled$Cmodel  # Query model structure Cmodel$getNodeNames() Cmodel$getDependencies(\"beta[1]\") Cmodel$getLogProb(\"beta\")  # Get the compiled MCMC Cmcmc <- compiled$Cmcmc  # Run MCMC manually Cmcmc$run(5000, reset = TRUE)  # Extract samples directly samples <- as.matrix(Cmcmc$mvSamples) samples2 <- as.matrix(Cmcmc$mvSamples2)"},{"path":[]},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/articles/nimble-internals.html","id":"checking-sampler-configuration","dir":"Articles","previous_headings":"Troubleshooting","what":"Checking Sampler Configuration","title":"Under the Hood: NIMBLE Backend and Advanced Usage","text":"","code":"# After compilation, inspect what samplers are assigned compiled$mcmc_conf$printSamplers()  # Count samplers by type sampler_types <- sapply(   seq_len(length(compiled$mcmc_conf$getSamplers())),   function(i) compiled$mcmc_conf$getSamplers()[[i]]$name ) table(sampler_types)"},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/articles/nimble-internals.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Under the Hood: NIMBLE Backend and Advanced Usage","text":"de Valpine, P., Turek, D., Paciorek, C. J., Anderson-Bergman, C., Lang, D. T., & Bodik, R. (2017). Programming models: Writing statistical algorithms general model structures NIMBLE. Journal Computational Graphical Statistics, 26(2), 403–413. Paganin, S., Paciorek, C. J., Wehrhahn, C., Rodríguez, ., Rabe-Hesketh, S., & de Valpine, P. (2023). Computational strategies estimation performance Bayesian semiparametric item response theory models. Journal Educational Behavioral Statistics, 48(2), 147–188. https://doi.org/10.3102/10769986221136105 NIMBLE Development Team. (2024). NIMBLE: MCMC, particle filtering, programmable hierarchical modeling. R package version 1.2.1. https://r-nimble.org","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/posterior-summaries.html","id":"overview","dir":"Articles","previous_headings":"","what":"1. Overview","title":"Posterior Summary Methods: Matching Estimators to Inferential Goals","text":"Bayesian IRT model delivers full posterior distribution every person parameter θp\\theta_p. Collapsing posterior single point estimate unavoidable operational decisions – point estimate report? answer depends plan numbers. vignette introduces three posterior summary methods shipped DPMirt — posterior mean (PM), constrained Bayes (CB), triple-goal (GR) — shows match one inferential goal hand. discussion tracks framework developed Lee & Wind (APM manuscript) foundational theory Louis (1984), Ghosh (1992), Shen & Louis (1998). Key take-away. single set point estimates simultaneously minimises three loss functions. Choosing estimator choosing loss function; choosing loss function choosing inferential goal.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/posterior-summaries.html","id":"three-inferential-goals","dir":"Articles","previous_headings":"","what":"2. Three Inferential Goals","title":"Posterior Summary Methods: Matching Estimators to Inferential Goals","text":"Bayesian decision theory tells us optimal point estimate minimises expected posterior loss. Different loss functions lead different estimators. table maps three common inferential goals criterion-based assessment (CBA) loss function implies estimator minimises . Three inferential goals optimal posterior summaries.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/posterior-summaries.html","id":"a-concrete-cba-scenario","dir":"Articles","previous_headings":"2. Three Inferential Goals","what":"A concrete CBA scenario","title":"Posterior Summary Methods: Matching Estimators to Inferential Goals","text":"Consider universal screening programme 200 elementary students complete 25-item mathematics assessment. school psychologist might ask three distinct questions data: Individual scoring. “Student 47’s latent ability?” – Report PM estimate credible interval. Ranking. “five students fall bottom 5% need Tier 2 support?” – Report GR estimates select five lowest. Distribution recovery. “proportion cohort falls state proficiency cutoff t=−0.5t = -0.5?” – Compute empirical distribution GR estimates evaluate ĜN(−0.5)\\hat{G}_N(-0.5). question calls different estimator. Using PM three preserves ranking, distribution-level summary distorted shrinkage. “single set point estimates simultaneously minimises three loss functions.” — Lee & Wind (APM manuscript)","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/articles/posterior-summaries.html","id":"why-posterior-means-compress-the-distribution","dir":"Articles","previous_headings":"3. The Shrinkage Problem","what":"Why posterior means compress the distribution","title":"Posterior Summary Methods: Matching Estimators to Inferential Goals","text":"posterior mean person pp exchangeable hierarchical model can written weighted combination likelihood-based estimate prior mean: θ̂pPM=wpθ̂pML+(1−wp)μθ \\hat{\\theta}_p^{\\text{PM}} \\;=\\; w_p\\,\\hat{\\theta}_p^{\\text{ML}}   \\;+\\; (1 - w_p)\\,\\mu_\\theta shrinkage weight wp=σθ2σθ2+se(θ̂p)2. w_p \\;=\\; \\frac{\\sigma^2_\\theta}{\\sigma^2_\\theta + \\text{se}(\\hat{\\theta}_p)^2}. every person, 0<wp<10 < w_p < 1, PM estimate pulled toward grand mean. direct consequence variance PM estimates smaller variance true abilities: Var(θ̂PM)<Var(θ). \\text{Var}(\\hat{\\theta}^{\\text{PM}}) \\;<\\; \\text{Var}(\\theta). -dispersion feature goal individual-level accuracy (Goal 1), reduces mean squared error. liability Goals 2 3: empirical distribution PM estimates narrow, tail probabilities systematically mis-estimated extreme ranks compressed toward centre.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/posterior-summaries.html","id":"visualising-shrinkage","dir":"Articles","previous_headings":"3. The Shrinkage Problem","what":"Visualising shrinkage","title":"Posterior Summary Methods: Matching Estimators to Inferential Goals","text":"figure loads pre-computed bimodal simulation (N=200N = 200, 25 items, Rasch). true density two modes; PM fills valley. PM (red) compresses distribution. CB (blue) GR (green) progressively de-shrink estimates, GR tracking true density closely. look . PM (red) compressed: valley two modes partially filled tails thin. CB (blue) widens distribution matching first two moments, restoring much true spread. GR (green) tracks true density (gray) closely, preserving modes valley . pre-computed data installed, figure render. See vignette(\"simulation-study\") generation instructions.","code":"comp <- readRDS(find_extdata(\"vignette_estimates_comparison.rds\"))  N <- length(comp$true_theta) df_shrink <- data.frame(   value = c(comp$true_theta,             comp$dpm$theta$theta_pm,             comp$dpm$theta$theta_cb,             comp$dpm$theta$theta_gr),   Method = factor(rep(c(\"True\", \"PM\", \"CB\", \"GR\"), each = N),                   levels = c(\"True\", \"PM\", \"CB\", \"GR\")) )  ggplot(df_shrink, aes(x = value, colour = Method, fill = Method)) +   geom_density(alpha = 0.15, linewidth = 0.9) +   scale_colour_manual(values = c(True = unname(palette_dpmirt[\"true\"]),                                   PM   = unname(palette_dpmirt[\"pm\"]),                                   CB   = unname(palette_dpmirt[\"cb\"]),                                   GR   = unname(palette_dpmirt[\"gr\"]))) +   scale_fill_manual(values = c(True = unname(palette_dpmirt[\"true\"]),                                 PM   = unname(palette_dpmirt[\"pm\"]),                                 CB   = unname(palette_dpmirt[\"cb\"]),                                 GR   = unname(palette_dpmirt[\"gr\"]))) +   labs(title = \"Shrinkage and de-shrinkage under a DPM prior\",        subtitle = \"Bimodal population, 25 items, 200 persons\",        x = expression(theta), y = \"Density\") +   theme_bw() +   theme(legend.position = \"top\")"},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/articles/posterior-summaries.html","id":"definition","dir":"Articles","previous_headings":"4. Posterior Mean (PM) Estimator","what":"Definition","title":"Posterior Summary Methods: Matching Estimators to Inferential Goals","text":"posterior mean person pp simply average SS retained MCMC draws: θ̂pPM=1S∑s=1Sθp(s). \\hat{\\theta}_p^{\\text{PM}}   \\;=\\; \\frac{1}{S}\\sum_{s=1}^{S}\\theta_p^{(s)}. squared-error loss Bayes-optimal point estimate. DPMirt returns theta_pm whenever call dpmirt_estimates().","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/posterior-summaries.html","id":"code","dir":"Articles","previous_headings":"4. Posterior Mean (PM) Estimator","what":"Code","title":"Posterior Summary Methods: Matching Estimators to Inferential Goals","text":"","code":"# Compute only the posterior mean est <- dpmirt_estimates(fit, methods = \"pm\")  # Inspect first few values head(est$theta[, c(\"theta_pm\", \"theta_psd\")])"},{"path":"https://joonho112.github.io/DPMirt/articles/posterior-summaries.html","id":"when-to-use-pm","dir":"Articles","previous_headings":"4. Posterior Mean (PM) Estimator","what":"When to use PM","title":"Posterior Summary Methods: Matching Estimators to Inferential Goals","text":"PM safest default consumer scores interpret one person time.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/articles/posterior-summaries.html","id":"idea","dir":"Articles","previous_headings":"5. Constrained Bayes (CB) Estimator","what":"Idea","title":"Posterior Summary Methods: Matching Estimators to Inferential Goals","text":"Ghosh (1992) proposed simple moment-matching correction: rescale PM estimates first two moments match marginal empirical distribution. removes systematic -dispersion caused shrinkage retaining Bayesian ranking.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/posterior-summaries.html","id":"formula","dir":"Articles","previous_headings":"5. Constrained Bayes (CB) Estimator","what":"Formula","title":"Posterior Summary Methods: Matching Estimators to Inferential Goals","text":"Let η‾=1N∑pθ̂pPM\\bar\\eta = \\frac{1}{N}\\sum_p \\hat{\\theta}_p^{\\text{PM}} grand mean PMs, Vη=Var(θ̂PM)V_\\eta = \\text{Var}(\\hat{\\theta}^{\\text{PM}}) variance, λ‾=1N∑pVar(θp∣data)\\bar\\lambda = \\frac{1}{N}\\sum_p \\text{Var}(\\theta_p \\mid \\text{data}) average posterior variance. θ̂pCB=η‾+(θ̂pPM−η‾)1+λ‾Vη. \\hat{\\theta}_p^{\\text{CB}}   \\;=\\; \\bar\\eta   \\;+\\; (\\hat{\\theta}_p^{\\text{PM}} - \\bar\\eta)         \\sqrt{1 + \\frac{\\bar\\lambda}{V_\\eta}}. two constraints : Mean preservation: 1N∑pθ̂pCB=η‾\\frac{1}{N}\\sum_p \\hat{\\theta}_p^{\\text{CB}} = \\bar\\eta (grand mean PM). Variance inflation: Var(θ̂CB)=Vη+λ‾\\text{Var}(\\hat{\\theta}^{\\text{CB}}) = V_\\eta + \\bar\\lambda (restores marginal variance). correction factor 1+λ‾/Vη\\sqrt{1 + \\bar\\lambda / V_\\eta} always ≥1\\geq 1: CB estimates always least dispersed PM estimates.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/posterior-summaries.html","id":"code-1","dir":"Articles","previous_headings":"5. Constrained Bayes (CB) Estimator","what":"Code","title":"Posterior Summary Methods: Matching Estimators to Inferential Goals","text":"","code":"# Compute PM and CB est <- dpmirt_estimates(fit, methods = c(\"pm\", \"cb\"))  # CB estimates alongside PM head(est$theta[, c(\"theta_pm\", \"theta_cb\")])"},{"path":"https://joonho112.github.io/DPMirt/articles/posterior-summaries.html","id":"quality-flags","dir":"Articles","previous_headings":"5. Constrained Bayes (CB) Estimator","what":"Quality flags","title":"Posterior Summary Methods: Matching Estimators to Inferential Goals","text":"posterior means near-zero variance (e.g., short test extremely strong prior), CB scaling factor can become numerically unstable. DPMirt detects falls back PM: est$quality_flags$cb_fallback TRUE. scaling factor 5 triggers warning stored est$quality_flags$cb_extreme_factor.","code":"# Check quality flags est$quality_flags$cb_fallback est$quality_flags$cb_extreme_factor"},{"path":"https://joonho112.github.io/DPMirt/articles/posterior-summaries.html","id":"limitations","dir":"Articles","previous_headings":"5. Constrained Bayes (CB) Estimator","what":"Limitations","title":"Posterior Summary Methods: Matching Estimators to Inferential Goals","text":"CB derived assumption exchangeable Gaussian prior. true latent distribution strongly multimodal, rescaling first two moments alone recover shape. multimodal distributions, GR generally outperforms CB ranking EDF estimation.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/articles/posterior-summaries.html","id":"idea-1","dir":"Articles","previous_headings":"6. Triple-Goal (GR) Estimator","what":"Idea","title":"Posterior Summary Methods: Matching Estimators to Inferential Goals","text":"Shen & Louis (1998) designed estimator simultaneously optimises three properties: preserves Bayesian rankings, matches empirical distribution function, remains close posterior means. DPMirt estimator labeled “GR” two key ingredients: estimated G function (EDF latent trait) posterior mean Ranks.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/posterior-summaries.html","id":"algorithm-four-steps","dir":"Articles","previous_headings":"6. Triple-Goal (GR) Estimator","what":"Algorithm (four steps)","title":"Posterior Summary Methods: Matching Estimators to Inferential Goals","text":"full triple-goal algorithm proceeds follows: Step 1. Posterior mean ranks. MCMC iteration ss, rank NN persons θp(s)\\theta_p^{(s)} values. Average across iterations obtain posterior mean rank: R‾p=1S∑s=1SRp(s)=∑q=1NP(θq≤θp∣data). \\bar{R}_p \\;=\\; \\frac{1}{S}\\sum_{s=1}^{S} R_p^{(s)}   \\;=\\; \\sum_{q=1}^{N} P(\\theta_q \\le \\theta_p \\mid \\text{data}). Step 2. Integer ranks. Convert fractional posterior mean ranks integer ranks ranking : R̂p=rank(R‾p). \\hat{R}_p \\;=\\; \\text{rank}(\\bar{R}_p). Step 3. ISEL EDF. integrated squared error loss (ISEL) estimator latent EDF pools posterior samples: ĜN(t)=1N∑p=1NP(θp≤t∣data). \\hat{G}_N(t) \\;=\\; \\frac{1}{N}\\sum_{p=1}^{N}   P(\\theta_p \\le t \\mid \\text{data}). practice ECDF N×SN \\times S pooled draws. Step 4. Quantile placement. person’s GR estimate quantile ĜN\\hat{G}_N corresponds integer rank: θ̂pGR=ĜN−1(2R̂p−12N). \\hat{\\theta}_p^{\\text{GR}} \\;=\\; \\hat{G}_N^{-1}   \\!\\left(\\frac{2\\hat{R}_p - 1}{2N}\\right).","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/posterior-summaries.html","id":"intuition","dir":"Articles","previous_headings":"6. Triple-Goal (GR) Estimator","what":"Intuition","title":"Posterior Summary Methods: Matching Estimators to Inferential Goals","text":"GR estimator places one estimate NN equally spaced quantiles estimated latent distribution. ranking step determines quantile person occupies; quantile step determines location estimate θ\\theta scale. quantile grid spans full estimated distribution, GR estimates reproduce shape — modes, tails, gaps represented faithfully.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/posterior-summaries.html","id":"code-2","dir":"Articles","previous_headings":"6. Triple-Goal (GR) Estimator","what":"Code","title":"Posterior Summary Methods: Matching Estimators to Inferential Goals","text":"","code":"# Compute all three estimators est <- dpmirt_estimates(fit, methods = c(\"pm\", \"cb\", \"gr\"))  # GR estimates with posterior mean ranks head(est$theta[, c(\"theta_pm\", \"theta_gr\", \"rbar\", \"rhat\")])"},{"path":"https://joonho112.github.io/DPMirt/articles/posterior-summaries.html","id":"quality-flags-ties","dir":"Articles","previous_headings":"6. Triple-Goal (GR) Estimator","what":"Quality flags: ties","title":"Posterior Summary Methods: Matching Estimators to Inferential Goals","text":"DPMirt breaks ties posterior mean ranks randomly default. Pass stop_if_ties = TRUE raise error instead: Ties unusual continuous posteriors; occur typically signals low test information subset persons.","code":"est <- dpmirt_estimates(fit, methods = \"gr\", stop_if_ties = TRUE)"},{"path":"https://joonho112.github.io/DPMirt/articles/posterior-summaries.html","id":"side-by-side-comparison","dir":"Articles","previous_headings":"","what":"7. Side-by-Side Comparison","title":"Posterior Summary Methods: Matching Estimators to Inferential Goals","text":"section loads pre-computed estimates object produces four complementary views.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/posterior-summaries.html","id":"density-overlay","dir":"Articles","previous_headings":"7. Side-by-Side Comparison","what":"7.1 Density overlay","title":"Posterior Summary Methods: Matching Estimators to Inferential Goals","text":"look . PM (red) compressed. CB (blue) widens distribution may recover multimodal shape. GR (green) tracks true density (grey) closely, reproducing modes valley .","code":"# Build long-format data for ggplot df_dens <- data.frame(   value = c(comp$true_theta,             comp$dpm$theta$theta_pm,             comp$dpm$theta$theta_cb,             comp$dpm$theta$theta_gr),   method = rep(c(\"True\", \"PM\", \"CB\", \"GR\"),                each = length(comp$true_theta)) ) df_dens$method <- factor(df_dens$method,                           levels = c(\"True\", \"PM\", \"CB\", \"GR\"))  ggplot(df_dens, aes(x = value, colour = method, fill = method)) +   geom_density(alpha = 0.12, linewidth = 0.9) +   scale_colour_manual(values = c(True = palette_dpmirt[\"true\"],                                   PM   = palette_dpmirt[\"pm\"],                                   CB   = palette_dpmirt[\"cb\"],                                   GR   = palette_dpmirt[\"gr\"])) +   scale_fill_manual(values = c(True = palette_dpmirt[\"true\"],                                 PM   = palette_dpmirt[\"pm\"],                                 CB   = palette_dpmirt[\"cb\"],                                 GR   = palette_dpmirt[\"gr\"])) +   labs(title = \"True vs. PM vs. CB vs. GR densities\",        x = expression(theta), y = \"Density\",        colour = \"Method\", fill = \"Method\") +   theme_bw() +   theme(legend.position = \"top\") #> Warning: No shared levels found between `names(values)` of the manual scale and the #> data's colour values. #> Warning: No shared levels found between `names(values)` of the manual scale and the #> data's fill values. #> Warning: No shared levels found between `names(values)` of the manual scale and the #> data's colour values. #> Warning: No shared levels found between `names(values)` of the manual scale and the #> data's fill values."},{"path":"https://joonho112.github.io/DPMirt/articles/posterior-summaries.html","id":"caterpillar-plot","dir":"Articles","previous_headings":"7. Side-by-Side Comparison","what":"7.2 Caterpillar plot","title":"Posterior Summary Methods: Matching Estimators to Inferential Goals","text":"dpmirt_estimates object available, built-plot() method produces caterpillar plot three estimators overlaid. Persons sorted PM. CB GR deviate tails.","code":"# Built-in caterpillar plot plot(est, type = \"estimates\", param = \"theta\")"},{"path":"https://joonho112.github.io/DPMirt/articles/posterior-summaries.html","id":"rank-scatter","dir":"Articles","previous_headings":"7. Side-by-Side Comparison","what":"7.3 Rank scatter","title":"Posterior Summary Methods: Matching Estimators to Inferential Goals","text":"Rank agreement typically high interior. Discrepancies concentrate tails — precisely students targeted classification decisions.","code":"df_rank <- data.frame(   rank_pm = rank(comp$dpm$theta$theta_pm),   rank_gr = rank(comp$dpm$theta$theta_gr) )  ggplot(df_rank, aes(x = rank_pm, y = rank_gr)) +   geom_point(alpha = 0.5, size = 1.5, colour = palette_dpmirt[\"dpm\"]) +   geom_abline(intercept = 0, slope = 1, linetype = \"dashed\",               colour = \"grey50\") +   labs(title = \"Rank agreement: PM vs. GR\",        x = \"Rank (PM)\", y = \"Rank (GR)\") +   theme_bw()"},{"path":"https://joonho112.github.io/DPMirt/articles/posterior-summaries.html","id":"table-of-first-10-persons","dir":"Articles","previous_headings":"7. Side-by-Side Comparison","what":"7.4 Table of first 10 persons","title":"Posterior Summary Methods: Matching Estimators to Inferential Goals","text":"Estimates ranks first 10 persons.","code":"tab10 <- data.frame(   Person   = 1:10,   True     = round(comp$true_theta[1:10], 3),   PM       = round(comp$dpm$theta$theta_pm[1:10], 3),   CB       = round(comp$dpm$theta$theta_cb[1:10], 3),   GR       = round(comp$dpm$theta$theta_gr[1:10], 3),   PM_rank  = rank(-comp$dpm$theta$theta_pm)[1:10],   GR_rank  = rank(-comp$dpm$theta$theta_gr)[1:10] ) knitr::kable(tab10, caption = \"Estimates and ranks for the first 10 persons.\")"},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/articles/posterior-summaries.html","id":"reliability-as-the-dominant-moderator","dir":"Articles","previous_headings":"8. The Role of Test Reliability","what":"Reliability as the dominant moderator","title":"Posterior Summary Methods: Matching Estimators to Inferential Goals","text":"simulation studies Lee & Wind show average test reliability w‾\\bar{w} — sample size NN — dominant moderator estimator performance. Reliability determines much shrinkage occurs therefore much room estimator choice (prior choice) make difference. average shrinkage weight w‾\\bar{w} related classical marginal reliability ρ\\rho w‾≈ρ\\bar{w} \\approx \\rho long tests Rasch model. rough mapping reliability test length : Reliability determines whether estimator choice prior choice influence recovery.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/posterior-summaries.html","id":"practical-implications","dir":"Articles","previous_headings":"8. The Role of Test Reliability","what":"Practical implications","title":"Posterior Summary Methods: Matching Estimators to Inferential Goals","text":"Low reliability (w‾≈0.50\\bar{w} \\approx 0.50): Shrinkage dominates. CB provides largest EDF gains; model flexibility matters less posteriors concentrate around prior regardless. Moderate reliability (w‾≈0.70\\bar{w} \\approx 0.70): estimator prior contribute meaningfully. DPM + GR starts outperform Normal + GR non-normal populations. screening instruments (20–30 items) fall regime. High reliability (w‾≈0.90\\bar{w} \\approx 0.90): three estimators converge. Prior choice (DPM vs. Normal) becomes primary driver EDF ranking accuracy non-normal distributions. Rule thumb. short test non-normal population, start CB. long test suspect non-normality, invest DPM prior use GR.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/posterior-summaries.html","id":"visualizing-the-reliability-effect","dir":"Articles","previous_headings":"8. The Role of Test Reliability","what":"Visualizing the reliability effect","title":"Posterior Summary Methods: Matching Estimators to Inferential Goals","text":"figure makes abstract table concrete. panels show bimodal population estimated DPM prior, left panel uses 10-item test (w‾≈0.5\\bar{w} \\approx 0.5) right uses 25-item test (w‾≈0.8\\bar{w} \\approx 0.8). Effect reliability estimator behavior. Left (ρ≈0.5\\rho \\approx 0.5, 10 items): PM (red) collapses bimodal distribution sharp unimodal peak — two modes completely lost. CB (blue) GR (green) resist compression, preserving two-group structure even severe shrinkage. Right (ρ≈0.8\\rho \\approx 0.8, 25 items): three estimators begin recover true bimodal shape, GR tracking truth closely. low reliability (left panel), posterior person heavily shrunk toward prior center, PM distribution collapses narrow unimodal peak. CB GR resist compression inflating variance (CB) placing estimates quantiles estimated EDF (GR), preserving two-group structure. high reliability (right panel), data speak loudly enough even PM preserves bimodal shape. three estimators converge, primary gains come using DPM prior rather Normal prior (see Section 5.4 vignette(\"models--workflow\")).","code":"# Load both reliability conditions comp_hi  <- readRDS(find_extdata(\"vignette_estimates_comparison.rds\")) comp_lo  <- readRDS(find_extdata(\"vignette_estimates_comparison_lowrel.rds\"))  build_panel <- function(comp_obj, label) {   N <- length(comp_obj$true_theta)   data.frame(     value = c(comp_obj$true_theta,               comp_obj$dpm$theta$theta_pm,               comp_obj$dpm$theta$theta_cb,               comp_obj$dpm$theta$theta_gr),     Method = factor(rep(c(\"True\", \"PM\", \"CB\", \"GR\"), each = N),                     levels = c(\"True\", \"PM\", \"CB\", \"GR\")),     Reliability = label   ) }  df_rel <- rbind(   build_panel(comp_lo, \"\\u03C1 \\u2248 0.5  (10 items)\"),   build_panel(comp_hi, \"\\u03C1 \\u2248 0.8  (25 items)\") ) df_rel$Reliability <- factor(df_rel$Reliability,   levels = c(\"\\u03C1 \\u2248 0.5  (10 items)\",              \"\\u03C1 \\u2248 0.8  (25 items)\"))  ggplot(df_rel, aes(x = value, colour = Method, fill = Method)) +   geom_density(alpha = 0.15, linewidth = 0.9) +   facet_wrap(~ Reliability, ncol = 2) +   scale_colour_manual(values = c(True = unname(palette_dpmirt[\"true\"]),                                   PM   = unname(palette_dpmirt[\"pm\"]),                                   CB   = unname(palette_dpmirt[\"cb\"]),                                   GR   = unname(palette_dpmirt[\"gr\"]))) +   scale_fill_manual(values = c(True = unname(palette_dpmirt[\"true\"]),                                 PM   = unname(palette_dpmirt[\"pm\"]),                                 CB   = unname(palette_dpmirt[\"cb\"]),                                 GR   = unname(palette_dpmirt[\"gr\"]))) +   labs(title = \"Reliability determines when estimator choice matters\",        x = expression(theta), y = \"Density\") +   theme_bw() +   theme(legend.position = \"top\",         strip.text = element_text(face = \"bold\", size = 11))"},{"path":"https://joonho112.github.io/DPMirt/articles/posterior-summaries.html","id":"quantifying-the-shrinkage","dir":"Articles","previous_headings":"8. The Role of Test Reliability","what":"Quantifying the shrinkage","title":"Posterior Summary Methods: Matching Estimators to Inferential Goals","text":"table makes shrinkage problem concrete numbers, comparing standard deviation estimator true SD. Dispersion estimates relative truth. low reliability, PM retains ~50% true SD; CB GR recover ~80-95%. Reading table. “Ratio” rows reveal shrinkage severity. ρ≈0.5\\rho \\approx 0.5, PM compresses distribution roughly half true spread (ratio ≈0.50\\approx 0.50). CB GR partially resist compression, recovering 70% true SD (ratio ≈0.70\\approx 0.70). ρ≈0.8\\rho \\approx 0.8, three estimators converge toward — even slightly exceed — true dispersion (ratios near 1.0), confirming reliability dominant moderator shrinkage severity.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/posterior-summaries.html","id":"practical-recommendations","dir":"Articles","previous_headings":"","what":"9. Practical Recommendations","title":"Posterior Summary Methods: Matching Estimators to Inferential Goals","text":"table summarises estimator-prior pairings common operational goals. Quick-reference guide: estimator prior goal.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/posterior-summaries.html","id":"decision-workflow","dir":"Articles","previous_headings":"9. Practical Recommendations","what":"Decision workflow","title":"Posterior Summary Methods: Matching Estimators to Inferential Goals","text":"simple three-step workflow: 1. Determine primary goal. scores used ? individual feedback, use PM. classification, ranking, distributional summaries, use GR. 2. Assess reliability. Estimate w‾\\bar{w} KR-20 model’s average posterior variance. w‾<0.65\\bar{w} < 0.65, estimator choice dominates; w‾>0.80\\bar{w} > 0.80, prior choice dominates. 3. Choose prior. reliability high reason doubt normality (e.g., known floor/ceiling effects, gifted subpopulations, mixed curricula), use DPM prior. Otherwise Normal prior sufficient.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/posterior-summaries.html","id":"loss-functions-for-evaluation","dir":"Articles","previous_headings":"","what":"10. Loss Functions for Evaluation","title":"Posterior Summary Methods: Matching Estimators to Inferential Goals","text":"true parameter values available (e.g., simulation study), dpmirt_loss() computes three loss functions correspond three goals.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/posterior-summaries.html","id":"built-in-loss-functions","dir":"Articles","previous_headings":"10. Loss Functions for Evaluation","what":"Built-in loss functions","title":"Posterior Summary Methods: Matching Estimators to Inferential Goals","text":"Loss function results (DPM prior, bimodal population, 25 items, rho=0.8). PM wins MSEL; GR wins MSELR KS. pattern typical: MSEL: PM << GR << CB — posterior mean minimises individual MSE construction. MSELR: GR << PM ≈\\approx CB — triple-goal algorithm directly optimises ranking loss. KS: GR << CB << PM — GR CB reduce distributional bias, GR achieving tightest fit. reliability drops, loss differences across estimators become pronounced: Loss comparison across reliability levels. low reliability, estimator differences amplified — especially KS, GR achieves much tighter fit PM.","code":"# Assume 'fit' was run on simulated data with known true values est  <- dpmirt_estimates(fit, methods = c(\"pm\", \"cb\", \"gr\")) loss <- dpmirt_loss(est, true_theta = sim$theta, true_beta = sim$beta) print(loss)"},{"path":"https://joonho112.github.io/DPMirt/articles/posterior-summaries.html","id":"custom-loss-functions","dir":"Articles","previous_headings":"10. Loss Functions for Evaluation","what":"Custom loss functions","title":"Posterior Summary Methods: Matching Estimators to Inferential Goals","text":"Supply arbitrary loss function via custom_loss. function must accept two numeric vectors return scalar. See vignette(\"simulation-study\") full factorial comparison loss across reliability levels, sample sizes, latent shapes, priors.","code":"# Mean absolute error mae_loss <- function(est, true) mean(abs(est - true))  loss_mae <- dpmirt_loss(   est,   true_theta  = sim$theta,   true_beta   = sim$beta,   custom_loss = mae_loss ) print(loss_mae)"},{"path":"https://joonho112.github.io/DPMirt/articles/posterior-summaries.html","id":"summary-and-next-steps","dir":"Articles","previous_headings":"","what":"11. Summary and Next Steps","title":"Posterior Summary Methods: Matching Estimators to Inferential Goals","text":"vignette shown : posterior mean (PM) optimal inferential goal individual-level accuracy (Goal 1: minimise MSEL). constrained Bayes (CB) estimator corrects -dispersion PM matching first two moments marginal distribution. helpful reliability low simple correction suffices. triple-goal (GR) estimator simultaneously optimises ranking distribution recovery (Goals 2 3). recommended estimator whenever classification, selection, distributional summaries primary output. Test reliability w‾\\bar{w}, sample size, dominant moderator estimator performance. Short tests benefit estimator choice; long tests benefit prior choice (DPM vs. Normal).","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/posterior-summaries.html","id":"what-next","dir":"Articles","previous_headings":"11. Summary and Next Steps","what":"What next?","title":"Posterior Summary Methods: Matching Estimators to Inferential Goals","text":"Simulation study. See vignette(\"simulation-study\") full factorial evaluation prior ×\\times estimator ×\\times reliability ×\\times latent shape. Prior elicitation. See vignette(\"prior-elicitation\") principled selection DPM concentration parameter α\\alpha using DPprior package. Getting started. yet fit first model, see vignette(\"getting-started\") basic DPMirt workflow.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/posterior-summaries.html","id":"references","dir":"Articles","previous_headings":"11. Summary and Next Steps","what":"References","title":"Posterior Summary Methods: Matching Estimators to Inferential Goals","text":"Ghosh, M. (1992). Constrained Bayes estimation applications. Journal American Statistical Association, 87(418), 533–540. Lee, J. & Wind, S. Targeting toward inferential goals Bayesian Rasch models estimating person-specific latent traits. OSF Preprint. https://doi.org/10.31219/osf.io/qrw4n Louis, T. . (1984). Estimating population parameter values using Bayes empirical Bayes methods. Journal American Statistical Association, 79(386), 393–398. Paganin, S., Paciorek, C. J., Wehrhahn, C., Rodríguez, ., Rabe-Hesketh, S., & de Valpine, P. (2023). Computational strategies estimation performance Bayesian semiparametric item response theory models. Journal Educational Behavioral Statistics, 48(2), 147–188. https://doi.org/10.3102/10769986221136105 Shen, W., & Louis, T. . (1998). Triple-goal estimates two-stage hierarchical models. Journal Royal Statistical Society: Series B, 60(2), 455–471.","code":"#> R version 4.5.1 (2025-06-13) #> Platform: aarch64-apple-darwin20 #> Running under: macOS Tahoe 26.2 #>  #> Matrix products: default #> BLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib  #> LAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1 #>  #> locale: #> [1] C.UTF-8/C.UTF-8/C.UTF-8/C/C.UTF-8/C.UTF-8 #>  #> time zone: America/Chicago #> tzcode source: internal #>  #> attached base packages: #> [1] stats     graphics  grDevices utils     datasets  methods   base      #>  #> other attached packages: #> [1] ggplot2_4.0.2 DPMirt_0.1.0  #>  #> loaded via a namespace (and not attached): #>  [1] gtable_0.3.6        jsonlite_2.0.0      dplyr_1.2.0         #>  [4] compiler_4.5.1      tidyselect_1.2.1    parallel_4.5.1      #>  [7] dichromat_2.0-0.1   jquerylib_0.1.4     systemfonts_1.3.1   #> [10] scales_1.4.0        textshaping_1.0.1   yaml_2.3.12         #> [13] fastmap_1.2.0       lattice_0.22-7      coda_0.19-4.1       #> [16] R6_2.6.1            labeling_0.4.3      generics_0.1.4      #> [19] igraph_2.2.1        nimble_1.4.0        knitr_1.50          #> [22] htmlwidgets_1.6.4   tibble_3.3.1        desc_1.4.3          #> [25] pillar_1.11.1       bslib_0.9.0         RColorBrewer_1.1-3  #> [28] rlang_1.1.7         cachem_1.1.0        xfun_0.53           #> [31] fs_1.6.6            sass_0.4.10         S7_0.2.1            #> [34] cli_3.6.5           withr_3.0.2         pkgdown_2.2.0       #> [37] magrittr_2.0.4      digest_0.6.37       grid_4.5.1          #> [40] lifecycle_1.0.5     vctrs_0.7.1         evaluate_1.0.5      #> [43] pracma_2.4.6        glue_1.8.0          farver_2.1.2        #> [46] numDeriv_2016.8-1.1 ragg_1.4.0          rmarkdown_2.30      #> [49] tools_4.5.1         pkgconfig_2.0.3     htmltools_0.5.8.1"},{"path":"https://joonho112.github.io/DPMirt/articles/prior-elicitation.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Principled Prior Elicitation for the DP Concentration Parameter","text":"Every Dirichlet Process Mixture (DPM) model contains concentration parameter α\\alpha controls much nonparametric prior deviates single parametric component. Choosing α\\alpha well just technical detail — shapes cluster formation, posterior shrinkage, balance flexibility parsimony. vignette covers: α\\alpha matters — three operational dimensions. Paganin default vs. principled elicitation — Gamma(1,3)\\text{Gamma}(1,3) adequate . DPprior integration — three routes set α\\alpha DPMirt. Two strategies Lee (2026) — DP-diffuse DP-inform. Sensitivity analysis — comparing posteriors different priors. Fallback behavior — happens DPprior installed. Custom base measure tuning — advanced hyperparameter control.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/prior-elicitation.html","id":"why-alpha-matters","dir":"Articles","previous_headings":"","what":"Why Alpha Matters","title":"Principled Prior Elicitation for the DP Concentration Parameter","text":"concentration parameter α\\alpha operates along three dimensions jointly determine behavior DP prior.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/prior-elicitation.html","id":"dimension-1-number-of-clusters","dir":"Articles","previous_headings":"Why Alpha Matters","what":"Dimension 1: Number of Clusters","title":"Principled Prior Elicitation for the DP Concentration Parameter","text":"expected number distinct clusters KK among NN observations approximately E[K∣α,N]≈αlog⁡(1+Nα). \\mathrm{E}[K \\mid \\alpha, N] \\approx \\alpha \\log\\!\\left(1 + \\frac{N}{\\alpha}\\right). Larger α\\alpha implies clusters; smaller α\\alpha concentrates posterior onto fewer groups.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/prior-elicitation.html","id":"dimension-2-weight-concentration","dir":"Articles","previous_headings":"Why Alpha Matters","what":"Dimension 2: Weight Concentration","title":"Principled Prior Elicitation for the DP Concentration Parameter","text":"first stick-breaking weight w1w_1 follows Beta(1,α)\\text{Beta}(1, \\alpha). α\\alpha small, E[w1]\\mathrm{E}[w_1] large mass captured single component. α\\alpha large, mass spreads across many components.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/prior-elicitation.html","id":"dimension-3-posterior-shrinkage","dir":"Articles","previous_headings":"Why Alpha Matters","what":"Dimension 3: Posterior Shrinkage","title":"Principled Prior Elicitation for the DP Concentration Parameter","text":"IRT, prior θ\\theta acts regularizer. DPM prior small α\\alpha shrinks person abilities toward fewer cluster centers, closely resembling parametric Normal prior. DPM prior large α\\alpha allows person retain data-driven estimate, reducing shrinkage cost higher variance. Key insight: choice α\\alpha merely tuning knob — encodes substantive belief heterogeneity latent trait distribution. Getting wrong can either mask genuine subgroups (small) fragment homogeneous population (large).","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/prior-elicitation.html","id":"paganin-default-vs--principled-elicitation","dir":"Articles","previous_headings":"","what":"Paganin Default vs. Principled Elicitation","title":"Principled Prior Elicitation for the DP Concentration Parameter","text":"Paganin et al. (2023) use α∼Gamma(1,3)\\alpha \\sim \\text{Gamma}(1, 3) default. prior mean E[α]=1/3\\mathrm{E}[\\alpha] = 1/3 concentrated near zero, strongly favoring clusters. many educational testing applications latent trait approximately unimodal, default reasonable. However, can overly restrictive : - population known heterogeneous (e.g., mixed clinical groups). - Sample size large (N>500N > 500) data can support many clusters. - research question specifically concerns subgroup detection. Lee (2026) provides principled alternative DPprior package, translates researcher’s belief expected number clusters calibrated Gamma(,b)\\text{Gamma}(, b) hyperprior. Paganin default Gamma(1, 3) prior alpha, implied E[alpha] = 0.33.","code":"alpha_grid <- seq(0, 5, length.out = 500) dens_default <- dgamma(alpha_grid, shape = 1, rate = 3)  plot(alpha_grid, dens_default, type = \"l\", lwd = 2, col = pal$reference,      xlab = expression(alpha), ylab = \"Density\",      main = expression(paste(\"Paganin default: \", alpha, \" ~ Gamma(1, 3)\"))) abline(v = 1/3, lty = 2, col = pal$reference) text(1.2, max(dens_default) * 0.8,      bquote(E[alpha] == .(round(1/3, 2))), col = pal$reference)"},{"path":"https://joonho112.github.io/DPMirt/articles/prior-elicitation.html","id":"dpprior-integration","dir":"Articles","previous_headings":"","what":"DPprior Integration","title":"Principled Prior Elicitation for the DP Concentration Parameter","text":"DPMirt offers three ways set α\\alpha prior, ranging fully automated fully manual.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/prior-elicitation.html","id":"method-1-dpmirt_alpha_prior-wrapper","dir":"Articles","previous_headings":"DPprior Integration","what":"Method 1: dpmirt_alpha_prior() Wrapper","title":"Principled Prior Elicitation for the DP Concentration Parameter","text":"simplest approach standalone elicitation function, returns named vector c(= ..., b = ...):","code":"# Expect ~5 clusters among 200 persons, medium confidence ab <- dpmirt_alpha_prior(N = 200, mu_K = 5, confidence = \"medium\") #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 60.4% exceeds 40%. #>   This may indicate unintended prior behavior (RN-07). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation. #> Alpha prior: Gamma(1.85, 2.21) [E[alpha]=0.84] ab #>        a        b  #> 1.848904 2.212652 # DPprior not installed --- showing expected output cat(\"Alpha prior: Gamma(1.60, 0.82) [E[alpha]=1.96]\\n\") cat(\"  a     b \\n\") cat(\"1.60  0.82\\n\")"},{"path":"https://joonho112.github.io/DPMirt/articles/prior-elicitation.html","id":"method-2-elicit-then-pass-to-dpmirt","dir":"Articles","previous_headings":"DPprior Integration","what":"Method 2: Elicit Then Pass to dpmirt()","title":"Principled Prior Elicitation for the DP Concentration Parameter","text":"Elicit prior first dpmirt_alpha_prior(), pass result directly alpha_prior:","code":"ab <- dpmirt_alpha_prior(N = 200, mu_K = 5, confidence = \"medium\")  fit <- dpmirt(   data,   model       = \"rasch\",   prior       = \"dpm\",   alpha_prior = ab,   niter       = 10000,   nburnin     = 2000 )"},{"path":"https://joonho112.github.io/DPMirt/articles/prior-elicitation.html","id":"method-3-manual-dpprior-workflow","dir":"Articles","previous_headings":"DPprior Integration","what":"Method 3: Manual DPprior Workflow","title":"Principled Prior Elicitation for the DP Concentration Parameter","text":"maximum control, call DPprior directly pass result:","code":"library(DPprior)  fit_prior <- DPprior_fit(J = 200, mu_K = 5, confidence = \"medium\") #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 60.4% exceeds 40%. #>   This may indicate unintended prior behavior (RN-07). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation. print(fit_prior) #> DPprior Prior Elicitation Result #> =============================================  #>  #> Gamma Hyperprior: α ~ Gamma(a = 1.8489, b = 2.2127) #>   E[α] = 0.836, SD[α] = 0.615 #>  #> Target (J = 200): #>   E[K_J]   = 5.00 #>   Var(K_J) = 10.00 #>   (from confidence = 'medium') #>  #> Achieved: #>   E[K_J] = 5.000000, Var(K_J) = 10.000000 #>   Residual = 6.79e-11 #>  #> Method: A2-MN (6 iterations) #>  #> Dominance Risk: HIGH ✘ (P(w₁>0.5) = 60%) # Pass the DPprior_fit object to dpmirt fit <- dpmirt(   data,   model       = \"rasch\",   prior       = \"dpm\",   alpha_prior = fit_prior,   niter       = 10000 )"},{"path":"https://joonho112.github.io/DPMirt/articles/prior-elicitation.html","id":"confidence-levels","dir":"Articles","previous_headings":"DPprior Integration","what":"Confidence Levels","title":"Principled Prior Elicitation for the DP Concentration Parameter","text":"confidence argument controls tightly prior concentrates around expected cluster count. maps variance implied prior KK: Confidence levels implied hyperparameters (N = 200, mu_K = 5). Interpretation: Higher confidence concentrates Gamma prior (lower CV), constraining α\\alpha thereby cluster count. Low confidence yields diffuse prior lets data determine cluster structure. three levels share prior mean α\\alpha, differing spread. Note DPprior calls analytic (closed-form fast Newton iteration) complete milliseconds — MCMC involved.","code":"conf_levels <- c(\"low\", \"medium\", \"high\") conf_results <- lapply(conf_levels, function(cl) {   fp <- DPprior_fit(J = 200, mu_K = 5, confidence = cl)   data.frame(     Confidence = cl,     a          = round(fp$a, 3),     b          = round(fp$b, 3),     E_alpha    = round(fp$a / fp$b, 3),     CV_alpha   = round(1 / sqrt(fp$a), 3),     Var_K      = round(fp$target$var_K, 2),     stringsAsFactors = FALSE   ) }) #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 64.3% exceeds 40%. #>   This may indicate unintended prior behavior (RN-07). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation. #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 60.4% exceeds 40%. #>   This may indicate unintended prior behavior (RN-07). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation. #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 58.7% exceeds 40%. #>   This may indicate unintended prior behavior (RN-07). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation. conf_table <- do.call(rbind, conf_results) knitr::kable(conf_table,              caption = \"Confidence levels and their implied hyperparameters (N = 200, mu_K = 5).\",              align = \"lccccc\")"},{"path":"https://joonho112.github.io/DPMirt/articles/prior-elicitation.html","id":"two-strategies-from-lee-2026","dir":"Articles","previous_headings":"","what":"Two Strategies from Lee (2026)","title":"Principled Prior Elicitation for the DP Concentration Parameter","text":"APM manuscript (Lee & Wind) identifies two complementary approaches specifying α\\alpha:","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/prior-elicitation.html","id":"dp-diffuse-exploratory","dir":"Articles","previous_headings":"Two Strategies from Lee (2026)","what":"DP-Diffuse (Exploratory)","title":"Principled Prior Elicitation for the DP Concentration Parameter","text":"Use little domain knowledge population heterogeneity. goal prior minimally informative yet properly calibrated sample size: strategy DPMirt uses mu_K = NULL left default.","code":"# DP-diffuse: set mu_K to log(N), low confidence N <- 200 mu_K_diffuse <- max(3, ceiling(log(N)))  # ~5 for N=200  ab_diffuse <- dpmirt_alpha_prior(N = N, mu_K = mu_K_diffuse,                                   confidence = \"low\") #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 57.2% exceeds 40%. #>   This may indicate unintended prior behavior (RN-07). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation. #> Alpha prior: Gamma(0.84, 0.74) [E[alpha]=1.14] cat(\"DP-diffuse: Gamma(\", round(ab_diffuse[\"a\"], 2), \", \",     round(ab_diffuse[\"b\"], 2), \")\\n\", sep = \"\") #> DP-diffuse: Gamma(0.84, 0.74) cat(\"  E[alpha] =\", round(ab_diffuse[\"a\"] / ab_diffuse[\"b\"], 2), \"\\n\") #>   E[alpha] = 1.14"},{"path":"https://joonho112.github.io/DPMirt/articles/prior-elicitation.html","id":"dp-inform-domain-driven","dir":"Articles","previous_headings":"Two Strategies from Lee (2026)","what":"DP-Inform (Domain-Driven)","title":"Principled Prior Elicitation for the DP Concentration Parameter","text":"Use substantive knowledge suggests specific number latent subgroups. example, assessment designed distinguish remedial, proficient, advanced learners might target μK=3\\mu_K = 3:","code":"# DP-inform: domain-driven belief of 3 subgroups, high confidence ab_inform <- dpmirt_alpha_prior(N = 200, mu_K = 3, confidence = \"high\") #> Warning: HIGH DOMINANCE RISK: P(w1 > 0.5) = 77.8% exceeds 40%. #>   This may indicate unintended prior behavior (RN-07). #>   Consider using DPprior_dual() for weight-constrained elicitation. #>   See ?DPprior_diagnostics for interpretation. #> Alpha prior: Gamma(2.88, 7.61) [E[alpha]=0.38] cat(\"DP-inform: Gamma(\", round(ab_inform[\"a\"], 2), \", \",     round(ab_inform[\"b\"], 2), \")\\n\", sep = \"\") #> DP-inform: Gamma(2.88, 7.61) cat(\"  E[alpha] =\", round(ab_inform[\"a\"] / ab_inform[\"b\"], 2), \"\\n\") #>   E[alpha] = 0.38"},{"path":"https://joonho112.github.io/DPMirt/articles/prior-elicitation.html","id":"visual-comparison","dir":"Articles","previous_headings":"Two Strategies from Lee (2026)","what":"Visual Comparison","title":"Principled Prior Elicitation for the DP Concentration Parameter","text":"Comparing DP-diffuse DP-inform alpha priors.","code":"alpha_grid <- seq(0.01, 8, length.out = 500)  dens_diffuse <- dgamma(alpha_grid, shape = ab_diffuse[\"a\"],                         rate = ab_diffuse[\"b\"]) dens_inform  <- dgamma(alpha_grid, shape = ab_inform[\"a\"],                         rate = ab_inform[\"b\"]) dens_paganin <- dgamma(alpha_grid, shape = 1, rate = 3)  plot(alpha_grid, dens_diffuse, type = \"l\", lwd = 2, col = pal$semiparametric,      xlab = expression(alpha), ylab = \"Density\",      ylim = c(0, max(c(dens_diffuse, dens_inform, dens_paganin)) * 1.1),      main = \"Alpha prior comparison\") lines(alpha_grid, dens_inform, lwd = 2, col = pal$parametric) lines(alpha_grid, dens_paganin, lwd = 2, col = pal$reference, lty = 2) legend(\"topright\",        legend = c(\"DP-diffuse (low, mu_K=5)\",                    \"DP-inform (high, mu_K=3)\",                    \"Paganin Gamma(1,3)\"),        col    = c(pal$semiparametric, pal$parametric, pal$reference),        lwd    = 2, lty = c(1, 1, 2), bty = \"n\")"},{"path":"https://joonho112.github.io/DPMirt/articles/prior-elicitation.html","id":"sensitivity-analysis","dir":"Articles","previous_headings":"","what":"Sensitivity Analysis","title":"Principled Prior Elicitation for the DP Concentration Parameter","text":"responsible Bayesian analysis examines conclusions change different prior specifications. compare posterior results three α\\alpha priors applied data. fits pre-computed. used Rasch-DPM model bimodal data set (N=200N = 200, =25I = 25):","code":"sens <- readRDS(find_extdata(\"vignette_sensitivity_fits.rds\"))  # sens contains: #   $default   - Gamma(1, 3) [Paganin default] #   $broad     - DP-diffuse #   $inform    - DP-inform"},{"path":"https://joonho112.github.io/DPMirt/articles/prior-elicitation.html","id":"posterior-density-comparison","dir":"Articles","previous_headings":"Sensitivity Analysis","what":"Posterior Density Comparison","title":"Principled Prior Elicitation for the DP Concentration Parameter","text":"Posterior mean theta densities three alpha priors. data informative, posteriors converge despite different priors.","code":"# Extract posterior mean theta for each fit est_paganin <- dpmirt_estimates(sens$default, methods = \"pm\") est_diffuse <- dpmirt_estimates(sens$broad, methods = \"pm\") est_inform  <- dpmirt_estimates(sens$inform,  methods = \"pm\")  dens_p <- density(est_paganin$theta$theta_pm) dens_d <- density(est_diffuse$theta$theta_pm) dens_i <- density(est_inform$theta$theta_pm)  xlim <- range(c(dens_p$x, dens_d$x, dens_i$x)) ylim <- c(0, max(c(dens_p$y, dens_d$y, dens_i$y)) * 1.1)  plot(dens_p, xlim = xlim, ylim = ylim, col = pal$reference, lwd = 2,      lty = 2, main = \"Posterior theta density under different alpha priors\",      xlab = expression(theta), ylab = \"Density\") lines(dens_d, col = pal$semiparametric, lwd = 2) lines(dens_i, col = pal$parametric, lwd = 2) legend(\"topright\",        legend = c(\"Paganin Gamma(1,3)\", \"DP-diffuse\", \"DP-inform\"),        col = c(pal$reference, pal$semiparametric, pal$parametric),        lwd = 2, lty = c(2, 1, 1), bty = \"n\")"},{"path":"https://joonho112.github.io/DPMirt/articles/prior-elicitation.html","id":"cluster-count-comparison","dir":"Articles","previous_headings":"Sensitivity Analysis","what":"Cluster Count Comparison","title":"Principled Prior Elicitation for the DP Concentration Parameter","text":"Sensitivity analysis: cluster counts WAIC three alpha priors. Takeaway: data moderately informative (say, w‾≥0.7\\bar{w} \\ge 0.7 N≥100N \\ge 100), posterior distributions theta tend robust choice alpha prior. main differences appear number active clusters posterior uncertainty around alpha . WAIC can help discriminate, differences often small. convergence observed reflects moderately high reliability (w‾≈0.8\\bar{w} \\approx 0.8) 25-item test. shorter tests lower reliability (w‾≈0.5\\bar{w} \\approx 0.5), alpha prior may exert stronger influence posterior data provide less information overcome prior. See vignette(\"posterior-summaries\") detailed analysis reliability moderates estimator choice prior choice.","code":"cluster_summary <- data.frame(   Prior          = c(\"Paganin Gamma(1,3)\", \"DP-diffuse\", \"DP-inform\"),   Median_K       = c(median(sens$default$cluster_info$n_clusters),                      median(sens$broad$cluster_info$n_clusters),                      median(sens$inform$cluster_info$n_clusters)),   Mean_K         = c(mean(sens$default$cluster_info$n_clusters),                      mean(sens$broad$cluster_info$n_clusters),                      mean(sens$inform$cluster_info$n_clusters)),   Posterior_alpha = c(     mean(sens$default$other_samp[, \"alpha\"]),     mean(sens$broad$other_samp[, \"alpha\"]),     mean(sens$inform$other_samp[, \"alpha\"])   ),   WAIC           = c(sens$default$waic,                      sens$broad$waic,                      sens$inform$waic) ) cluster_summary$Median_K <- round(cluster_summary$Median_K, 1) cluster_summary$Mean_K   <- round(cluster_summary$Mean_K, 1) cluster_summary$Posterior_alpha <- round(cluster_summary$Posterior_alpha, 3) cluster_summary$WAIC     <- round(cluster_summary$WAIC, 1)  knitr::kable(cluster_summary,              caption = \"Sensitivity analysis: cluster counts and WAIC under three alpha priors.\",              align = \"lcccc\")"},{"path":"https://joonho112.github.io/DPMirt/articles/prior-elicitation.html","id":"fallback-behavior","dir":"Articles","previous_headings":"","what":"Fallback Behavior","title":"Principled Prior Elicitation for the DP Concentration Parameter","text":"DPprior package installed, DPMirt falls back gracefully Paganin default informative message: design ensures DPMirt works box encouraging users install DPprior better-calibrated priors. DPprior listed Suggests, Imports, never hard dependency.","code":"# Simulate what happens without DPprior # (dpmirt_alpha_prior handles this internally) if (!has_dpprior) {   ab_fallback <- dpmirt_alpha_prior(N = 200)   cat(\"Returned:\", ab_fallback, \"\\n\") } else {   cat(\"With DPprior installed, the package uses principled elicitation.\\n\")   cat(\"Without DPprior, it returns c(a = 1, b = 3) with a message:\\n\\n\")   cat('  \"DPprior not installed. Using default: Gamma(1, 3)\\n')   cat('   [Paganin et al., 2023].\\n')   cat('   Install DPprior for principled alpha elicitation:\\n')   cat('   remotes::install_github(\\\\\"joonho112/DPprior\\\\\")\"\\n') } #> With DPprior installed, the package uses principled elicitation. #> Without DPprior, it returns c(a = 1, b = 3) with a message: #>  #>   \"DPprior not installed. Using default: Gamma(1, 3) #>    [Paganin et al., 2023]. #>    Install DPprior for principled alpha elicitation: #>    remotes::install_github(\\\"joonho112/DPprior\\\")\""},{"path":"https://joonho112.github.io/DPMirt/articles/prior-elicitation.html","id":"advanced-custom-base-measure","dir":"Articles","previous_headings":"","what":"Advanced: Custom Base Measure","title":"Principled Prior Elicitation for the DP Concentration Parameter","text":"DP base measure G0G_0 determines shape mixture component. DPMirt uses Normal–Inverse-Gamma base: G0=𝒩(0,sμ2)×InvGamma(ν1,ν2) G_0 = \\mathcal{N}(0, s^2_\\mu) \\times \\text{InvGamma}(\\nu_1, \\nu_2) Paganin defaults sμ2=2s^2_\\mu = 2, ν1=2.01\\nu_1 = 2.01, ν2=1.01\\nu_2 = 1.01. yield wide cluster means diffuse cluster variances, appropriate standardized IRT scales. customize: step--step interface gives direct access:","code":"# Wider cluster means, more concentrated cluster variances fit <- dpmirt(   data,   model        = \"rasch\",   prior        = \"dpm\",   mu_K         = 5,   confidence   = \"medium\",   base_measure = list(s2_mu = 3, nu1 = 2.01, nu2 = 1.01),   niter        = 10000 ) spec <- dpmirt_spec(   data,   model        = \"rasch\",   prior        = \"dpm\",   alpha_prior  = c(a = 1.6, b = 0.82),   base_measure = list(s2_mu = 3, nu1 = 2.01, nu2 = 1.01) )  # Inspect what was set spec$constants$s2_mu   # 3 spec$constants$nu1     # 2.01 spec$constants$nu2     # 1.01"},{"path":"https://joonho112.github.io/DPMirt/articles/prior-elicitation.html","id":"base-measure-hyperparameter-effects","dir":"Articles","previous_headings":"Advanced: Custom Base Measure","what":"Base Measure Hyperparameter Effects","title":"Principled Prior Elicitation for the DP Concentration Parameter","text":"Practical guidance: IRT applications, Paganin defaults work well. Increase sμ2s^2_\\mu expect latent subgroups separated 3–4 standard deviations (e.g., combined clinical non-clinical samples).","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/prior-elicitation.html","id":"elicitation-decision-flowchart","dir":"Articles","previous_headings":"","what":"Elicitation Decision Flowchart","title":"Principled Prior Elicitation for the DP Concentration Parameter","text":"following summary may help decide approach use:","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/prior-elicitation.html","id":"whats-next","dir":"Articles","previous_headings":"","what":"What’s Next?","title":"Principled Prior Elicitation for the DP Concentration Parameter","text":"Now can set principled priors α\\alpha, following vignettes show put work:","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/prior-elicitation.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Principled Prior Elicitation for the DP Concentration Parameter","text":"Lee, J. (2026). Design-conditional prior elicitation Dirichlet Process mixtures: unified framework cluster counts weight control. arXiv preprint arXiv:2602.06301. https://arxiv.org/abs/2602.06301 Lee, J. & Wind, S. Targeting toward inferential goals Bayesian Rasch models estimating person-specific latent traits. OSF Preprint. https://doi.org/10.31219/osf.io/qrw4n Paganin, S., Paciorek, C. J., Wehrhahn, C., Rodríguez, ., Rabe-Hesketh, S., & de Valpine, P. (2023). Computational strategies estimation performance Bayesian semiparametric item response theory models. Journal Educational Behavioral Statistics, 48(2), 147–188. https://doi.org/10.3102/10769986221136105","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/quick-start.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Quick Start: Your First IRT Model in 5 Minutes","text":"vignette walks complete DPMirt workflow start finish. end know : Simulate IRT response data dpmirt_simulate(). Fit Rasch model Normal prior Dirichlet Process Mixture (DPM) prior. Visualize posterior densities, item parameters, MCMC diagnostics. Extract person ability estimates using posterior mean (PM), constrained Bayes (CB), triple-goal (GR) estimators. NIMBLE compilation required simulation estimation steps shown — load pre-computed MCMC results can follow along instantly.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/quick-start.html","id":"simulate-data","dir":"Articles","previous_headings":"","what":"Simulate Data","title":"Quick Start: Your First IRT Model in 5 Minutes","text":"dpmirt_simulate() generates binary response data known IRT model. optional IRTsimrel package installed, uses Empirical Quadrature Calibration (EQC) hit target marginal reliability; otherwise falls back Paganin-style simulation. returned dpmirt_sim object contains binary response matrix (sim$response), true person abilities (sim$theta), true item difficulties (sim$beta). can inspect simulation print(): dpmirt_simulate() pure R, runs instantly — NIMBLE compilation needed.","code":"sim <- dpmirt_simulate(   n_persons    = 200,   n_items      = 25,   model        = \"rasch\",   target_rho   = 0.8,   latent_shape = \"normal\",   seed         = 42 ) #> Note: Target rho* = 0.800 is near the achievable maximum (0.824) for this configuration.  str(sim, max.level = 1) #> List of 13 #>  $ response    : num [1:200, 1:25] 0 0 0 1 1 0 1 0 1 0 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>  $ theta       : num [1:200] -2.5215 0.0563 -0.6466 1.135 -0.3096 ... #>  $ beta        : num [1:25] 0.131 -1.295 0.384 -0.636 0.507 ... #>  $ lambda      : NULL #>  $ delta       : NULL #>  $ n_persons   : num 200 #>  $ n_items     : num 25 #>  $ model       : chr \"rasch\" #>  $ reliability : num 0.807 #>  $ target_rho  : num 0.8 #>  $ latent_shape: chr \"normal\" #>  $ eqc_result  :List of 16 #>   ..- attr(*, \"class\")= chr [1:2] \"eqc_result\" \"list\" #>  $ method      : chr \"irtsimrel\" #>  - attr(*, \"class\")= chr \"dpmirt_sim\" sim #> DPMirt Simulated Data #> ===================== #> Model:         RASCH  #> Persons:       200  #> Items:         25  #> Distribution:  normal  #> Method:        irtsimrel  #> Target rho:    0.8  #> KR-20:         0.807  #> EQC c*:        0.9082  #> EQC rho:       0.8"},{"path":"https://joonho112.github.io/DPMirt/articles/quick-start.html","id":"fit-a-rasch-model-with-a-normal-prior","dir":"Articles","previous_headings":"","what":"Fit a Rasch Model with a Normal Prior","title":"Quick Start: Your First IRT Model in 5 Minutes","text":"main entry point dpmirt(). call run interactive session. NIMBLE compiles model first use, takes roughly 1–2 minutes; , additional sampling fast. vignette load pre-computed result instead:","code":"# This is the code you would run (takes ~2 minutes for compilation): fit <- dpmirt(   sim$response,   model   = \"rasch\",   prior   = \"normal\",   niter   = 10000,   nburnin = 2000,   seed    = 100 ) fit <- readRDS(find_extdata(\"vignette_fit_rasch_normal.rds\"))"},{"path":"https://joonho112.github.io/DPMirt/articles/quick-start.html","id":"understanding-the-output","dir":"Articles","previous_headings":"","what":"Understanding the Output","title":"Quick Start: Your First IRT Model in 5 Minutes","text":"dpmirt_fit object stores posterior samples, diagnostics, model configuration. print() method gives compact overview: Key fields: Model / Prior / Identification — specified. MCMC — iteration count, burn-, thinning. WAIC — Watanabe–Akaike information criterion model comparison. Min ESS — minimum effective sample size across items persons; quick convergence check. Total time — wall-clock time full pipeline. richer view, call summary(): summary adds item--item parameter estimates (posterior mean SD), distributional summary person abilities, — DPM models — cluster concentration-parameter diagnostics.","code":"print(fit) #> DPMirt Model Fit #> ================ #> Model:            RASCH  #> Prior:            normal  #> Identification:   constrained_item  #> Persons (N):      200  #> Items (I):        25  #> MCMC:            10000 iterations (2000 burnin, thin=1) #> WAIC:             6079.03  #> Total time:       55.4 sec  #> Min ESS (items):  1714  #> Min ESS (theta):  1372 summary(fit) #> DPMirt Model Summary #> ==================== #>  #> Model Configuration: #>   Model:            RASCH  #>   Prior:            normal  #>   Identification:   constrained_item  #>   Rescaled:         TRUE  #>  #> Data: #>   Persons (N): 200  #>   Items (I):   25  #>  #> MCMC Settings: #>   Iterations:  10000  #>   Burn-in:     2000  #>   Thinning:    1  #>   Chains:      1  #>  #> Timing: #>   Compilation:  18.1 sec  #>   Sampling:     36.6 sec  #>   Total:        55.4 sec  #>  #> Item Difficulty (beta) Summary: #>            Mean    SD #> beta[1]   0.143 0.151 #> beta[2]  -1.022 0.161 #> beta[3]   0.535 0.158 #> beta[4]  -0.688 0.154 #> beta[5]   0.191 0.152 #> beta[6]   0.501 0.154 #> beta[7]  -0.347 0.149 #> beta[8]  -0.378 0.153 #> beta[9]   0.482 0.156 #> beta[10] -0.843 0.158 #> beta[11]  0.760 0.157 #> beta[12]  0.335 0.155 #> beta[13]  0.147 0.152 #> beta[14] -0.252 0.148 #> beta[15]  0.031 0.148 #> beta[16] -0.038 0.157 #> beta[17] -0.186 0.151 #> beta[18]  0.383 0.151 #> beta[19]  0.999 0.163 #> beta[20]  0.897 0.165 #> beta[21] -0.113 0.153 #> beta[22] -0.692 0.154 #> beta[23]  0.678 0.155 #> beta[24] -0.180 0.151 #> beta[25] -1.342 0.170 #>  #> Person Ability (theta) Summary: #>   Range: [ -2.052 ,  1.768 ] #>   Mean:   -0.073  #>   SD:     0.81  #>  #> Model Comparison: #>   WAIC:  6079.03"},{"path":"https://joonho112.github.io/DPMirt/articles/quick-start.html","id":"visualizations","dir":"Articles","previous_headings":"","what":"Visualizations","title":"Quick Start: Your First IRT Model in 5 Minutes","text":"plot(fit, type = ...) dispatches 12 plot types. ggplot2 installed package uses automatically; otherwise base R graphics produced.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/quick-start.html","id":"posterior-density-of-theta","dir":"Articles","previous_headings":"Visualizations","what":"Posterior Density of Theta","title":"Quick Start: Your First IRT Model in 5 Minutes","text":"Kernel density posterior mean theta Normal prior. shows kernel density N=200N = 200 posterior-mean person abilities. Normal prior density smooth unimodal construction.","code":"plot(fit, type = \"density\")"},{"path":"https://joonho112.github.io/DPMirt/articles/quick-start.html","id":"item-difficulty-estimates","dir":"Articles","previous_headings":"Visualizations","what":"Item Difficulty Estimates","title":"Quick Start: Your First IRT Model in 5 Minutes","text":"Item difficulty estimates +/- 2 posterior SD error bars. point posterior mean βj\\beta_j; error bars span ±2\\pm 2 posterior standard deviations. Items ordered easiest (negative) hardest.","code":"plot(fit, type = \"items\")"},{"path":"https://joonho112.github.io/DPMirt/articles/quick-start.html","id":"mcmc-trace","dir":"Articles","previous_headings":"Visualizations","what":"MCMC Trace","title":"Quick Start: Your First IRT Model in 5 Minutes","text":"Log-likelihood trace plot. stationary trace suggests convergence. stationary log-likelihood trace visible trend drift first-pass convergence check. formal diagnostics see Models Workflow vignette.","code":"plot(fit, type = \"trace\")"},{"path":"https://joonho112.github.io/DPMirt/articles/quick-start.html","id":"adding-dpm-flexibility","dir":"Articles","previous_headings":"","what":"Adding DPM Flexibility","title":"Quick Start: Your First IRT Model in 5 Minutes","text":"Normal prior assumes latent abilities follow Gaussian distribution. assumption questionable — bimodal populations, floor/ceiling effects, skew — Dirichlet Process Mixture (DPM) prior lets data speak. , load pre-computed result:","code":"# This is the code you would run: fit_dpm <- dpmirt(   sim$response,   model   = \"rasch\",   prior   = \"dpm\",   niter   = 10000,   nburnin = 2000,   seed    = 200 ) fit_dpm <- readRDS(find_extdata(\"vignette_fit_rasch_dpm.rds\"))"},{"path":"https://joonho112.github.io/DPMirt/articles/quick-start.html","id":"posterior-density-comparison","dir":"Articles","previous_headings":"Adding DPM Flexibility","what":"Posterior Density Comparison","title":"Quick Start: Your First IRT Model in 5 Minutes","text":"Posterior mean theta density DPM prior. overlay places posteriors axes direct comparison. true latent distribution Normal, two densities nearly identical — DPM prior adapts data distort estimates. Normal-prior vs. DPM-prior posterior mean densities data. true distribution Normal, priors recover equally well.","code":"plot(fit_dpm, type = \"density\") if (requireNamespace(\"ggplot2\", quietly = TRUE)) {   library(ggplot2)   pm_normal <- colMeans(fit$theta_samp)   pm_dpm    <- colMeans(fit_dpm$theta_samp)    df_overlay <- data.frame(     value  = c(pm_normal, pm_dpm),     Prior  = factor(rep(c(\"Normal\", \"DPM\"), each = length(pm_normal)),                     levels = c(\"Normal\", \"DPM\"))   )    ggplot(df_overlay, aes(x = value, colour = Prior, fill = Prior)) +     geom_density(alpha = 0.25, linewidth = 0.9) +     scale_colour_manual(values = c(Normal = pal$parametric,                                     DPM   = pal$semiparametric)) +     scale_fill_manual(values = c(Normal = pal$parametric,                                   DPM   = pal$semiparametric)) +     labs(title = \"Normal vs. DPM Prior (Normal Population)\",          x = expression(theta), y = \"Density\") +     theme_bw() +     theme(legend.position = \"top\") } #> Warning: package 'ggplot2' was built under R version 4.5.2"},{"path":"https://joonho112.github.io/DPMirt/articles/quick-start.html","id":"cluster-diagnostics","dir":"Articles","previous_headings":"Adding DPM Flexibility","what":"Cluster Diagnostics","title":"Quick Start: Your First IRT Model in 5 Minutes","text":"Number active clusters across MCMC iterations (left) posterior distribution (right). left panel traces number active clusters post-burn-iteration; right panel shows posterior distribution cluster counts. single dominant mode suggests data well-described many latent subgroups.","code":"plot(fit_dpm, type = \"clusters\")"},{"path":"https://joonho112.github.io/DPMirt/articles/quick-start.html","id":"dp-mixture-density","dir":"Articles","previous_headings":"Adding DPM Flexibility","what":"DP Mixture Density","title":"Quick Start: Your First IRT Model in 5 Minutes","text":"DP mixture posterior mean density 95 percent pointwise credible band. Dashed line: N(0,1) reference. solid curve posterior mean DP mixture density evaluated fine grid; shaded ribbon 95% pointwise credible band. dashed line shows standard Normal reference.","code":"plot(fit_dpm, type = \"dp_density\")"},{"path":"https://joonho112.github.io/DPMirt/articles/quick-start.html","id":"seeing-the-dpm-advantage","dir":"Articles","previous_headings":"","what":"Seeing the DPM Advantage","title":"Quick Start: Your First IRT Model in 5 Minutes","text":"example used truly Normal population, priors performed equally well. happens population departs normality? DPMirt package ships pre-computed results bimodal population — 50/50 mixture two groups centered θ=−1.5\\theta = -1.5 θ=1.5\\theta = 1.5 — reveals DPM prior’s key advantage. true population bimodal, Normal prior forces unimodal fit (blue), masking two-group structure. DPM prior (orange) recovers modes. Key insight. Normal prior mechanism represent two modes, forces estimates toward single central peak. DPM prior adapts shape data, preserving bimodal structure. difference consequential classification decisions (e.g., identifying students intervention) reporting shape population distribution. See vignette(\"posterior-summaries\") detailed comparison estimators exploit flexibility.","code":"sim_bm   <- readRDS(find_extdata(\"vignette_sim_bimodal.rds\")) fit_n_bm <- readRDS(find_extdata(\"vignette_fit_rasch_normal_bimodal.rds\")) fit_d_bm <- readRDS(find_extdata(\"vignette_fit_rasch_dpm_bimodal.rds\"))  if (requireNamespace(\"ggplot2\", quietly = TRUE)) {   true_theta <- sim_bm$theta   pm_normal  <- colMeans(fit_n_bm$theta_samp)   pm_dpm     <- colMeans(fit_d_bm$theta_samp)    df_bm <- data.frame(     value  = c(true_theta, pm_normal, pm_dpm),     source = factor(rep(c(\"True\", \"Normal Prior (PM)\", \"DPM Prior (PM)\"),                         each = length(true_theta)),                     levels = c(\"True\", \"Normal Prior (PM)\", \"DPM Prior (PM)\"))   )    ggplot(df_bm, aes(x = value, fill = source, colour = source)) +     geom_density(alpha = 0.30, linewidth = 0.8) +     scale_fill_manual(values = c(\"True\"              = pal$reference,                                   \"Normal Prior (PM)\" = pal$parametric,                                   \"DPM Prior (PM)\"    = pal$semiparametric)) +     scale_colour_manual(values = c(\"True\"              = pal$reference,                                     \"Normal Prior (PM)\" = pal$parametric,                                     \"DPM Prior (PM)\"    = pal$semiparametric)) +     labs(title = \"Normal vs. DPM Prior: Recovering a Bimodal Population\",          subtitle = \"Rasch model, 25 items, 200 persons\",          x = expression(theta), y = \"Density\") +     theme_bw() +     theme(legend.position = \"bottom\", legend.title = element_blank()) }"},{"path":"https://joonho112.github.io/DPMirt/articles/quick-start.html","id":"extracting-estimates","dir":"Articles","previous_headings":"","what":"Extracting Estimates","title":"Quick Start: Your First IRT Model in 5 Minutes","text":"dpmirt_estimates() computes person item point estimates using three complementary posterior summary methods: theta element data frame one row per person: estimator use? depends inferential goal. need best point prediction individual, use PM. need set estimates reproduce shape ability distribution (e.g., group-level reporting), use CB. need accurate rankings distributional fidelity, use GR. See Posterior Summaries vignette -depth comparison. Item estimates available est$beta:","code":"est <- dpmirt_estimates(fit_dpm, methods = c(\"pm\", \"cb\", \"gr\")) head(est$theta, 10) #>            theta_pm theta_psd    theta_cb     theta_gr      rbar rhat #> eta[1]  -1.64208358 0.4850620 -1.82658631 -1.898414370  14.10438    6 #> eta[2]   0.08246350 0.3785971  0.10105187  0.130777459 110.04200  114 #> eta[3]   0.05810186 0.3859230  0.07382128  0.001450727 108.21700  103 #> eta[4]   1.15463248 0.4241983  1.29948472  1.393735077 179.26688  192 #> eta[5]  -0.68190514 0.3877922 -0.75333256 -0.665180404  53.89862   52 #> eta[6]   0.81760681 0.3950633  0.92276925  0.811079297 162.99625  167 #> eta[7]   1.72015915 0.4758415  1.93161057  2.206872410 194.11588  200 #> eta[8]  -0.06517854 0.3837235 -0.06397722 -0.057278283  98.39575   98 #> eta[9]   0.66101983 0.3824489  0.74774183  0.688329335 153.44163  159 #> eta[10] -0.06306564 0.3877453 -0.06161549 -0.033409063  98.65662  100 #>         theta_lower theta_upper #> eta[1]  -2.71809760 -0.76137677 #> eta[2]  -0.63931121  0.81955388 #> eta[3]  -0.68900612  0.82161938 #> eta[4]   0.34563696  2.00481098 #> eta[5]  -1.44006283  0.07806641 #> eta[6]   0.05942028  1.60027832 #> eta[7]   0.84623291  2.75717002 #> eta[8]  -0.84149547  0.68498198 #> eta[9]  -0.06723822  1.41774065 #> eta[10] -0.82119382  0.69405528 head(est$beta, 10) #>             beta_pm  beta_psd    beta_cb     beta_gr     rbar rhat beta_lower #> beta[1]   0.1393281 0.1481244  0.1437448  0.09951606 14.54713   14 -0.1448619 #> beta[2]  -1.0281008 0.1593125 -1.0606917 -1.05388296  2.26200    2 -1.3531175 #> beta[3]   0.5266330 0.1558563  0.5433273  0.59943417 19.94138   21  0.2277232 #> beta[4]  -0.6922001 0.1558382 -0.7141429 -0.73611032  4.36675    4 -0.9959212 #> beta[5]   0.1946660 0.1501926  0.2008369  0.23378009 15.36788   16 -0.1017568 #> beta[6]   0.5082932 0.1550549  0.5244062  0.52121043 19.70375   20  0.2010165 #> beta[7]  -0.3503717 0.1511989 -0.3614786 -0.36061570  7.43475    7 -0.6562346 #> beta[8]  -0.3770295 0.1534740 -0.3889813 -0.46590990  7.14050    6 -0.6858021 #> beta[9]   0.4868289 0.1543031  0.5022614  0.44842581 19.43700   19  0.1870308 #> beta[10] -0.8442989 0.1608205 -0.8710633 -0.87137757  3.31225    3 -1.1662977 #>           beta_upper #> beta[1]   0.44597696 #> beta[2]  -0.72312083 #> beta[3]   0.84615054 #> beta[4]  -0.39020070 #> beta[5]   0.48423148 #> beta[6]   0.80991762 #> beta[7]  -0.06704874 #> beta[8]  -0.08586970 #> beta[9]   0.78795591 #> beta[10] -0.52819222"},{"path":"https://joonho112.github.io/DPMirt/articles/quick-start.html","id":"whats-next","dir":"Articles","previous_headings":"","what":"What’s Next?","title":"Quick Start: Your First IRT Model in 5 Minutes","text":"now working end--end pipeline. Depending goal, following vignettes go deeper: Happy modeling! now equipped fit Rasch models parametric (Normal) semiparametric (DPM) priors. questions, bugs, suggestions, visit DPMirt repository.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/simulation-study.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Simulation Study: Evaluating Prior Models and Posterior Summaries","text":"Simulation studies primary tool evaluating IRT methods provide access ground truth — true person abilities item parameters generated data. DPMirt provides integrated simulation framework lets : Simulate data known conditions using IRTsimrel’s EQC calibration (built-fallback). Fit models competing prior specifications (Normal vs. DPM). Estimate person abilities using three posterior summary methods (PM, CB, GR). Evaluate performance using multiple loss functions (MSEL, MSELR, KS). vignette walks complete simulation study design, executes single-condition deep dive, interprets results, provides templates scaling full factorial study.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/simulation-study.html","id":"simulation-design","dir":"Articles","previous_headings":"","what":"Simulation Design","title":"Simulation Study: Evaluating Prior Models and Posterior Summaries","text":"APM manuscript (Lee & Wind) uses 3×2×33 \\times 2 \\times 3 factorial design crossing three factors:","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/simulation-study.html","id":"factor-1-latent-distribution-shape-g","dir":"Articles","previous_headings":"Simulation Design","what":"Factor 1: Latent Distribution Shape (GG)","title":"Simulation Study: Evaluating Prior Models and Posterior Summaries","text":"Normal condition parametric model’s “home turf” DPM offers little advantage. Bimodal Skew conditions represent departures flexible priors excel.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/articles/simulation-study.html","id":"factor-3-marginal-reliability-barw","dir":"Articles","previous_headings":"Simulation Design","what":"Factor 3: Marginal Reliability (w‾\\bar{w})","title":"Simulation Study: Evaluating Prior Models and Posterior Summaries","text":"Reliability w‾\\bar{w} influential factor simulation. controls information per person therefore degree posterior shrinkage. Reliability levels implications IRT estimation. reliability dominates: w‾=0.50\\bar{w} = 0.50, person’s posterior heavily shrunk toward prior — little room method differ another. w‾=0.90\\bar{w} = 0.90, posteriors tightly concentrated around data-driven estimates, amplifying impact prior misspecification.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/simulation-study.html","id":"full-design-matrix","dir":"Articles","previous_headings":"Simulation Design","what":"Full Design Matrix","title":"Simulation Study: Evaluating Prior Models and Posterior Summaries","text":"full factorial design 3×2×3=183 \\times 2 \\times 3 = 18 conditions. condition replicated (e.g., 100 times) Monte Carlo stability. Full 3 x 2 x 3 factorial design (18 conditions).","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/simulation-study.html","id":"irtsimrel-integration","dir":"Articles","previous_headings":"Simulation Design","what":"IRTsimrel Integration","title":"Simulation Study: Evaluating Prior Models and Posterior Summaries","text":"DPMirt uses IRTsimrel package (available) achieve precise reliability targeting via Empirical Quadrature Calibration (EQC). key function dpmirt_simulate(): returned dpmirt_sim object reports: Method: “irtsimrel” (EQC-calibrated) “fallback” (Paganin-style) KR-20: Empirical reliability generated data EQC c*: calibration constant maps target reliability number items IRTsimrel installed, dpmirt_simulate() falls back simpler simulation evenly spaced item difficulties reliability targeting.","code":"# Simulate bimodal data with target reliability 0.8 sim <- dpmirt_simulate(   n_persons    = 200,   n_items      = 25,   model        = \"rasch\",   target_rho   = 0.8,   latent_shape = \"bimodal\",   seed         = 42 )  sim #> DPMirt Simulated Data #> ===================== #> Model:         RASCH  #> Persons:       200  #> Items:         25  #> Distribution:  bimodal  #> Method:        irtsimrel  #> Target rho:    0.8  #> KR-20:         0.81  #> EQC c*:        0.935  #> EQC rho:       0.8"},{"path":"https://joonho112.github.io/DPMirt/articles/simulation-study.html","id":"visualizing-the-simulated-data","dir":"Articles","previous_headings":"Simulation Design","what":"Visualizing the Simulated Data","title":"Simulation Study: Evaluating Prior Models and Posterior Summaries","text":"Density true theta values bimodal simulation. Distribution sum scores simulated response matrix.","code":"theta_dens <- density(sim$theta) plot(theta_dens, main = \"True theta distribution (bimodal)\",      xlab = expression(theta), lwd = 2) rug(sim$theta, col = adjustcolor(\"black\", alpha.f = 0.2)) sum_scores <- rowSums(sim$response) hist(sum_scores, breaks = 20, main = \"Sum score distribution\",      xlab = \"Sum score\", col = adjustcolor(pal$parametric, alpha.f = 0.5),      border = \"white\")"},{"path":"https://joonho112.github.io/DPMirt/articles/simulation-study.html","id":"analysis-pipeline","dir":"Articles","previous_headings":"","what":"Analysis Pipeline","title":"Simulation Study: Evaluating Prior Models and Posterior Summaries","text":"full analysis pipeline single simulation condition consists six steps. show complete code run live session, load pre-computed results remaining analysis.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/simulation-study.html","id":"step-1-simulate-data","dir":"Articles","previous_headings":"Analysis Pipeline","what":"Step 1: Simulate Data","title":"Simulation Study: Evaluating Prior Models and Posterior Summaries","text":"","code":"sim <- dpmirt_simulate(   n_persons    = 200,   n_items      = 25,   model        = \"rasch\",   target_rho   = 0.8,   latent_shape = \"bimodal\",   seed         = 42 )"},{"path":"https://joonho112.github.io/DPMirt/articles/simulation-study.html","id":"step-2-fit-models","dir":"Articles","previous_headings":"Analysis Pipeline","what":"Step 2: Fit Models","title":"Simulation Study: Evaluating Prior Models and Posterior Summaries","text":"","code":"# --- Fit Normal prior model (~2 min compilation + sampling) --- fit_normal <- dpmirt(   sim$response,   model   = \"rasch\",   prior   = \"normal\",   niter   = 10000,   nburnin = 2000,   seed    = 100 )  # --- Fit DPM prior model (~2 min compilation + sampling) --- fit_dpm <- dpmirt(   sim$response,   model      = \"rasch\",   prior      = \"dpm\",   mu_K       = 5,   confidence = \"medium\",   niter      = 10000,   nburnin    = 2000,   seed       = 200 )"},{"path":"https://joonho112.github.io/DPMirt/articles/simulation-study.html","id":"step-3-extract-estimates","dir":"Articles","previous_headings":"Analysis Pipeline","what":"Step 3: Extract Estimates","title":"Simulation Study: Evaluating Prior Models and Posterior Summaries","text":"","code":"# Compute PM, CB, GR for both models est_normal <- dpmirt_estimates(fit_normal, methods = c(\"pm\", \"cb\", \"gr\")) est_dpm    <- dpmirt_estimates(fit_dpm,    methods = c(\"pm\", \"cb\", \"gr\"))"},{"path":"https://joonho112.github.io/DPMirt/articles/simulation-study.html","id":"step-4-evaluate-losses","dir":"Articles","previous_headings":"Analysis Pipeline","what":"Step 4: Evaluate Losses","title":"Simulation Study: Evaluating Prior Models and Posterior Summaries","text":"","code":"# Compare to true theta loss_normal <- dpmirt_loss(est_normal, true_theta = sim$theta,                             true_beta = sim$beta) loss_dpm    <- dpmirt_loss(est_dpm,    true_theta = sim$theta,                             true_beta = sim$beta)"},{"path":"https://joonho112.github.io/DPMirt/articles/simulation-study.html","id":"step-5-combine-results","dir":"Articles","previous_headings":"Analysis Pipeline","what":"Step 5: Combine Results","title":"Simulation Study: Evaluating Prior Models and Posterior Summaries","text":"","code":"loss_normal$prior <- \"Normal\" loss_dpm$prior    <- \"DPM\" combined_loss <- rbind(loss_normal, loss_dpm)"},{"path":"https://joonho112.github.io/DPMirt/articles/simulation-study.html","id":"loading-pre-computed-results","dir":"Articles","previous_headings":"Analysis Pipeline","what":"Loading Pre-Computed Results","title":"Simulation Study: Evaluating Prior Models and Posterior Summaries","text":"vignette, fitting results pre-computed:","code":"# Load pre-computed simulation data sim_data <- readRDS(find_extdata(\"vignette_sim_bimodal.rds\"))  # Load estimates comparison (all 6 method-prior combos) est_comparison <- readRDS(find_extdata(\"vignette_estimates_comparison.rds\"))  # Load loss results loss_results <- readRDS(find_extdata(\"vignette_loss_results.rds\"))"},{"path":"https://joonho112.github.io/DPMirt/articles/simulation-study.html","id":"single-condition-deep-dive","dir":"Articles","previous_headings":"","what":"Single Condition Deep Dive","title":"Simulation Study: Evaluating Prior Models and Posterior Summaries","text":"focus informative condition: Bimodal, N=200N = 200, w‾≈0.8\\bar{w} \\approx 0.8. DPM prior show clearest advantage Normal prior, true latent distribution violates Gaussian assumption data informative enough posterior reflect violation.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/simulation-study.html","id":"posterior-density-overlay","dir":"Articles","previous_headings":"Single Condition Deep Dive","what":"Posterior Density Overlay","title":"Simulation Study: Evaluating Prior Models and Posterior Summaries","text":"Density estimates six method-prior combinations overlaid true latent density. DPM-based methods (warm colors) better capture bimodal shape. look : Normal prior, three estimators (PM, CB, GR) tend “fill ” valley two modes Gaussian assumption forces unimodal shape. DPM-based estimators, especially CB GR, better preserve bimodal structure.","code":"theta_true <- est_comparison$true_theta N <- length(theta_true)  df_dens <- data.frame(   value = c(theta_true,             est_comparison$normal$theta$theta_pm,             est_comparison$normal$theta$theta_cb,             est_comparison$normal$theta$theta_gr,             est_comparison$dpm$theta$theta_pm,             est_comparison$dpm$theta$theta_cb,             est_comparison$dpm$theta$theta_gr),   Method = factor(rep(c(\"True\", \"Normal-PM\", \"Normal-CB\", \"Normal-GR\",                          \"DPM-PM\", \"DPM-CB\", \"DPM-GR\"), each = N),                   levels = c(\"True\", \"Normal-PM\", \"Normal-CB\", \"Normal-GR\",                              \"DPM-PM\", \"DPM-CB\", \"DPM-GR\")) )  method_colors <- c(   \"True\"      = \"black\",   \"Normal-PM\" = pal$normal_pm, \"Normal-CB\" = pal$normal_cb,   \"Normal-GR\" = pal$normal_gr,   \"DPM-PM\"    = pal$dpm_pm, \"DPM-CB\" = pal$dpm_cb,   \"DPM-GR\"    = pal$dpm_gr ) method_lty <- c(\"True\" = \"solid\",                 \"Normal-PM\" = \"solid\", \"Normal-CB\" = \"dashed\",                 \"Normal-GR\" = \"dotted\",                 \"DPM-PM\"    = \"solid\", \"DPM-CB\"    = \"dashed\",                 \"DPM-GR\"    = \"dotted\")  ggplot(df_dens, aes(x = value, colour = Method, linetype = Method)) +   geom_density(linewidth = 0.9, fill = NA) +   scale_colour_manual(values = method_colors) +   scale_linetype_manual(values = method_lty) +   labs(title = \"Posterior density comparison: 6 methods vs. truth\",        subtitle = \"Bimodal population, 25 items, 200 persons\",        x = expression(theta), y = \"Density\") +   theme_bw() +   theme(legend.position = \"right\")"},{"path":"https://joonho112.github.io/DPMirt/articles/simulation-study.html","id":"shrinkage-comparison","dir":"Articles","previous_headings":"Single Condition Deep Dive","what":"Shrinkage Comparison","title":"Simulation Study: Evaluating Prior Models and Posterior Summaries","text":"Posterior mean (PM) estimates vs. true theta. Normal-PM shows stronger shrinkage toward zero; DPM-PM preserves extreme values better.","code":"par(mfrow = c(1, 2))  # Normal-PM plot(theta_true, est_comparison$normal$theta$theta_pm,      pch = 16, cex = 0.6, col = adjustcolor(pal$normal_pm, 0.6),      xlab = expression(theta[true]), ylab = expression(hat(theta)[PM]),      main = \"Normal-PM\", asp = 1) abline(0, 1, col = pal$reference, lwd = 1.5, lty = 2)  # DPM-PM plot(theta_true, est_comparison$dpm$theta$theta_pm,      pch = 16, cex = 0.6, col = adjustcolor(pal$dpm_pm, 0.6),      xlab = expression(theta[true]), ylab = expression(hat(theta)[PM]),      main = \"DPM-PM\", asp = 1) abline(0, 1, col = pal$reference, lwd = 1.5, lty = 2) par(mfrow = c(1, 1))"},{"path":"https://joonho112.github.io/DPMirt/articles/simulation-study.html","id":"loss-function-results","dir":"Articles","previous_headings":"Single Condition Deep Dive","what":"Loss Function Results","title":"Simulation Study: Evaluating Prior Models and Posterior Summaries","text":"Three complementary loss functions capture different aspects estimator quality: Loss function results: Bimodal, N=200, w-bar=0.8.","code":"# loss_results is a list with $normal and $dpm data.frames, # each with columns: parameter, method, msel, mselr, ks  # Combine into one table with a prior column loss_normal <- loss_results$normal loss_normal$prior <- \"Normal\" loss_dpm <- loss_results$dpm loss_dpm$prior <- \"DPM\" loss_combined <- rbind(loss_normal, loss_dpm)  # Filter to theta and format loss_display <- loss_combined[loss_combined$parameter == \"theta\", ] loss_display <- loss_display[order(loss_display$prior, loss_display$method), ]  loss_display$Label <- paste0(loss_display$prior, \"-\",                               toupper(loss_display$method)) loss_display <- loss_display[, c(\"Label\", \"msel\", \"mselr\", \"ks\")] names(loss_display) <- c(\"Method\", \"MSEL\", \"MSELR\", \"KS\") loss_display$MSEL  <- round(loss_display$MSEL, 4) loss_display$MSELR <- round(loss_display$MSELR, 5) loss_display$KS    <- round(loss_display$KS, 4)  knitr::kable(loss_display, row.names = FALSE,              caption = \"Loss function results: Bimodal, N=200, w-bar=0.8.\",              align = \"lccc\")"},{"path":"https://joonho112.github.io/DPMirt/articles/simulation-study.html","id":"interpreting-the-loss-table","dir":"Articles","previous_headings":"Single Condition Deep Dive","what":"Interpreting the Loss Table","title":"Simulation Study: Evaluating Prior Models and Posterior Summaries","text":"","code":"# Identify best method for each loss best_msel  <- loss_display$Method[which.min(loss_display$MSEL)] best_mselr <- loss_display$Method[which.min(loss_display$MSELR)] best_ks    <- loss_display$Method[which.min(loss_display$KS)]  cat(\"Best for MSEL  (individual accuracy):\", best_msel, \"\\n\") #> Best for MSEL  (individual accuracy): DPM-PM cat(\"Best for MSELR (ranking accuracy):   \", best_mselr, \"\\n\") #> Best for MSELR (ranking accuracy):    Normal-GR cat(\"Best for KS    (distributional):     \", best_ks, \"\\n\") #> Best for KS    (distributional):      DPM-GR"},{"path":"https://joonho112.github.io/DPMirt/articles/simulation-study.html","id":"visual-loss-comparison","dir":"Articles","previous_headings":"Single Condition Deep Dive","what":"Visual Loss Comparison","title":"Simulation Study: Evaluating Prior Models and Posterior Summaries","text":"Bar chart loss values across six methods. Lower better three metrics. PM wins MSEL (individual accuracy); GR wins MSELR (ranking) KS (distributional fidelity).","code":"method_colors_vec <- c(   \"Normal-CB\" = pal$normal_cb, \"Normal-GR\" = pal$normal_gr,   \"Normal-PM\" = pal$normal_pm,   \"DPM-CB\"    = pal$dpm_cb, \"DPM-GR\" = pal$dpm_gr,   \"DPM-PM\"    = pal$dpm_pm )  loss_long <- data.frame(   Method = rep(loss_display$Method, 3),   Metric = rep(c(\"MSEL\", \"MSELR\", \"KS\"), each = nrow(loss_display)),   Loss   = c(loss_display$MSEL, loss_display$MSELR, loss_display$KS) ) loss_long$Method <- factor(loss_long$Method, levels = loss_display$Method) loss_long$Metric <- factor(loss_long$Metric, levels = c(\"MSEL\", \"MSELR\", \"KS\"))  ggplot(loss_long, aes(x = Method, y = Loss, fill = Method)) +   geom_col(width = 0.7) +   facet_wrap(~ Metric, scales = \"free_y\", ncol = 3) +   scale_fill_manual(values = method_colors_vec, guide = \"none\") +   labs(title = \"Loss comparison: 6 method-prior combinations\",        y = \"Loss (lower is better)\") +   theme_bw() +   theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 9),         strip.text = element_text(face = \"bold\", size = 11))"},{"path":"https://joonho112.github.io/DPMirt/articles/simulation-study.html","id":"low-reliability-contrast","dir":"Articles","previous_headings":"Single Condition Deep Dive","what":"Low-Reliability Contrast","title":"Simulation Study: Evaluating Prior Models and Posterior Summaries","text":"deep dive used 25-item test (w‾≈0.8\\bar{w} \\approx 0.8) data informative enough DPM prior shine. patterns change reliability much lower? Posterior density comparison two reliability levels (DPM prior ). Left (ρ≈0.5\\rho \\approx 0.5, 10 items): severe shrinkage causes PM collapse bimodal distribution single narrow peak. CB GR resist compression, preserving two-group structure. Right (ρ≈0.8\\rho \\approx 0.8, 25 items): shrinkage mild; three estimators recover bimodal shape, GR tracking truth closely. Loss values two reliability levels. low reliability gap PM GR KS widens substantially. Key observation. w‾≈0.5\\bar{w} \\approx 0.5, choice estimator (PM vs. CB vs. GR) matters choice prior, every person’s posterior heavily shrunk toward prior center. CB GR resist compression, producing estimates whose distribution closely tracks truth — even though individual-level MSE (MSEL) slightly higher PM’s.","code":"comp_hi <- est_comparison comp_lo <- readRDS(find_extdata(\"vignette_estimates_comparison_lowrel.rds\"))  build_panel <- function(comp_obj, label) {   N <- length(comp_obj$true_theta)   data.frame(     value = c(comp_obj$true_theta,               comp_obj$dpm$theta$theta_pm,               comp_obj$dpm$theta$theta_cb,               comp_obj$dpm$theta$theta_gr),     Method = factor(rep(c(\"True\", \"DPM-PM\", \"DPM-CB\", \"DPM-GR\"), each = N),                     levels = c(\"True\", \"DPM-PM\", \"DPM-CB\", \"DPM-GR\")),     Reliability = label   ) }  df_rel <- rbind(   build_panel(comp_lo, \"\\u03C1 \\u2248 0.5  (10 items)\"),   build_panel(comp_hi, \"\\u03C1 \\u2248 0.8  (25 items)\") ) df_rel$Reliability <- factor(df_rel$Reliability,   levels = c(\"\\u03C1 \\u2248 0.5  (10 items)\",              \"\\u03C1 \\u2248 0.8  (25 items)\"))  rel_colors <- c(\"True\" = \"gray40\", \"DPM-PM\" = pal$dpm_pm,                 \"DPM-CB\" = pal$dpm_cb, \"DPM-GR\" = pal$dpm_gr)  ggplot(df_rel, aes(x = value, colour = Method, fill = Method)) +   geom_density(alpha = 0.12, linewidth = 0.9) +   facet_wrap(~ Reliability, ncol = 2) +   scale_colour_manual(values = rel_colors) +   scale_fill_manual(values = rel_colors) +   labs(title = \"Reliability determines when estimator choice matters\",        x = expression(theta), y = \"Density\") +   theme_bw() +   theme(legend.position = \"top\",         strip.text = element_text(face = \"bold\", size = 11))"},{"path":"https://joonho112.github.io/DPMirt/articles/simulation-study.html","id":"dispersion-recovery-at-two-reliability-levels","dir":"Articles","previous_headings":"Single Condition Deep Dive","what":"Dispersion Recovery at Two Reliability Levels","title":"Simulation Study: Evaluating Prior Models and Posterior Summaries","text":"Standard deviation estimates vs. truth. PM/True ratio quantifies shrinkage severity; GR/True shows well triple-goal estimator recovers true dispersion. Pattern. low reliability, PM compresses ability distribution roughly half true spread (PM/True ≈0.50\\approx 0.50), effectively destroying bimodal structure. GR estimator retains 70% true dispersion (GR/True ≈0.70\\approx 0.70), substantially reducing information loss. high reliability, estimators converge toward true spread — shrinkage effect becomes negligible.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/simulation-study.html","id":"key-patterns","dir":"Articles","previous_headings":"","what":"Key Patterns","title":"Simulation Study: Evaluating Prior Models and Posterior Summaries","text":"simulation study Lee & Wind reveals four main findings:","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/simulation-study.html","id":"finding-1-reliability-dominates-over-sample-size","dir":"Articles","previous_headings":"Key Patterns","what":"Finding 1: Reliability Dominates Over Sample Size","title":"Simulation Study: Evaluating Prior Models and Posterior Summaries","text":"Across conditions, marginal reliability w‾\\bar{w} stronger predictor estimator performance sample size NN. w‾=0.50\\bar{w} = 0.50, six methods produce similar results data weak distinguish methods. w‾=0.90\\bar{w} = 0.90, method differences amplified. Implication: Invest longer tests (items) rather larger samples goal discriminate Normal DPM priors.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/simulation-study.html","id":"finding-2-dpm-advantage-under-non-normality-high-reliability","dir":"Articles","previous_headings":"Key Patterns","what":"Finding 2: DPM Advantage Under Non-Normality + High Reliability","title":"Simulation Study: Evaluating Prior Models and Posterior Summaries","text":"DPM prior shows largest advantage : true latent distribution non-normal (bimodal skewed), Reliability least moderate (w‾≥0.70\\bar{w} \\ge 0.70). normality, DPM prior performs comparably Normal prior — DP adapts true distribution distort .","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/simulation-study.html","id":"finding-3-pm-best-for-individual-mse-gr-best-for-ks","dir":"Articles","previous_headings":"Key Patterns","what":"Finding 3: PM Best for Individual MSE; GR Best for KS","title":"Simulation Study: Evaluating Prior Models and Posterior Summaries","text":"three posterior summary methods optimize different goals: PM traditional choice remains best Goal 1 (minimizing per-person squared error). However, PM always -shrinks toward prior center, producing estimates whose empirical distribution narrow. CB GR “de-shrink” estimates better match true distribution, small cost individual MSE.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/simulation-study.html","id":"finding-4-no-one-size-fits-all","dir":"Articles","previous_headings":"Key Patterns","what":"Finding 4: No One-Size-Fits-All","title":"Simulation Study: Evaluating Prior Models and Posterior Summaries","text":"single method–prior combination dominates across conditions loss functions simultaneously. optimal choice depends : shape true latent distribution (best guess). reliability instrument. inferential goal (individual prediction vs. distributional reporting). Recommendation: routine use, fit Normal DPM models, compare via WAIC, select estimator (PM, CB, GR) matches reporting goals.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/simulation-study.html","id":"scaling-to-a-full-study","dir":"Articles","previous_headings":"","what":"Scaling to a Full Study","title":"Simulation Study: Evaluating Prior Models and Posterior Summaries","text":"single-condition pipeline can wrapped loop full Monte Carlo study. template run non-interactive session (e.g., computing cluster). code shown executed vignette:","code":"# ============================================================ # Full simulation study template # ============================================================ # WARNING: This runs 18 conditions x 100 replications x 2 models # Estimated time: ~72 hours on a single core # ============================================================  library(DPMirt)  # --- Design --- conditions <- expand.grid(   latent_shape = c(\"normal\", \"bimodal\", \"skew_pos\"),   n_persons    = c(50, 200),   target_rho   = c(0.5, 0.7, 0.9),   stringsAsFactors = FALSE )  n_reps  <- 100 n_items <- 25  # --- Storage --- all_results <- vector(\"list\", nrow(conditions) * n_reps) result_idx  <- 0  for (cond in seq_len(nrow(conditions))) {   cfg <- conditions[cond, ]   cat(\"Condition\", cond, \"/\", nrow(conditions), \":\",       cfg$latent_shape, \"N =\", cfg$n_persons,       \"rho =\", cfg$target_rho, \"\\n\")    for (rep in seq_len(n_reps)) {     result_idx <- result_idx + 1     rep_seed   <- cond * 1000 + rep      # --- Step 1: Simulate ---     sim <- dpmirt_simulate(       n_persons    = cfg$n_persons,       n_items      = n_items,       model        = \"rasch\",       target_rho   = cfg$target_rho,       latent_shape = cfg$latent_shape,       seed         = rep_seed     )      # --- Step 2: Fit Normal ---     fit_n <- dpmirt(       sim$response,       model   = \"rasch\",       prior   = \"normal\",       niter   = 10000,       nburnin = 2000,       seed    = rep_seed + 1,       verbose = FALSE     )      # --- Step 3: Fit DPM ---     fit_d <- dpmirt(       sim$response,       model      = \"rasch\",       prior      = \"dpm\",       mu_K       = 5,       confidence = \"medium\",       niter      = 10000,       nburnin    = 2000,       seed       = rep_seed + 2,       verbose    = FALSE     )      # --- Step 4: Estimate ---     est_n <- dpmirt_estimates(fit_n, methods = c(\"pm\", \"cb\", \"gr\"))     est_d <- dpmirt_estimates(fit_d, methods = c(\"pm\", \"cb\", \"gr\"))      # --- Step 5: Evaluate ---     loss_n <- dpmirt_loss(est_n, true_theta = sim$theta,                            true_beta = sim$beta)     loss_d <- dpmirt_loss(est_d, true_theta = sim$theta,                            true_beta = sim$beta)      loss_n$prior <- \"Normal\"     loss_d$prior <- \"DPM\"      # --- Step 6: Store ---     all_results[[result_idx]] <- cbind(       rbind(loss_n, loss_d),       condition    = cond,       replication  = rep,       latent_shape = cfg$latent_shape,       n_persons    = cfg$n_persons,       target_rho   = cfg$target_rho,       waic_normal  = fit_n$waic,       waic_dpm     = fit_d$waic,       reliability  = sim$reliability     )   } }  # --- Combine --- results_df <- do.call(rbind, all_results)  # --- Save --- saveRDS(results_df, \"simulation_results.rds\")"},{"path":"https://joonho112.github.io/DPMirt/articles/simulation-study.html","id":"parallelization","dir":"Articles","previous_headings":"Scaling to a Full Study","what":"Parallelization","title":"Simulation Study: Evaluating Prior Models and Posterior Summaries","text":"faster execution, parallelize across conditions using parallel::mclapply() cluster scheduler:","code":"library(parallel)  run_one_condition <- function(cond, n_reps = 100) {   cfg <- conditions[cond, ]   # ... same inner loop as above ... }  # Run on 4 cores (adjust to your machine) results_list <- mclapply(   seq_len(nrow(conditions)),   run_one_condition,   mc.cores = 4 )"},{"path":"https://joonho112.github.io/DPMirt/articles/simulation-study.html","id":"aggregation-and-reporting","dir":"Articles","previous_headings":"Scaling to a Full Study","what":"Aggregation and Reporting","title":"Simulation Study: Evaluating Prior Models and Posterior Summaries","text":"replications complete, aggregate results condition:","code":"library(dplyr)  summary_table <- results_df %>%   filter(parameter == \"theta\") %>%   group_by(latent_shape, n_persons, target_rho, prior, method) %>%   summarise(     mean_msel  = mean(msel),     se_msel    = sd(msel) / sqrt(n()),     mean_mselr = mean(mselr),     mean_ks    = mean(ks),     .groups    = \"drop\"   )"},{"path":"https://joonho112.github.io/DPMirt/articles/simulation-study.html","id":"extending-the-study","dir":"Articles","previous_headings":"","what":"Extending the Study","title":"Simulation Study: Evaluating Prior Models and Posterior Summaries","text":"DPMirt simulation framework supports several extensions beyond basic Rasch study:","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/simulation-study.html","id":"pl-models","dir":"Articles","previous_headings":"Extending the Study","what":"2PL Models","title":"Simulation Study: Evaluating Prior Models and Posterior Summaries","text":"","code":"sim_2pl <- dpmirt_simulate(   n_persons    = 200,   n_items      = 25,   model        = \"2pl\",   target_rho   = 0.8,   latent_shape = \"bimodal\",   seed         = 42 )  fit_2pl <- dpmirt(   sim_2pl$response,   model = \"2pl\",   prior = \"dpm\",   niter = 15000,   nburnin = 3000 )"},{"path":"https://joonho112.github.io/DPMirt/articles/simulation-study.html","id":"custom-latent-distributions","dir":"Articles","previous_headings":"Extending the Study","what":"Custom Latent Distributions","title":"Simulation Study: Evaluating Prior Models and Posterior Summaries","text":"IRTsimrel installed, access 12 distribution shapes:","code":"# All supported shapes (when IRTsimrel is available) shapes <- c(\"normal\", \"bimodal\", \"trimodal\", \"multimodal\",             \"skew_pos\", \"skew_neg\", \"heavy_tail\", \"light_tail\",             \"uniform\", \"floor\", \"ceiling\", \"custom\")  for (shape in shapes) {   sim <- dpmirt_simulate(200, 25, latent_shape = shape, seed = 42)   cat(shape, \": KR-20 =\", round(sim$reliability, 3), \"\\n\") }"},{"path":"https://joonho112.github.io/DPMirt/articles/simulation-study.html","id":"custom-loss-functions","dir":"Articles","previous_headings":"Extending the Study","what":"Custom Loss Functions","title":"Simulation Study: Evaluating Prior Models and Posterior Summaries","text":"Extend evaluation loss function:","code":"# Bias (signed error) bias_loss <- function(estimate, true) mean(estimate - true)  # Coverage of 95% CI coverage_loss <- function(estimate, true) {   # Requires access to full posterior...   # Use dpmirt_draws() for this }  loss_custom <- dpmirt_loss(   est_dpm,   true_theta  = sim$theta,   custom_loss = bias_loss )"},{"path":"https://joonho112.github.io/DPMirt/articles/simulation-study.html","id":"diagnostic-checks-for-simulation-validity","dir":"Articles","previous_headings":"","what":"Diagnostic Checks for Simulation Validity","title":"Simulation Study: Evaluating Prior Models and Posterior Summaries","text":"interpreting results, verify simulation MCMC converged properly.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/simulation-study.html","id":"check-1-achieved-reliability","dir":"Articles","previous_headings":"Diagnostic Checks for Simulation Validity","what":"Check 1: Achieved Reliability","title":"Simulation Study: Evaluating Prior Models and Posterior Summaries","text":"","code":"cat(\"Target reliability:\", 0.8, \"\\n\") #> Target reliability: 0.8 cat(\"Achieved KR-20:   \", round(sim$reliability, 4), \"\\n\") #> Achieved KR-20:    0.8099 cat(\"Simulation method: \", sim$method, \"\\n\") #> Simulation method:  irtsimrel"},{"path":"https://joonho112.github.io/DPMirt/articles/simulation-study.html","id":"check-2-mcmc-convergence","dir":"Articles","previous_headings":"Diagnostic Checks for Simulation Validity","what":"Check 2: MCMC Convergence","title":"Simulation Study: Evaluating Prior Models and Posterior Summaries","text":"pre-computed fits, check:","code":"# Minimum ESS across all parameters min(fit$ess$items)   # Should be > 400 for 8000 post-burnin samples min(fit$ess$theta)  # Trace plot plot(fit, type = \"trace\")  # WAIC comparison cat(\"WAIC Normal:\", fit_normal$waic, \"\\n\") cat(\"WAIC DPM:   \", fit_dpm$waic, \"\\n\")"},{"path":"https://joonho112.github.io/DPMirt/articles/simulation-study.html","id":"check-3-posterior-predictive-check","dir":"Articles","previous_headings":"Diagnostic Checks for Simulation Validity","what":"Check 3: Posterior Predictive Check","title":"Simulation Study: Evaluating Prior Models and Posterior Summaries","text":"","code":"# Compare observed vs. predicted sum score distribution plot(fit, type = \"ppc\")"},{"path":[]},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/articles/simulation-study.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Simulation Study: Evaluating Prior Models and Posterior Summaries","text":"Lee, J. & Wind, S. Targeting toward inferential goals Bayesian Rasch models estimating person-specific latent traits. OSF Preprint. https://doi.org/10.31219/osf.io/qrw4n Lee, J. (2025). Reliability-targeted simulation item response data: Solving inverse design problem. arXiv preprint arXiv:2512.16012. https://arxiv.org/abs/2512.16012 Paganin, S., Paciorek, C. J., Wehrhahn, C., Rodríguez, ., Rabe-Hesketh, S., & de Valpine, P. (2023). Computational strategies estimation performance Bayesian semiparametric item response theory models. Journal Educational Behavioral Statistics, 48(2), 147–188. https://doi.org/10.3102/10769986221136105 Ghosh, M. (1992). Constrained Bayes estimation applications. JASA, 87(418), 533–540. Shen, W., & Louis, T. . (1998). Triple-goal estimates two-stage hierarchical models. JRSS-B, 60(2), 455–471.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/theory-irt-dpm.html","id":"overview","dir":"Articles","previous_headings":"","what":"1. Overview","title":"Mathematical Foundations: IRT Models and Dirichlet Process Mixture Priors","text":"vignette provides rigorous mathematical treatment theory underlying DPMirt package. intended statisticians methodologically-inclined researchers wish understand full probabilistic framework connecting Item Response Theory (IRT) measurement models, Bayesian hierarchical priors, Dirichlet Process Mixture (DPM) extensions, identification strategies, posterior summary methods. cover following topics depth: Bayesian Rasch model hierarchical structure 2PL 3PL extensions Identification indeterminacy post-hoc rescaling Dirichlet Process Mixture priors latent trait distribution concentration parameter α\\alpha hyperprior Posterior summary theory: PM, CB, GR estimators DP density reconstruction MCMC output Throughout, carefully distinguish established results IRT, Bayesian nonparametric, decision-theoretic literatures novel contributions work. DPMirt package synthesizes components unified computational framework; novelty lies primarily integration extending CB GR estimators semiparametric IRT setting. Note: vignette contains live MCMC computation. code blocks show model specifications mathematical formulas reference. applied examples actual model fitting, see companion vignettes models--workflow posterior-summaries.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/articles/theory-irt-dpm.html","id":"measurement-model","dir":"Articles","previous_headings":"2. The Bayesian Rasch Model","what":"2.1 Measurement Model","title":"Mathematical Foundations: IRT Models and Dirichlet Process Mixture Priors","text":"Rasch model (Rasch, 1960) specifies probability person pp(p=1,…,N)(p = 1, \\ldots, N) endorses item ii(=1,…,)(= 1, \\ldots, ) function two parameters: person ability θp\\theta_p item difficulty βi\\beta_i. measurement model : yip∼Bernoulli(πip), y_{ip} \\sim \\text{Bernoulli}(\\pi_{ip}),  item response function (IRF) maps latent linear predictor probability scale via logistic link: logit(πip)=θp−βi. \\text{logit}(\\pi_{ip}) = \\theta_p - \\beta_i. Equivalently, probability correct response : πip=P(yip=1∣θp,βi)=exp⁡(θp−βi)1+exp⁡(θp−βi). \\pi_{ip} = P(y_{ip} = 1 \\mid \\theta_p, \\beta_i) = \\frac{\\exp(\\theta_p - \\beta_i)}{1 + \\exp(\\theta_p - \\beta_i)}. Rasch model embodies principle specific objectivity: difference two persons’ abilities can estimated independently items administered, conversely item difficulties. NIMBLE, measurement model expressed :","code":"for (j in 1:N) {   for (i in 1:I) {     y[j, i] ~ dbern(pi[j, i])     logit(pi[j, i]) <- eta[j] - beta[i]   } }"},{"path":"https://joonho112.github.io/DPMirt/articles/theory-irt-dpm.html","id":"sufficient-statistics","dir":"Articles","previous_headings":"2. The Bayesian Rasch Model","what":"2.2 Sufficient Statistics","title":"Mathematical Foundations: IRT Models and Dirichlet Process Mixture Priors","text":"fundamental property Rasch model total score rp=∑=1Iyipr_p = \\sum_{=1}^{} y_{ip} sufficient statistic θp\\theta_p. joint likelihood factorizes : P(𝒚p∣θp,𝜷)=exp⁡(rpθp−∑iyipβi)∏=1I(1+exp(θp−βi)), P(\\mathbf{y}_p \\mid \\theta_p, \\boldsymbol{\\beta}) = \\frac{\\exp\\left(r_p \\theta_p - \\sum_i y_{ip} \\beta_i\\right)}      {\\prod_{=1}^{} \\left(1 + \\exp(\\theta_p - \\beta_i)\\right)},  , Neyman-Fisher factorization theorem, establishes posterior θp\\theta_p depends data rpr_p. Key insight: Rasch model standard unidimensional IRT model sufficiency property. Two persons total score identical likelihoods θ\\theta.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/theory-irt-dpm.html","id":"hierarchical-framework","dir":"Articles","previous_headings":"2. The Bayesian Rasch Model","what":"2.3 Hierarchical Framework","title":"Mathematical Foundations: IRT Models and Dirichlet Process Mixture Priors","text":"full Bayesian Rasch model three levels: Level 1 (Measurement model): p(𝒀∣𝜽,𝜷)=∏p=1N∏=1Iπipyip(1−πip)1−yip, p(\\mathbf{Y} \\mid \\boldsymbol{\\theta}, \\boldsymbol{\\beta}) = \\prod_{p=1}^{N} \\prod_{=1}^{} \\pi_{ip}^{y_{ip}} (1 - \\pi_{ip})^{1 - y_{ip}},  πip\\pi_{ip} defined Rasch IRF . Level 2 (Population model): Person abilities drawn θp∼iidG\\theta_p \\stackrel{iid}{\\sim} G item difficulties βi∼iidN(μβ,σβ2)\\beta_i \\stackrel{iid}{\\sim} \\text{N}(\\mu_\\beta, \\sigma^2_\\beta). choice GG two approaches diverge: parametric prior G=N(μθ,σθ2)G = \\text{N}(\\mu_\\theta, \\sigma^2_\\theta), DPM prior G∼DP(α,G0)G \\sim \\text{DP}(\\alpha, G_0) (Section 5). Level 3 (Hyperpriors): Normal prior, μθ∼N(0,3)\\mu_\\theta \\sim \\text{N}(0, 3) σθ2∼Inv-Gamma(2.01,1.01)\\sigma^2_\\theta \\sim \\text{Inv-Gamma}(2.01, 1.01). DPM hyperprior structure detailed Section 5.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/theory-irt-dpm.html","id":"posterior-mean-and-shrinkage","dir":"Articles","previous_headings":"2. The Bayesian Rasch Model","what":"2.4 Posterior Mean and Shrinkage","title":"Mathematical Foundations: IRT Models and Dirichlet Process Mixture Priors","text":"Normal population prior G=N(μθ,σθ2)G = \\text{N}(\\mu_\\theta, \\sigma^2_\\theta), posterior mean (expected posteriori, EAP) estimate θp\\theta_p exhibits shrinkage toward population mean. EAP can approximately characterized weighted combination likelihood-based estimate prior mean: θ̂pEAP≈wpθ̂pMLE+(1−wp)μθ, \\hat{\\theta}_p^{\\text{EAP}} \\approx w_p \\hat{\\theta}_p^{\\text{MLE}} + (1 - w_p) \\mu_\\theta,  θ̂pMLE\\hat{\\theta}_p^{\\text{MLE}} maximum likelihood estimate wpw_p shrinkage weight: wp=σθ2σθ2+se(θ̂p)2. w_p = \\frac{\\sigma^2_\\theta}{\\sigma^2_\\theta + \\text{se}(\\hat{\\theta}_p)^2}. se(θ̂p)2=1/(θ̂p)\\text{se}(\\hat{\\theta}_p)^2 = 1 / (\\hat{\\theta}_p) squared standard error. Key consequences: persons extreme scores pulled strongly toward μθ\\mu_\\theta (larger standard errors); weight wp∈(0,1)w_p \\(0, 1) person-specific; items mean less shrinkage. Key insight: Shrinkage produces underdispersion posterior means relative true population distribution. variance {θ̂pEAP}p=1N\\{\\hat{\\theta}_p^{\\text{EAP}}\\}_{p=1}^N strictly less population variance σθ2\\sigma^2_\\theta. underdispersion primary motivation CB GR estimators (Section 7).","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/theory-irt-dpm.html","id":"test-reliability","dir":"Articles","previous_headings":"2. The Bayesian Rasch Model","what":"2.5 Test Reliability","title":"Mathematical Foundations: IRT Models and Dirichlet Process Mixture Priors","text":"average shrinkage weight across persons provides measure test reliability analogous classical reliability coefficients: w‾=σθ2σθ2+MSEM¯, \\bar{w} = \\frac{\\sigma^2_\\theta}{\\sigma^2_\\theta + \\overline{\\text{MSEM}}},  MSEM¯\\overline{\\text{MSEM}} mean squared error measurement averaged across persons. Fisher information person pp Rasch model : (θp)=∑=1IPi(θp)(1−Pi(θp)), (\\theta_p) = \\sum_{=1}^{} P_i(\\theta_p)(1 - P_i(\\theta_p)),  Pi(θp)=logistic(θp−βi)P_i(\\theta_p) = \\text{logistic}(\\theta_p - \\beta_i) probability correct response. information maximized θp=βi\\theta_p = \\beta_i (.e., person ability matches item difficulty) equals /4I/4 items difficulty person’s ability. connects Rasch separation index: G=SDadjustedRMSE, G = \\frac{\\text{SD}_{\\text{adjusted}}}{\\text{RMSE}},  associated strata count H=(4G+1)/3H = (4G + 1)/3, estimates number statistically distinguishable ability levels test can discriminate.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/articles/theory-irt-dpm.html","id":"two-parameter-logistic-model-2pl-irt","dir":"Articles","previous_headings":"3. The 2PL and 3PL Extensions","what":"3.1 Two-Parameter Logistic Model (2PL IRT)","title":"Mathematical Foundations: IRT Models and Dirichlet Process Mixture Priors","text":"2PL model (Birnbaum, 1968) extends Rasch model introducing item-specific discrimination parameters λi>0\\lambda_i > 0: logit(πip)=λi(θp−βi). \\text{logit}(\\pi_{ip}) = \\lambda_i (\\theta_p - \\beta_i). discrimination parameter λi\\lambda_i controls steepness item characteristic curve (ICC). Items higher λi\\lambda_i better distinguishing persons near difficulty level βi\\beta_i. NIMBLE: Note λi\\lambda_i constrained positive via log-normal prior: log⁡(λi)∼N(0.5,0.5)\\log(\\lambda_i) \\sim \\text{N}(0.5, 0.5). prior places median discrimination exp⁡(0.5)≈1.65\\exp(0.5) \\approx 1.65 reasonable spread practically relevant values. Key difference Rasch: total score rpr_p longer sufficient θp\\theta_p 2PL model. specific pattern correct incorrect responses matters items contribute differentially likelihood.","code":"for (i in 1:I) {   for (j in 1:N) {     y[j, i] ~ dbern(pi[j, i])     logit(pi[j, i]) <- lambda[i] * (eta[j] - beta[i])   } } for (i in 1:I) {   log(lambda[i]) ~ dnorm(0.5, var = 0.5)   beta[i] ~ dnorm(0, var = sigma2_beta) }"},{"path":"https://joonho112.github.io/DPMirt/articles/theory-irt-dpm.html","id":"slope-intercept-si-parameterization","dir":"Articles","previous_headings":"3. The 2PL and 3PL Extensions","what":"3.2 Slope-Intercept (SI) Parameterization","title":"Mathematical Foundations: IRT Models and Dirichlet Process Mixture Priors","text":"alternative parameterization 2PL replaces (λi,βi)(\\lambda_i, \\beta_i) (λi,γi)(\\lambda_i, \\gamma_i), γi\\gamma_i intercept: logit(πip)=γi+λiθp. \\text{logit}(\\pi_{ip}) = \\gamma_i + \\lambda_i \\theta_p. two parameterizations related : γi=−λiβi⇔βi=−γi/λi. \\gamma_i = -\\lambda_i \\beta_i \\quad \\Longleftrightarrow \\quad \\beta_i = -\\gamma_i / \\lambda_i. NIMBLE: SI parameterization sometimes preferred computational reasons linear predictor additive θp\\theta_p, can improve mixing certain MCMC samplers. DPMirt supports parameterizations.","code":"for (i in 1:I) {   for (j in 1:N) {     y[j, i] ~ dbern(pi[j, i])     logit(pi[j, i]) <- lambda[i] * eta[j] + gamma[i]   } }"},{"path":"https://joonho112.github.io/DPMirt/articles/theory-irt-dpm.html","id":"three-parameter-logistic-model-3pl","dir":"Articles","previous_headings":"3. The 2PL and 3PL Extensions","what":"3.3 Three-Parameter Logistic Model (3PL)","title":"Mathematical Foundations: IRT Models and Dirichlet Process Mixture Priors","text":"3PL model (Birnbaum, 1968) adds lower asymptote parameter δi∈[0,1]\\delta_i \\[0, 1] representing probability person low ability still endorses item (“guessing” parameter): πip=δi+(1−δi)⋅logistic(λi(θp−βi)). \\pi_{ip} = \\delta_i + (1 - \\delta_i) \\cdot \\text{logistic}(\\lambda_i (\\theta_p - \\beta_i)). item response probability approaches δi\\delta_i (rather 0) θp→−∞\\theta_p \\-\\infty. upper asymptote remains 1. NIMBLE: prior δi∼Beta(4,12)\\delta_i \\sim \\text{Beta}(4, 12) mean 4/16=0.254/16 = 0.25 concentrates mass 0.05 0.45, reflecting prior belief guessing parameters typically modest. standard informative prior lower asymptote (De Ayala, 2022).","code":"for (i in 1:I) {   for (j in 1:N) {     y[j, i] ~ dbern(pi[j, i])     pi[j, i] <- delta[i] + (1 - delta[i]) * linearReg[j, i]     logit(linearReg[j, i]) <- lambda[i] * (eta[j] - beta[i])   } } for (i in 1:I) {   delta[i] ~ dbeta(4, 12) }"},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/articles/theory-irt-dpm.html","id":"the-identification-problem","dir":"Articles","previous_headings":"4. Identification and Rescaling","what":"4.1 The Identification Problem","title":"Mathematical Foundations: IRT Models and Dirichlet Process Mixture Priors","text":"IRT models contain identification indeterminacy: certain transformations parameters leave likelihood invariant. Without constraints, posterior improper along directions. Rasch model (location indeterminacy): constant cc, transformation θp↦θp+c\\theta_p \\mapsto \\theta_p + c, βi↦βi+c\\beta_i \\mapsto \\beta_i + c leaves θp−βi\\theta_p - \\beta_i unchanged hence likelihood invariant. one degree freedom (location) indeterminate. 2PL 3PL models (location + scale indeterminacy): constants cc d>0d > 0, transformation θp↦(θp+c)/d\\theta_p \\mapsto (\\theta_p + c) / d, βi↦(βi+c)/d\\beta_i \\mapsto (\\beta_i + c) / d, λi↦λi⋅d\\lambda_i \\mapsto \\lambda_i \\cdot d leaves λi(θp−βi)\\lambda_i(\\theta_p - \\beta_i) invariant. Two degrees freedom (location scale) indeterminate. choice identification strategy affects interpretation parameters efficiency MCMC sampling.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/theory-irt-dpm.html","id":"three-identification-strategies","dir":"Articles","previous_headings":"4. Identification and Rescaling","what":"4.2 Three Identification Strategies","title":"Mathematical Foundations: IRT Models and Dirichlet Process Mixture Priors","text":"DPMirt supports three identification strategies, selected via identification argument dpmirt_spec(): Strategy 1: constrained_ability – Fix θ∼N(0,1)\\theta \\sim \\text{N}(0, 1). Resolves location scale indeterminacy constrains latent distribution incompatible DPM prior. Strategy 2: constrained_item – Center item parameters MCMC. Rasch: βi*=βitmp−1I∑j=1Iβjtmp. \\beta_i^* = \\beta_i^{\\text{tmp}} - \\frac{1}{}\\sum_{j=1}^{} \\beta_j^{\\text{tmp}}. 2PL/3PL, β\\beta (γ\\gamma) log⁡(λ)\\log(\\lambda) centered: βi*=βitmp−β‾tmp,log⁡(λi*)=log⁡(λitmp)−log⁡λ¯tmp. \\beta_i^* = \\beta_i^{\\text{tmp}} - \\bar{\\beta}^{\\text{tmp}}, \\quad \\log(\\lambda_i^*) = \\log(\\lambda_i^{\\text{tmp}}) - \\overline{\\log \\lambda}^{\\text{tmp}}. approach identifies model within MCMC without constraining ability distribution, making compatible Normal DPM priors. Strategy 3: unconstrained – Place identification constraints MCMC. Instead, apply post-hoc rescaling posterior samples achieve identification. approach, advocated Paganin et al. (2023), advantage interfering sampler’s geometry.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/theory-irt-dpm.html","id":"post-hoc-rescaling-formulas","dir":"Articles","previous_headings":"4. Identification and Rescaling","what":"4.3 Post-hoc Rescaling Formulas","title":"Mathematical Foundations: IRT Models and Dirichlet Process Mixture Priors","text":"unconstrained models, rescaling applied iteration--iteration MCMC output. Let superscript (s)(s) denote MCMC iteration ss. Rasch model (location shift ): βi*(s)=βi(s)−β‾(s),θp*(s)=θp(s)−β‾(s), \\beta_i^{*(s)} = \\beta_i^{(s)} - \\bar{\\beta}^{(s)}, \\quad \\theta_p^{*(s)} = \\theta_p^{(s)} - \\bar{\\beta}^{(s)},  β‾(s)=1I∑=1Iβi(s)\\bar{\\beta}^{(s)} = \\frac{1}{}\\sum_{=1}^{} \\beta_i^{(s)} mean item difficulty iteration ss. 2PL/3PL IRT parameterization (location + scale): c(s)=β‾(s),d(s)=(∏=1Iλi(s))−1/, c^{(s)} = \\bar{\\beta}^{(s)}, \\quad d^{(s)} = \\left(\\prod_{=1}^{} \\lambda_i^{(s)}\\right)^{-1/}, βi*(s)=βi(s)−c(s)d(s),λi*(s)=λi(s)⋅d(s),θp*(s)=θp(s)−c(s)d(s). \\beta_i^{*(s)} = \\frac{\\beta_i^{(s)} - c^{(s)}}{d^{(s)}}, \\quad \\lambda_i^{*(s)} = \\lambda_i^{(s)} \\cdot d^{(s)}, \\quad \\theta_p^{*(s)} = \\frac{\\theta_p^{(s)} - c^{(s)}}{d^{(s)}}. scale factor d(s)d^{(s)} inverse geometric mean discriminations, ensuring geometric mean rescaled λ*\\lambda^* equals 1. 2PL/3PL SI parameterization: c(s)=∑iγi(s)∑iλi(s),d(s)=(∏=1Iλi(s))−1/, c^{(s)} = \\frac{\\sum_i \\gamma_i^{(s)}}{\\sum_i \\lambda_i^{(s)}}, \\quad d^{(s)} = \\left(\\prod_{=1}^{} \\lambda_i^{(s)}\\right)^{-1/}, γi*(s)=γi(s)−λi(s)⋅c(s),λi*(s)=λi(s)⋅d(s),θp*(s)=θp(s)+c(s)d(s). \\gamma_i^{*(s)} = \\gamma_i^{(s)} - \\lambda_i^{(s)} \\cdot c^{(s)}, \\quad \\lambda_i^{*(s)} = \\lambda_i^{(s)} \\cdot d^{(s)}, \\quad \\theta_p^{*(s)} = \\frac{\\theta_p^{(s)} + c^{(s)}}{d^{(s)}}. Note sign difference θ\\theta SI case: γi=−λiβi\\gamma_i = -\\lambda_i \\beta_i, location shift opposite sign compared IRT parameterization. Key insight: 3PL guessing parameter δi\\delta_i scale-invariant require rescaling. enters model multiplicatively outside logistic function unaffected affine transformations ability scale.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/theory-irt-dpm.html","id":"efficiency-of-unconstrained-sampling","dir":"Articles","previous_headings":"4. Identification and Rescaling","what":"4.4 Efficiency of Unconstrained Sampling","title":"Mathematical Foundations: IRT Models and Dirichlet Process Mixture Priors","text":"Paganin et al. (2023) found unconstrained sampling post-hoc rescaling generally efficient strategy, constraining parameters sampling can distort posterior geometry. DPMirt uses unconstrained identification default 2PL 3PL models, constrained_item default Rasch (difference smaller).","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/articles/theory-irt-dpm.html","id":"the-dirichlet-process","dir":"Articles","previous_headings":"5. Dirichlet Process Mixture Priors","what":"5.1 The Dirichlet Process","title":"Mathematical Foundations: IRT Models and Dirichlet Process Mixture Priors","text":"Dirichlet Process (DP; Ferguson, 1973) distribution probability distributions. random measure G∼DP(α,G0)G \\sim \\text{DP}(\\alpha, G_0) satisfies: every finite measurable partition (A1,…,)(A_1, \\ldots, A_m), (G(A1),…,G())∼Dirichlet(αG0(A1),…,αG0()). (G(A_1), \\ldots, G(A_m)) \\sim \\text{Dirichlet}(\\alpha G_0(A_1), \\ldots, \\alpha G_0(A_m)). Three properties essential: (1) Almost-sure discreteness – draws DP discrete probability one, inducing clustering. (2) Centering G0G_0 – 𝔼[G()]=G0()\\mathbb{E}[G()] = G_0() measurable AA. (3) Concentration control – α→∞\\alpha \\\\infty, G→G0G \\G_0; α→0\\alpha \\0, GG concentrates single atom.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/theory-irt-dpm.html","id":"the-chinese-restaurant-process","dir":"Articles","previous_headings":"5. Dirichlet Process Mixture Priors","what":"5.2 The Chinese Restaurant Process","title":"Mathematical Foundations: IRT Models and Dirichlet Process Mixture Priors","text":"Chinese Restaurant Process (CRP; Blackwell & MacQueen, 1973) characterizes partition structure induced DP. Customers (persons) arrive sequentially restaurant infinitely many tables (clusters). Customer pp joins existing table kk probability nk/(α+p−1)n_k / (\\alpha + p - 1) starts new table probability α/(α+p−1)\\alpha / (\\alpha + p - 1), nkn_k current table size. Key insight: CRP exhibits “rich get richer” property: tables customers proportionally likely attract new customers. produces power-law distribution cluster sizes explains DP mixtures naturally create large clusters many small ones. CRP partition exchangeable (independent arrival order), enabling Gibbs-based MCMC. expected number clusters : 𝔼[KN∣α]=∑p=1Nαα+p−1≈αlog⁡(N)large N. \\mathbb{E}[K_N \\mid \\alpha] = \\sum_{p=1}^{N} \\frac{\\alpha}{\\alpha + p - 1} \\approx \\alpha \\log(N) \\quad \\text{large } N. logarithmic growth reasonable modeling assumption latent trait distributions.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/theory-irt-dpm.html","id":"dpm-irt-model-specification","dir":"Articles","previous_headings":"5. Dirichlet Process Mixture Priors","what":"5.3 DPM-IRT Model Specification","title":"Mathematical Foundations: IRT Models and Dirichlet Process Mixture Priors","text":"DPM-IRT model replaces parametric Normal prior DP Mixture. measurement model unchanged; DPM prior specifies: θp∣zp,𝝁̃,𝝈̃2∼N(μ̃zp,σ̃zp2), \\theta_p \\mid z_p, \\tilde{\\boldsymbol{\\mu}}, \\tilde{\\boldsymbol{\\sigma}}^2 \\sim \\text{N}(\\tilde{\\mu}_{z_p}, \\tilde{\\sigma}^2_{z_p}),  zp∈{1,2,…}z_p \\\\{1, 2, \\ldots\\} cluster assignment person pp. CRP prior cluster assignments: 𝒛=(z1,…,zN)∼CRP(α,N). \\mathbf{z} = (z_1, \\ldots, z_N) \\sim \\text{CRP}(\\alpha, N). Base measure cluster parameters: G0=N(0,σμ2)×Inv-Gamma(ν1,ν2), G_0 = \\text{N}(0, \\sigma^2_\\mu) \\times \\text{Inv-Gamma}(\\nu_1, \\nu_2),  meaning cluster mm: μ̃m∼N(0,σμ2),σ̃m2∼Inv-Gamma(ν1,ν2). \\tilde{\\mu}_m \\sim \\text{N}(0, \\sigma^2_\\mu), \\quad \\tilde{\\sigma}^2_m \\sim \\text{Inv-Gamma}(\\nu_1, \\nu_2). Default hyperparameters (following Paganin et al., 2023): σμ2=2,ν1=2.01,ν2=1.01. \\sigma^2_\\mu = 2, \\quad \\nu_1 = 2.01, \\quad \\nu_2 = 1.01. values place cluster variance prior just boundary finite mean (ν1>2\\nu_1 > 2) 𝔼[σ̃2]≈1\\mathbb{E}[\\tilde{\\sigma}^2] \\approx 1. NIMBLE, DPM prior implemented via CRP representation:","code":"# CRP cluster assignments zi[1:N] ~ dCRP(alpha, size = N)  # Concentration parameter hyperprior alpha ~ dgamma(a, b)  # Person abilities: Normal kernel with cluster-specific parameters for (j in 1:N) {   eta[j] ~ dnorm(mu_j[j], var = s2_j[j])   mu_j[j]  <- muTilde[zi[j]]   s2_j[j]  <- s2Tilde[zi[j]] }  # Cluster parameters drawn from base measure G0 for (m in 1:M) {   muTilde[m]  ~ dnorm(0, var = s2_mu)   s2Tilde[m]  ~ dinvgamma(nu1, nu2) }"},{"path":"https://joonho112.github.io/DPMirt/articles/theory-irt-dpm.html","id":"stick-breaking-vs--crp","dir":"Articles","previous_headings":"5. Dirichlet Process Mixture Priors","what":"5.4 Stick-Breaking vs. CRP","title":"Mathematical Foundations: IRT Models and Dirichlet Process Mixture Priors","text":"alternative CRP Sethuraman’s (1994) stick-breaking construction, represents GG infinite discrete measure: G=∑h=1∞whδθh*,wh=vh∏ℓ<h(1−vℓ),vh∼iidBeta(1,α), G = \\sum_{h=1}^{\\infty} w_h \\delta_{\\theta^*_h}, \\quad w_h = v_h \\prod_{\\ell < h}(1 - v_\\ell), \\quad v_h \\stackrel{iid}{\\sim} \\text{Beta}(1, \\alpha),  {θh*}∼iidG0\\{\\theta^*_h\\} \\stackrel{iid}{\\sim} G_0. DPMirt uses CRP representation instead, natively supported NIMBLE’s dCRP distribution offers direct access cluster assignments zpz_p without requiring explicit truncation number components.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/theory-irt-dpm.html","id":"practical-truncation","dir":"Articles","previous_headings":"5. Dirichlet Process Mixture Priors","what":"5.5 Practical Truncation","title":"Mathematical Foundations: IRT Models and Dirichlet Process Mixture Priors","text":"Although CRP defined infinitely many potential clusters, NIMBLE requires finite upper bound MM pre-allocated cluster parameter vectors. default DPMirt M=50M = 50. Since 𝔼[KN∣α]≈αlog⁡(N)\\mathbb{E}[K_N \\mid \\alpha] \\approx \\alpha \\log(N) typical applications α∈[0.5,5]\\alpha \\[0.5, 5] N≤2,000N \\leq 2{,}000, default M=50M = 50 conservative. MCMC sampler creates clusters approaching MM, user increase via M argument dpmirt_spec().","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/articles/theory-irt-dpm.html","id":"role-of-alpha","dir":"Articles","previous_headings":"6. The Concentration Parameter (α\\alpha)","what":"6.1 Role of α\\alpha","title":"Mathematical Foundations: IRT Models and Dirichlet Process Mixture Priors","text":"concentration parameter α\\alpha controls (1) expected number clusters 𝔼[KN∣α]\\mathbb{E}[K_N \\mid \\alpha], (2) degree departure G0G_0, (3) resolution density estimation. large NN: 𝔼[KN∣α]=∑p=1Nαα+p−1≈αlog⁡(N). \\mathbb{E}[K_N \\mid \\alpha] = \\sum_{p=1}^{N} \\frac{\\alpha}{\\alpha + p - 1} \\approx \\alpha \\log(N). Illustrative values N=500N = 500:","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/theory-irt-dpm.html","id":"gamma-hyperprior","dir":"Articles","previous_headings":"6. The Concentration Parameter (α\\alpha)","what":"6.2 Gamma Hyperprior","title":"Mathematical Foundations: IRT Models and Dirichlet Process Mixture Priors","text":"DPMirt places α∼Gamma(,b)\\alpha \\sim \\text{Gamma}(, b) (shape-rate parameterization, 𝔼[α]=/b\\mathbb{E}[\\alpha] = /b). default α∼Gamma(1,3)\\alpha \\sim \\text{Gamma}(1, 3) following Paganin et al. (2023), 𝔼[α]=1/3\\mathbb{E}[\\alpha] = 1/3. conservative prior favors parsimonious models clusters, allowing data drive discovery multiple subpopulations.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/theory-irt-dpm.html","id":"principled-elicitation-via-dpprior","dir":"Articles","previous_headings":"6. The Concentration Parameter (α\\alpha)","what":"6.3 Principled Elicitation via DPprior","title":"Mathematical Foundations: IRT Models and Dirichlet Process Mixture Priors","text":"DPprior package (Lee, 2026) translates beliefs μK=𝔼[KN]\\mu_K = \\mathbb{E}[K_N] Gamma parameters (,b)(, b) via moment-matching. DPMirt integrates dpmirt_alpha_prior(): DPprior installed, DPMirt falls back Gamma(1, 3). Key insight: α\\alpha hyperprior meaningfully impacts inference moderate sample sizes. Confirmatory applications benefit principled elicitation encoding domain knowledge population heterogeneity.","code":"alpha_ab <- dpmirt_alpha_prior(N = 500, mu_K = 5, confidence = \"medium\") spec <- dpmirt_spec(data, model = \"rasch\", prior = \"dpm\",                     alpha_prior = alpha_ab)"},{"path":"https://joonho112.github.io/DPMirt/articles/theory-irt-dpm.html","id":"posterior-summary-theory","dir":"Articles","previous_headings":"","what":"7. Posterior Summary Theory","title":"Mathematical Foundations: IRT Models and Dirichlet Process Mixture Priors","text":"central theme DPMirt package choice posterior summary method guided inferential goal. Different loss functions lead different optimal estimators, single estimator universally best.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/theory-irt-dpm.html","id":"loss-functions-and-optimality","dir":"Articles","previous_headings":"7. Posterior Summary Theory","what":"7.1 Loss Functions and Optimality","title":"Mathematical Foundations: IRT Models and Dirichlet Process Mixture Priors","text":"Consider NN persons true abilities θ1,…,θN\\theta_1, \\ldots, \\theta_N estimates θ̂1,…,θ̂N\\hat{\\theta}_1, \\ldots, \\hat{\\theta}_N. define three loss functions corresponding three inferential goals. Goal 1: Individual estimation accuracy. MSEL=1N∑p=1N(θ̂p−θp)2. \\text{MSEL} = \\frac{1}{N} \\sum_{p=1}^{N} (\\hat{\\theta}_p - \\theta_p)^2. posterior mean (PM) minimizes MSEL expectation posterior. classical Bayes estimator squared error loss. Goal 2: Ranking quality. MSELP=1N∑p=1N(R̂pN−RpN)2, \\text{MSELP} = \\frac{1}{N} \\sum_{p=1}^{N} \\left(\\frac{\\hat{R}_p}{N} - \\frac{R_p}{N}\\right)^2,  R̂p=rank(θ̂p)\\hat{R}_p = \\text{rank}(\\hat{\\theta}_p) Rp=rank(θp)R_p = \\text{rank}(\\theta_p) estimated true ranks, respectively. loss measures well estimator preserves ordering persons. Goal 3: Distribution recovery. KS=supt|ĜN(t)−GN(t)|, \\text{KS} = \\sup_{t} \\left|\\hat{G}_N(t) - G_N(t)\\right|,  ĜN(t)=1N∑p𝟏(θ̂p≤t)\\hat{G}_N(t) = \\frac{1}{N}\\sum_p \\mathbf{1}(\\hat{\\theta}_p \\leq t) GN(t)=1N∑p𝟏(θp≤t)G_N(t) = \\frac{1}{N}\\sum_p \\mathbf{1}(\\theta_p \\leq t) empirical distribution functions estimates true values. loss measures well set estimates reproduces shape true ability distribution. Key insight: PM estimator optimal Goal 1 performs poorly Goals 2 3 due shrinkage-induced underdispersion. CB estimator corrects underdispersion (Goal 3), GR estimator simultaneously addresses ranking distribution recovery (Goals 2 3).","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/theory-irt-dpm.html","id":"posterior-mean-pm","dir":"Articles","previous_headings":"7. Posterior Summary Theory","what":"7.2 Posterior Mean (PM)","title":"Mathematical Foundations: IRT Models and Dirichlet Process Mixture Priors","text":"posterior mean familiar Bayesian point estimate: θ̂pPM=𝔼[θp∣𝒀]=1S∑s=1Sθp(s), \\hat{\\theta}_p^{\\text{PM}} = \\mathbb{E}[\\theta_p \\mid \\mathbf{Y}] = \\frac{1}{S} \\sum_{s=1}^{S} \\theta_p^{(s)},  θp(s)\\theta_p^{(s)} value θp\\theta_p MCMC iteration ss SS total number post-burnin samples. PM minimizes posterior expected squared error loss person individually. However, set posterior means {θ̂pPM}p=1N\\{\\hat{\\theta}_p^{\\text{PM}}\\}_{p=1}^N underdispersed: empirical variance strictly less posterior expectation population variance. underdispersion distorts shape estimated ability distribution can bias percentile-based inferences.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/theory-irt-dpm.html","id":"constrained-bayes-cb","dir":"Articles","previous_headings":"7. Posterior Summary Theory","what":"7.3 Constrained Bayes (CB)","title":"Mathematical Foundations: IRT Models and Dirichlet Process Mixture Priors","text":"Constrained Bayes estimator, introduced Ghosh (1992) developed Louis (1984) Ghosh Kim (2002), addresses underdispersion posterior mean imposing two constraints: Match marginal mean: 1N∑pθ̂pCB=η‾\\frac{1}{N}\\sum_p \\hat{\\theta}_p^{\\text{CB}} = \\bar{\\eta} (PM). Match marginal variance: Var(θ̂pCB)=Vη+λ‾\\text{Var}(\\hat{\\theta}_p^{\\text{CB}}) = V_\\eta + \\bar{\\lambda} (match posterior expected population variance). constraints yield following closed-form estimator: θ̂pCB=η‾+(ηp−η‾)1+λ‾Vη, \\hat{\\theta}_p^{\\text{CB}} = \\bar{\\eta} + (\\eta_p - \\bar{\\eta}) \\sqrt{1 + \\frac{\\bar{\\lambda}}{V_\\eta}},  : ηp=θ̂pPM\\eta_p = \\hat{\\theta}_p^{\\text{PM}} posterior mean person pp, η‾=1N∑pηp\\bar{\\eta} = \\frac{1}{N}\\sum_p \\eta_p grand mean posterior means, λ‾=1N∑pVar(θp∣𝒀)\\bar{\\lambda} = \\frac{1}{N}\\sum_p \\text{Var}(\\theta_p \\mid \\mathbf{Y}) mean posterior variance, Vη=Var(η1,…,ηN)V_\\eta = \\text{Var}(\\eta_1, \\ldots, \\eta_N) sample variance posterior means (computed R’s var(), .e., N−1N-1 denominator). CB estimator inflates deviations posterior mean grand mean factor 1+λ‾/Vη\\sqrt{1 + \\bar{\\lambda}/V_\\eta}. factor always greater 1 (since λ‾>0\\bar{\\lambda} > 0), CB estimates dispersed posterior means. Interpretation CB scaling factor: ratio λ‾/Vη\\bar{\\lambda}/V_\\eta measures “severity shrinkage.” individual posterior variances λ‾\\bar{\\lambda} large relative -person variation VηV_\\eta (.e., test unreliable), scaling factor large CB makes substantial corrections. test highly reliable (λ‾≪Vη\\bar{\\lambda} \\ll V_\\eta), CB PM estimates nearly identical.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/theory-irt-dpm.html","id":"triple-goal-gr","dir":"Articles","previous_headings":"7. Posterior Summary Theory","what":"7.4 Triple-Goal (GR)","title":"Mathematical Foundations: IRT Models and Dirichlet Process Mixture Priors","text":"Triple-Goal estimator, introduced Shen Louis (1998), simultaneously addresses three goals: individual estimation, ranking, distribution recovery. computationally intensive three methods provides balanced trade-. GR algorithm proceeds four steps: Step 1: Posterior mean ranks. MCMC iteration ss, rank NN persons θ(s)\\theta^{(s)} values. Average ranks across iterations: R‾p=1S∑s=1SRp(s),Rp(s)=rank(θp(s)) among θ1(s),…,θN(s). \\bar{R}_p = \\frac{1}{S} \\sum_{s=1}^{S} R_p^{(s)}, \\quad \\text{} R_p^{(s)} = \\text{rank}(\\theta_p^{(s)}) \\text{ among } \\theta_1^{(s)}, \\ldots, \\theta_N^{(s)}. Equivalently, R‾p\\bar{R}_p can computed : R‾p=∑q=1NP(θq≤θp∣𝒀), \\bar{R}_p = \\sum_{q=1}^{N} P(\\theta_q \\leq \\theta_p \\mid \\mathbf{Y}),  expected rank person pp posterior. Step 2: Integer ranks. Convert (generally non-integer) posterior mean ranks integer ranks: R̂p=rank(R‾p)∈{1,2,…,N}. \\hat{R}_p = \\text{rank}(\\bar{R}_p) \\\\{1, 2, \\ldots, N\\}. Ties R‾p\\bar{R}_p broken randomly. Step 3: ISEL empirical distribution function. Compute integrated squared error loss (ISEL) optimal estimator population EDF: ĜN(t)=1N∑p=1NP(θp≤t∣𝒀). \\hat{G}_N(t) = \\frac{1}{N} \\sum_{p=1}^{N} P(\\theta_p \\leq t \\mid \\mathbf{Y}). posterior expectation true EDF implemented pooling posterior samples across persons. Step 4: Quantile inversion. Assign person value ĜN\\hat{G}_N corresponding integer rank: θ̂pGR=ĜN−1(2R̂p−12N). \\hat{\\theta}_p^{\\text{GR}} = \\hat{G}_N^{-1}\\left(\\frac{2\\hat{R}_p - 1}{2N}\\right). fraction (2R̂p−1)/(2N)(2\\hat{R}_p - 1)/(2N) maps rank R̂p\\hat{R}_p midpoint corresponding probability bin, preventing boundary artifacts. Computational complexity. Step 1 requires O(S×Nlog⁡N)O(S \\times N \\log N) operations. S=5,000S = 5{,}000 N=500N = 500, runs seconds. DPMirt, GR estimator implemented .triple_goal(), adapted HETOP package:","code":"# Step 1: Posterior mean ranks rbar <- apply(   t(apply(s, 1, rank, ties.method = \"average\")),   2, mean )  # Step 2: Integer ranks rhat <- rank(rbar, ties.method = \"random\")  # Steps 3-4: ISEL EDF + quantile inversion theta_gr <- quantile(   c(s),                            # Pool all posterior samples   probs = (2 * rhat - 1) / (2 * K),   type = quantile_type )"},{"path":"https://joonho112.github.io/DPMirt/articles/theory-irt-dpm.html","id":"comparison-of-estimators","dir":"Articles","previous_headings":"7. Posterior Summary Theory","what":"7.5 Comparison of Estimators","title":"Mathematical Foundations: IRT Models and Dirichlet Process Mixture Priors","text":"following table summarizes properties three estimators: Practical guidance: educational testing applications percentile-based interpretations important (e.g., reporting student’s standing relative population), GR estimates preferred. applications focused individual point estimates (e.g., adaptive testing), PM estimates optimal. CB provides useful middle ground computational simplicity PM.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/articles/theory-irt-dpm.html","id":"mixture-density-per-iteration","dir":"Articles","previous_headings":"8. DP Density Reconstruction","what":"8.1 Mixture Density per Iteration","title":"Mathematical Foundations: IRT Models and Dirichlet Process Mixture Priors","text":"MCMC iteration ss, DP posterior induces mixture density: fs(x)=∑k=1Ksws,kϕ(x;μ̃s,k,σ̃s,k2), f_s(x) = \\sum_{k=1}^{K_s} w_{s,k} \\, \\phi(x; \\tilde{\\mu}_{s,k}, \\tilde{\\sigma}^2_{s,k}),  KsK_s number occupied clusters, ws,kw_{s,k} cluster weight, ϕ(⋅;μ,σ2)\\phi(\\cdot; \\mu, \\sigma^2) denotes Normal density.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/theory-irt-dpm.html","id":"posterior-predictive-density-and-credible-bands","dir":"Articles","previous_headings":"8. DP Density Reconstruction","what":"8.2 Posterior Predictive Density and Credible Bands","title":"Mathematical Foundations: IRT Models and Dirichlet Process Mixture Priors","text":"posterior predictive density averages MCMC iterations: f̂(x)=1S∑s=1Sfs(x), \\hat{f}(x) = \\frac{1}{S} \\sum_{s=1}^{S} f_s(x),  integrating sources uncertainty. Pointwise credible bands obtained taking quantiles {fs(x)}s=1S\\{f_s(x)\\}_{s=1}^S grid point: f̂lower(x)=Q0.025({fs(x)}),f̂upper(x)=Q0.975({fs(x)}). \\hat{f}^{\\text{lower}}(x) = Q_{0.025}(\\{f_s(x)\\}), \\quad \\hat{f}^{\\text{upper}}(x) = Q_{0.975}(\\{f_s(x)\\}). Caveat: pointwise credible bands, simultaneous bands. probability true density lies within band every point simultaneously less nominal level.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/theory-irt-dpm.html","id":"implementation-via-nimble","dir":"Articles","previous_headings":"8. DP Density Reconstruction","what":"8.3 Implementation via NIMBLE","title":"Mathematical Foundations: IRT Models and Dirichlet Process Mixture Priors","text":"DPMirt implements density reconstruction dpmirt_dp_density() function, following Paganin et al.’s (2023) approach: extract DP posterior samples, call NIMBLE’s getSamplesDPmeasure() obtain stick-breaking weights atoms, evaluate fs(x)f_s(x) grid, apply rescaling. unconstrained Rasch models, rescaling location shift (Jacobian = 1): fsrescaled(x)=fs(x+β‾(s)). f_s^{\\text{rescaled}}(x) = f_s(x + \\bar{\\beta}^{(s)}). 2PL/3PL models, location scale adjustments required: fsrescaled(x)=d(s)⋅fs(d(s)x+c(s)), f_s^{\\text{rescaled}}(x) = d^{(s)} \\cdot f_s(d^{(s)} x + c^{(s)}),  c(s)c^{(s)} location shift d(s)d^{(s)} scale factor.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/theory-irt-dpm.html","id":"attribution-table","dir":"Articles","previous_headings":"","what":"9. Attribution Table","title":"Mathematical Foundations: IRT Models and Dirichlet Process Mixture Priors","text":"following table clarifies provenance major component used DPMirt package.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/theory-irt-dpm.html","id":"references","dir":"Articles","previous_headings":"","what":"10. References","title":"Mathematical Foundations: IRT Models and Dirichlet Process Mixture Priors","text":"Antoniak, C. E. (1974). Mixtures Dirichlet processes applications Bayesian nonparametric problems. Annals Statistics, 2(6), 1152–1174. Berger, J. O. (1985). Statistical Decision Theory Bayesian Analysis (2nd ed.). Springer. Birnbaum, . (1968). latent trait models use inferring examinee’s ability. F. M. Lord & M. R. Novick (Eds.), Statistical Theories Mental Test Scores (pp. 397–479). Addison-Wesley. Blackwell, D., & MacQueen, J. B. (1973). Ferguson distributions via Polya urn schemes. Annals Statistics, 1(2), 353–355. De Ayala, R. J. (2022). Theory Practice Item Response Theory (2nd ed.). Guilford Press. Ferguson, T. S. (1973). Bayesian analysis nonparametric problems. Annals Statistics, 1(2), 209–230. Fox, J.-P. (2010). Bayesian Item Response Modeling: Theory Applications. Springer. Ghosh, M. (1992). Constrained Bayes estimation applications. Journal American Statistical Association, 87(418), 533–540. Ghosh, M., & Kim, M.-H. (2002). Bayes constrained Bayes estimators balanced loss. Statistics & Probability Letters, 59(2), 175–183. Lee, J. & Wind, S. Targeting toward inferential goals Bayesian Rasch models estimating person-specific latent traits. OSF Preprint. https://doi.org/10.31219/osf.io/qrw4n Lee, J. (2025). Reliability-targeted simulation item response data: Solving inverse design problem. arXiv preprint arXiv:2512.16012. https://arxiv.org/abs/2512.16012 Lee, J. (2026). Design-conditional prior elicitation Dirichlet Process mixtures: unified framework cluster counts weight control. arXiv preprint arXiv:2602.06301. https://arxiv.org/abs/2602.06301 Louis, T. . (1984). Estimating population parameter values using Bayes empirical Bayes methods. Journal American Statistical Association, 79(386), 393–398. Paganin, S., Paciorek, C. J., Wehrhahn, C., Rodríguez, ., Rabe-Hesketh, S., & de Valpine, P. (2023). Computational strategies estimation performance Bayesian semiparametric item response theory models. Journal Educational Behavioral Statistics, 48(2), 147–188. https://doi.org/10.3102/10769986221136105 Rasch, G. (1960). Probabilistic Models Intelligence Attainment Tests. Danish Institute Educational Research. Sethuraman, J. (1994). constructive definition Dirichlet priors. Statistica Sinica, 4(2), 639–650. Shen, W., & Louis, T. . (1998). Triple-goal estimates two-stage hierarchical models. Journal Royal Statistical Society: Series B (Statistical Methodology), 60(2), 455–471. Wright, B. D., & Masters, G. N. (1982). Rating Scale Analysis: Rasch Measurement. MESA Press.","code":""},{"path":"https://joonho112.github.io/DPMirt/articles/theory-irt-dpm.html","id":"whats-next","dir":"Articles","previous_headings":"","what":"What’s Next?","title":"Mathematical Foundations: IRT Models and Dirichlet Process Mixture Priors","text":"vignette covered mathematical foundations. practical guidance using models methods, see: vignette(\"models--workflow\", package = \"DPMirt\") – Step--step guide fitting Rasch, 2PL, 3PL models Normal DPM priors. Covers compile-, sample-many workflow. vignette(\"posterior-summaries\", package = \"DPMirt\") – Practical comparison PM, CB, GR estimators real data examples. Demonstrates estimator preferred. vignette(\"nimble-internals\", package = \"DPMirt\") – --hood details NIMBLE integration, custom samplers, getSamplesDPmeasure() workflow DP density reconstruction. questions vignette DPMirt package, please visit GitHub repository.","code":""},{"path":"https://joonho112.github.io/DPMirt/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"JoonHo Lee. Author, maintainer.","code":""},{"path":"https://joonho112.github.io/DPMirt/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Lee J (2026). DPMirt: Bayesian Semiparametric Item Response Theory Models Using Dirichlet Process Mixture Priors. R package version 0.1.0, https://joonho112.github.io/DPMirt/.","code":"@Manual{,   title = {DPMirt: Bayesian Semiparametric Item Response Theory Models Using Dirichlet Process Mixture Priors},   author = {JoonHo Lee},   year = {2026},   note = {R package version 0.1.0},   url = {https://joonho112.github.io/DPMirt/}, }"},{"path":"https://joonho112.github.io/DPMirt/index.html","id":"dpmirt-","dir":"","previous_headings":"","what":"DPMirt: Bayesian Semiparametric IRT with DPM Priors","title":"DPMirt: Bayesian Semiparametric IRT with DPM Priors","text":"Bayesian Semiparametric Item Response Theory Models Using Dirichlet Process Mixture Priors DPMirt fits Bayesian IRT models flexible, nonparametric ability distributions via NIMBLE. supports Rasch, 2PL, 3PL models standard Normal prior Dirichlet Process Mixture (DPM) prior, provides three posterior summary methods — PM, CB, GR — designed different inferential goals.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"DPMirt: Bayesian Semiparametric IRT with DPM Priors","text":"Install development version GitHub: DPMirt requires R ≥ 4.1 nimble ≥ 1.0.0. NIMBLE needs working C++ compiler; see NIMBLE installation guide already one set .","code":"# install.packages(\"remotes\") remotes::install_github(\"joonho112/DPMirt\")"},{"path":"https://joonho112.github.io/DPMirt/index.html","id":"optional-packages","dir":"","previous_headings":"Installation","what":"Optional packages","title":"DPMirt: Bayesian Semiparametric IRT with DPM Priors","text":"","code":"# Principled alpha prior elicitation remotes::install_github(\"joonho112/DPprior\")  # Reliability-targeted simulation remotes::install_github(\"joonho112/IRTsimrel\")  # Enhanced plotting install.packages(c(\"ggplot2\", \"bayesplot\"))"},{"path":"https://joonho112.github.io/DPMirt/index.html","id":"quick-start","dir":"","previous_headings":"","what":"Quick Start","title":"DPMirt: Bayesian Semiparametric IRT with DPM Priors","text":"","code":"library(DPMirt)  # 1. Simulate a bimodal population (200 persons, 20 items) sim <- dpmirt_simulate(   n_persons = 200, n_items = 20,   model = \"rasch\", latent_shape = \"bimodal\",   target_rho = 0.8, seed = 42 )  # 2. Fit a Rasch model with a DPM prior fit <- dpmirt(   sim$response,   model = \"rasch\", prior = \"dpm\",   niter = 10000, nburnin = 3000, seed = 123 )  # 3. Inspect results summary(fit) plot(fit, type = \"density\")  # 4. Compute triple-goal estimates (PM, CB, GR) est <- dpmirt_estimates(fit) plot(est, type = \"shrinkage\")  # 5. Compare Normal vs DPM priors fit_normal <- dpmirt(   sim$response,   model = \"rasch\", prior = \"normal\",   niter = 10000, nburnin = 3000, seed = 123 ) dpmirt_compare(fit_normal, fit)"},{"path":"https://joonho112.github.io/DPMirt/index.html","id":"step-by-step-pipeline","dir":"","previous_headings":"","what":"Step-by-Step Pipeline","title":"DPMirt: Bayesian Semiparametric IRT with DPM Priors","text":"finer control, use modular pipeline instead --one dpmirt() wrapper:","code":"# Specify spec <- dpmirt_spec(sim$response, model = \"2pl\", prior = \"dpm\")  # Compile (slow — only done once) compiled <- dpmirt_compile(spec)  # Sample fit <- dpmirt_sample(compiled, niter = 10000, nburnin = 3000)  # Rescale (post-hoc identification) fit <- dpmirt_rescale(fit)  # Continue sampling without recompiling fit2 <- dpmirt_resume(fit, niter_more = 5000)"},{"path":"https://joonho112.github.io/DPMirt/index.html","id":"posterior-summary-methods","dir":"","previous_headings":"","what":"Posterior Summary Methods","title":"DPMirt: Bayesian Semiparametric IRT with DPM Priors","text":"DPMirt implements three complementary estimators person abilities: PM (Posterior Mean) — minimises individual-level mean squared error can severely compress ability distribution, especially test reliability low. CB (Constrained Bayes) — inflates PM distribution first two moments estimates match posterior predictive distribution (Ghosh, 1992). GR (Triple-Goal) — places estimate midpoint corresponding quantile interval estimated empirical distribution function, optimising simultaneous estimation, ranking, distributional recovery (Shen & Louis, 1998).","code":"est <- dpmirt_estimates(fit, methods = c(\"pm\", \"cb\", \"gr\"))  # Compare estimator distributions against truth dpmirt_loss(est, true_theta = sim$theta, metrics = c(\"msel\", \"ks\"))"},{"path":"https://joonho112.github.io/DPMirt/index.html","id":"vignettes","dir":"","previous_headings":"","what":"Vignettes","title":"DPMirt: Bayesian Semiparametric IRT with DPM Priors","text":"DPMirt ships eight vignettes organised two reading tracks:","code":""},{"path":"https://joonho112.github.io/DPMirt/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"DPMirt: Bayesian Semiparametric IRT with DPM Priors","text":"Lee, J. & Wind, S. Targeting toward inferential goals Bayesian Rasch models estimating person-specific latent traits. OSF Preprint. https://doi.org/10.31219/osf.io/qrw4n Paganin, S., Paciorek, C. J., Wehrhahn, C., Rodriguez, ., Rabe-Hesketh, S., & de Valpine, P. (2023). Computational strategies estimation performance Bayesian semiparametric item response theory models. Journal Educational Behavioral Statistics, 48(2), 147–188. Ghosh, M. (1992). Constrained Bayes estimation applications. Journal American Statistical Association, 87(418), 533–540. Shen, W., & Louis, T. . (1998). Triple-goal estimates two-stage hierarchical models. Journal Royal Statistical Society: Series B, 60(2), 455–471.","code":""},{"path":"https://joonho112.github.io/DPMirt/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"DPMirt: Bayesian Semiparametric IRT with DPM Priors","text":"MIT © JoonHo Lee","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/DPMirt-package.html","id":null,"dir":"Reference","previous_headings":"","what":"DPMirt: Bayesian Semiparametric IRT Models Using DPM Priors — DPMirt-package","title":"DPMirt: Bayesian Semiparametric IRT Models Using DPM Priors — DPMirt-package","text":"Fits Bayesian semiparametric Item Response Theory (IRT) models using Dirichlet Process Mixture (DPM) priors via NIMBLE.  Supports Rasch, 2PL, 3PL models parametric (Normal) semiparametric (Dirichlet Process Mixture) priors latent ability distribution, provides triple-goal posterior summaries (PM, CB, GR) simultaneous estimation ranking person abilities.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/DPMirt-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"DPMirt: Bayesian Semiparametric IRT Models Using DPM Priors — DPMirt-package","text":"DPMirt package supports: Three IRT models: Rasch, 2PL, 3PL Two latent trait priors: parametric (Normal) semiparametric (DPM) Three identification strategies: constrained_item, constrained_ability, unconstrained Three posterior summary methods: PM, CB (Ghosh 1992), GR (Shen & Louis 1998) Compile-, sample-many MCMC workflow Principled alpha hyperprior elicitation via DPprior Reliability-targeted simulation via IRTsimrel backbone NIMBLE model code adapted Paganin et al. (2023). MCMC compilation, sampling, model management handled NIMBLE's C++ infrastructure.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/DPMirt-package.html","id":"typical-workflow","dir":"Reference","previous_headings":"","what":"Typical Workflow","title":"DPMirt: Bayesian Semiparametric IRT Models Using DPM Priors — DPMirt-package","text":"standard DPMirt analysis proceeds five steps: Simulate load data: Use dpmirt_simulate provide binary response matrix. Fit model: Call dpmirt one-step fitting, use step--step pipeline dpmirt_spec \\(\\rightarrow\\) dpmirt_compile \\(\\rightarrow\\) dpmirt_sample \\(\\rightarrow\\) dpmirt_rescale. Summarize: Compute triple-goal estimates dpmirt_estimates extract posterior draws dpmirt_draws. Diagnose: Evaluate convergence model comparison via dpmirt_diagnostics dpmirt_compare. Visualize: Use plot dpmirt_plot_* family publication-quality figures.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/DPMirt-package.html","id":"model-fitting","dir":"Reference","previous_headings":"","what":"Model Fitting","title":"DPMirt: Bayesian Semiparametric IRT Models Using DPM Priors — DPMirt-package","text":"dpmirt One-step model fitting (specification + compilation + sampling + rescaling) dpmirt_spec Create model specification dpmirt_compile Compile NIMBLE model MCMC dpmirt_sample Run MCMC sampling dpmirt_resume Continue sampling fitted model","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/DPMirt-package.html","id":"estimation-and-rescaling","dir":"Reference","previous_headings":"","what":"Estimation and Rescaling","title":"DPMirt: Bayesian Semiparametric IRT Models Using DPM Priors — DPMirt-package","text":"dpmirt_rescale Post-hoc identification rescaling (Rasch, IRT, SI) dpmirt_estimates Compute PM, CB, GR triple-goal posterior summaries dpmirt_draws Extract posterior draws matrix long-format data frame","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/DPMirt-package.html","id":"diagnostics-and-model-comparison","dir":"Reference","previous_headings":"","what":"Diagnostics and Model Comparison","title":"DPMirt: Bayesian Semiparametric IRT Models Using DPM Priors — DPMirt-package","text":"dpmirt_diagnostics MCMC convergence diagnostics (ESS, Rhat, trace summaries) dpmirt_compare WAIC-based model comparison","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/DPMirt-package.html","id":"simulation","dir":"Reference","previous_headings":"","what":"Simulation","title":"DPMirt: Bayesian Semiparametric IRT Models Using DPM Priors — DPMirt-package","text":"dpmirt_simulate Simulate IRT data flexible latent distributions reliability targeting dpmirt_loss Evaluate estimator loss (MSEL, MSELR, KS, custom)","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/DPMirt-package.html","id":"prior-specification","dir":"Reference","previous_headings":"","what":"Prior Specification","title":"DPMirt: Bayesian Semiparametric IRT Models Using DPM Priors — DPMirt-package","text":"dpmirt_alpha_prior Principled DPM concentration parameter elicitation","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/DPMirt-package.html","id":"dp-density-estimation","dir":"Reference","previous_headings":"","what":"DP Density Estimation","title":"DPMirt: Bayesian Semiparametric IRT Models Using DPM Priors — DPMirt-package","text":"dpmirt_dp_density Posterior density estimation Dirichlet Process mixture","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/DPMirt-package.html","id":"visualization","dir":"Reference","previous_headings":"","what":"Visualization","title":"DPMirt: Bayesian Semiparametric IRT Models Using DPM Priors — DPMirt-package","text":"S3 plot methods: plot(fit) Trace plots, density plots, caterpillar plots fitted models plot(estimates) Shrinkage, rank, comparison plots PM/CB/GR estimates plot(sim) ICC distribution plots simulated data Standalone ggplot2 functions (require ggplot2): dpmirt_plot_trace, dpmirt_plot_density, dpmirt_plot_caterpillar, dpmirt_plot_items, dpmirt_plot_icc, dpmirt_plot_info, dpmirt_plot_dp_density, dpmirt_plot_clusters, dpmirt_plot_wright_map, dpmirt_plot_parameter_trace, dpmirt_plot_density_compare, dpmirt_plot_pp_check","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/DPMirt-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"DPMirt: Bayesian Semiparametric IRT Models Using DPM Priors — DPMirt-package","text":"Paganin, S., Paciorek, C. J., Wehrhahn, C., Rodriguez, ., Rabe-Hesketh, S., & de Valpine, P. (2023). Computational strategies estimation performance Bayesian semiparametric item response theory models. Journal Educational Behavioral Statistics, 48(2), 147–188. Ghosh, M. (1992). Constrained Bayes estimation applications. Journal American Statistical Association, 87(418), 533–540. Shen, W., & Louis, T. . (1998). Triple-goal estimates two-stage hierarchical models. Journal Royal Statistical Society: Series B, 60(2), 455–471.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/reference/DPMirt-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"DPMirt: Bayesian Semiparametric IRT Models Using DPM Priors — DPMirt-package","text":"Maintainer: JoonHo Lee jlee296@ua.edu","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_alpha_prior.html","id":null,"dir":"Reference","previous_headings":"","what":"Elicit a Gamma Hyperprior for the DP Concentration Parameter — dpmirt_alpha_prior","title":"Elicit a Gamma Hyperprior for the DP Concentration Parameter — dpmirt_alpha_prior","text":"Uses DPprior package calibrate Gamma(, b) hyperprior Dirichlet Process concentration parameter \\(\\alpha\\), based expected number clusters \\(\\mu_K\\) confidence level. Falls back Paganin's default Gamma(1, 3) DPprior installed.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_alpha_prior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Elicit a Gamma Hyperprior for the DP Concentration Parameter — dpmirt_alpha_prior","text":"","code":"dpmirt_alpha_prior(N, mu_K = NULL, confidence = \"medium\", ...)"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_alpha_prior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Elicit a Gamma Hyperprior for the DP Concentration Parameter — dpmirt_alpha_prior","text":"N Integer. Sample size (number persons). mu_K Numeric NULL. Expected number clusters. NULL, defaults max(3, ceiling(log(N))). confidence Character. DPprior confidence level: \"low\", \"medium\", \"high\". ... Additional arguments passed DPprior::DPprior_fit.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_alpha_prior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Elicit a Gamma Hyperprior for the DP Concentration Parameter — dpmirt_alpha_prior","text":"Named numeric vector c(= ..., b = ...) Gamma(, b).","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_alpha_prior.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Elicit a Gamma Hyperprior for the DP Concentration Parameter — dpmirt_alpha_prior","text":"CRP representation used DPMirt, concentration parameter \\(\\alpha\\) controls expected number clusters. Larger \\(\\alpha\\) favors clusters (closer nonparametric), smaller \\(\\alpha\\) concentrates mass fewer clusters (closer parametric). DPprior package (Lee, 2026) provides principled elicitation framework: given sample size \\(N\\) expected cluster count \\(\\mu_K\\), calibrates Gamma(, b) \\(E[K | \\alpha] \\approx \\mu_K\\) specified confidence level. Paganin et al. (2023) default Gamma(1, 3), implies \\(E[\\alpha] = 1/3\\) — mildly informative prior favoring clusters.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_alpha_prior.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Elicit a Gamma Hyperprior for the DP Concentration Parameter — dpmirt_alpha_prior","text":"Lee, J. (2026). Design-conditional prior elicitation Dirichlet process mixtures. arXiv:2602.06301. Paganin, S., Paciorek, C. J., Wehrhahn, C., Rodriguez, ., Rabe-Hesketh, S., & de Valpine, P. (2023). Computational strategies estimation performance Bayesian semiparametric item response theory models. Journal Educational Behavioral Statistics, 48(2), 147–188.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_alpha_prior.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Elicit a Gamma Hyperprior for the DP Concentration Parameter — dpmirt_alpha_prior","text":"","code":"if (FALSE) { # \\dontrun{ # Default: uses Gamma(1, 3) if DPprior not installed alpha <- dpmirt_alpha_prior(N = 200)  # Specify expected clusters and confidence alpha <- dpmirt_alpha_prior(N = 500, mu_K = 5, confidence = \"medium\")  # Use in model fitting sim <- dpmirt_simulate(200, 20, model = \"rasch\", seed = 42) fit <- dpmirt(sim$response, model = \"rasch\", prior = \"dpm\",               alpha_prior = alpha, niter = 5000, nburnin = 1000) } # }"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_compare.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare DPMirt models using information criteria — dpmirt_compare","title":"Compare DPMirt models using information criteria — dpmirt_compare","text":"Compare DPMirt models using information criteria","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_compare.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare DPMirt models using information criteria — dpmirt_compare","text":"","code":"dpmirt_compare(..., criterion = \"waic\")"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_compare.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare DPMirt models using information criteria — dpmirt_compare","text":"... Two dpmirt_fit objects. criterion Character. Comparison criterion. Default \"waic\".","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_compare.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare DPMirt models using information criteria — dpmirt_compare","text":"data.frame ranking models criterion.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_compare.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compare DPMirt models using information criteria — dpmirt_compare","text":"","code":"if (FALSE) { # \\dontrun{ sim <- dpmirt_simulate(200, 20, model = \"rasch\", seed = 42) fit1 <- dpmirt(sim$response, model = \"rasch\", prior = \"normal\",                niter = 5000, nburnin = 1000, seed = 123) fit2 <- dpmirt(sim$response, model = \"rasch\", prior = \"dpm\",                niter = 5000, nburnin = 1000, seed = 123)  # Compare via WAIC comp <- dpmirt_compare(fit1, fit2) print(comp) } # }"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_compile.html","id":null,"dir":"Reference","previous_headings":"","what":"Compile a DPMirt model specification — dpmirt_compile","title":"Compile a DPMirt model specification — dpmirt_compile","text":"Takes dpmirt_spec object compiles NIMBLE model MCMC engine. expensive step (~30-120 seconds) needs done per model specification.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_compile.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compile a DPMirt model specification — dpmirt_compile","text":"","code":"dpmirt_compile(   spec,   sampler_config = NULL,   use_centered_sampler = \"auto\",   enable_waic = TRUE,   enable_logprob_monitor = TRUE,   verbose = TRUE,   ... )  # S3 method for class 'dpmirt_compiled' print(x, ...)"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_compile.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compile a DPMirt model specification — dpmirt_compile","text":"spec dpmirt_spec object dpmirt_spec. sampler_config Optional custom MCMC sampler configuration. use_centered_sampler Character logical. Whether use centered sampler SI parameterization. \"auto\" enables appropriate (SI param + 2PL/3PL). relevant Phase 3+. enable_waic Logical. Whether enable WAIC computation. enable_logprob_monitor Logical. Whether add log-probability monitoring samplers. verbose Logical. Print progress messages. ... Additional arguments (currently unused). x dpmirt_compiled object.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_compile.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compile a DPMirt model specification — dpmirt_compile","text":"dpmirt_compiled S3 object containing compiled model, compiled MCMC, specification reference, session signature.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_compile.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compile a DPMirt model specification — dpmirt_compile","text":"compiled NIMBLE objects contain external C++ pointers serialized across R sessions. compile-pattern therefore within-session optimization. cross-session workflows, save dpmirt_spec object recompile new session.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_compile.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compile a DPMirt model specification — dpmirt_compile","text":"","code":"if (FALSE) { # \\dontrun{ sim <- dpmirt_simulate(200, 20, model = \"rasch\", seed = 42) spec <- dpmirt_spec(sim$response, model = \"rasch\", prior = \"normal\")  # Compile (takes 30-120 seconds) compiled <- dpmirt_compile(spec) print(compiled)  # Compile-once, sample-many pattern samples1 <- dpmirt_sample(compiled, niter = 5000, nburnin = 1000, seed = 1) samples2 <- dpmirt_sample(compiled, niter = 5000, nburnin = 1000, seed = 2) } # }"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_diagnostics.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute MCMC Diagnostics for a DPMirt Fit — dpmirt_diagnostics","title":"Compute MCMC Diagnostics for a DPMirt Fit — dpmirt_diagnostics","text":"Returns structured list diagnostic information including effective sample sizes (ESS), WAIC, log-likelihood trace, timing, DPM-specific cluster diagnostics (number clusters, alpha posterior).","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_diagnostics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute MCMC Diagnostics for a DPMirt Fit — dpmirt_diagnostics","text":"","code":"dpmirt_diagnostics(fit)  # S3 method for class 'dpmirt_diagnostics' print(x, ...)"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_diagnostics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute MCMC Diagnostics for a DPMirt Fit — dpmirt_diagnostics","text":"fit dpmirt_fit object dpmirt. x dpmirt_diagnostics object. ... Additional arguments (currently unused).","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_diagnostics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute MCMC Diagnostics for a DPMirt Fit — dpmirt_diagnostics","text":"dpmirt_diagnostics S3 object containing: ess List ESS vectors items persons. waic WAIC value (computed). loglik_trace Log-likelihood trace vector. n_clusters Posterior cluster counts (DPM ). alpha_summary Alpha posterior summary (DPM ). compilation_time, sampling_time, total_time Timing information.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_diagnostics.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute MCMC Diagnostics for a DPMirt Fit — dpmirt_diagnostics","text":"Effective sample size (ESS) measures number effectively independent draws posterior. Low ESS (< 100) suggests poor mixing need longer chains different samplers. DPM models, cluster count trace key diagnostic — stable oscillation indicates convergence, monotonic trends suggest chain yet mixed.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_diagnostics.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute MCMC Diagnostics for a DPMirt Fit — dpmirt_diagnostics","text":"","code":"if (FALSE) { # \\dontrun{ sim <- dpmirt_simulate(200, 20, model = \"rasch\", seed = 42) fit <- dpmirt(sim$response, model = \"rasch\", prior = \"dpm\",               niter = 5000, nburnin = 1000, seed = 123) diag <- dpmirt_diagnostics(fit) print(diag) } # }"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_dp_density.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute posterior density of the DP mixture — dpmirt_dp_density","title":"Compute posterior density of the DP mixture — dpmirt_dp_density","text":"Samples posterior Dirichlet Process mixing distribution using NIMBLE's getSamplesDPmeasure() evaluates resulting mixture density grid. density computed summing weighted Normal components DP base measure.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_dp_density.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute posterior density of the DP mixture — dpmirt_dp_density","text":"","code":"dpmirt_dp_density(   fit,   grid = seq(-6, 6, length.out = 500),   credible_interval = 0.95,   apply_rescaling = TRUE,   verbose = TRUE,   ... )  # S3 method for class 'dpmirt_dp_density' print(x, ...)"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_dp_density.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute posterior density of the DP mixture — dpmirt_dp_density","text":"fit dpmirt_fit object prior = \"dpm\". grid Numeric vector. Grid points density evaluation. Default: seq(-6, 6, length.= 500). credible_interval Numeric. Width pointwise credible band. Default: 0.95 (.e., 95 percent band). apply_rescaling Logical. TRUE (default), shift grid iteration-specific location shift post-hoc rescaling. relevant unconstrained models. verbose Logical. Print progress messages. Default TRUE. ... Additional arguments (currently unused). x dpmirt_dp_density object.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_dp_density.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute posterior density of the DP mixture — dpmirt_dp_density","text":"list class dpmirt_dp_density containing: grid Numeric vector evaluation points. density_mean Numeric vector posterior mean densities. density_lower Numeric vector lower credible band. density_upper Numeric vector upper credible band. density_samples Matrix (niter x length(grid)) per-iteration densities (custom summaries). dp_samples List getSamplesDPmeasure() – element matrix columns (weights, means, variances). ci_level credible interval level used.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_dp_density.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute posterior density of the DP mixture — dpmirt_dp_density","text":"function follows Paganin et al.'s (2023) workflow: Extract posterior samples DP parameters (alpha, zi, muTilde, s2Tilde) fitted model. Reconstruct NIMBLE model compiled MCMC monitors set DP parameters. Populate compiled MCMC's sample storage posterior samples using nimble:::matrix2mv(). Call getSamplesDPmeasure() compute stick-breaking weights atoms posterior draw. Evaluate mixture density f(x|Gs) = sum_k w_k * phi(x; mu_k, s2_k) posterior sample s grid point x. Rasch models unconstrained identification, location shift (mean(beta) per iteration) applied density rescaled theta scale.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_dp_density.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute posterior density of the DP mixture — dpmirt_dp_density","text":"","code":"if (FALSE) { # \\dontrun{ sim <- dpmirt_simulate(200, 20, model = \"rasch\",                        latent_shape = \"bimodal\", seed = 42) fit <- dpmirt(sim$response, model = \"rasch\", prior = \"dpm\",               niter = 10000, nburnin = 3000, seed = 123)  # Compute DP density on default grid dpd <- dpmirt_dp_density(fit) print(dpd)  # Custom grid dpd2 <- dpmirt_dp_density(fit, grid = seq(-4, 4, length.out = 200)) } # }"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_draws.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract posterior draws from a DPMirt fit — dpmirt_draws","title":"Extract posterior draws from a DPMirt fit — dpmirt_draws","text":"Provides convenient access posterior samples matrix long format.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_draws.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract posterior draws from a DPMirt fit — dpmirt_draws","text":"","code":"dpmirt_draws(   fit,   vars = c(\"theta\", \"beta\", \"lambda\", \"delta\"),   format = c(\"matrix\", \"long\"),   use_rescaled = TRUE )"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_draws.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract posterior draws from a DPMirt fit — dpmirt_draws","text":"fit dpmirt_fit object. vars Character vector variables extract. Options: \"theta\", \"beta\", \"lambda\", \"delta\". format Character. Output format: \"matrix\" \"long\". use_rescaled Logical. TRUE (default), return rescaled samples.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_draws.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract posterior draws from a DPMirt fit — dpmirt_draws","text":"matrix (niter x N niter x ) long data.frame.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_draws.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract posterior draws from a DPMirt fit — dpmirt_draws","text":"function provides direct access posterior MCMC samples stored dpmirt_fit object. matrix format (default) efficient computation, long format convenient visualization ggplot2.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_draws.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract posterior draws from a DPMirt fit — dpmirt_draws","text":"","code":"if (FALSE) { # \\dontrun{ sim <- dpmirt_simulate(200, 20, model = \"rasch\", seed = 42) fit <- dpmirt(sim$response, model = \"rasch\", prior = \"normal\",               niter = 5000, nburnin = 1000, seed = 123)  # Extract theta draws as matrix (niter x N) theta <- dpmirt_draws(fit, vars = \"theta\") dim(theta$theta)  # Extract beta draws in long format beta_long <- dpmirt_draws(fit, vars = \"beta\", format = \"long\") head(beta_long$beta) } # }"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_estimates.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute posterior estimates using PM, CB, and GR methods — dpmirt_estimates","title":"Compute posterior estimates using PM, CB, and GR methods — dpmirt_estimates","text":"Given dpmirt_fit object, computes person-specific item-specific point estimates using multiple posterior summary methods: PM: Posterior Mean — optimal individual MSE (Goal 1) CB: Constrained Bayes (Ghosh, 1992) — optimal EDF estimation (Goal 3) GR: Triple-Goal (Shen & Louis, 1998) — optimal ranking + EDF (Goals 2 & 3)","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_estimates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute posterior estimates using PM, CB, and GR methods — dpmirt_estimates","text":"","code":"dpmirt_estimates(   fit,   methods = c(\"pm\", \"cb\", \"gr\"),   alpha = 0.05,   quantile_type = 7,   stop_if_ties = FALSE,   include_items = TRUE )  # S3 method for class 'dpmirt_estimates' print(x, ...)"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_estimates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute posterior estimates using PM, CB, and GR methods — dpmirt_estimates","text":"fit dpmirt_fit object dpmirt. methods Character vector methods compute. Default c(\"pm\", \"cb\", \"gr\"). alpha Significance level credible intervals. Default 0.05. quantile_type Integer 1-9 quantile() type parameter. Default 7 (R default). stop_if_ties Logical. TRUE, stop ties detected posterior mean ranks. Default FALSE. include_items Logical. TRUE, apply CB/GR beta well. Default TRUE. x dpmirt_estimates object. ... Additional arguments (currently unused).","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_estimates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute posterior estimates using PM, CB, and GR methods — dpmirt_estimates","text":"dpmirt_estimates S3 object.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_estimates.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute posterior estimates using PM, CB, and GR methods — dpmirt_estimates","text":"three estimators target different inferential goals (Shen & Louis, 1998): Goal 1 — Individual estimation: Minimize individual mean squared error. posterior mean (PM) optimal: $$\\hat{\\theta}^{PM}_j = E[\\theta_j | y]$$ Goal 2 — Ranking: Correctly rank individuals. GR estimator uses quantiles marginal posterior predictive distribution evaluated posterior mean rank individual. Goal 3 — Distribution estimation: Recover empirical distribution function (EDF). constrained Bayes (CB) estimator rescales PM match correct first two moments: $$\\hat{\\theta}^{CB}_j = \\bar{\\theta}^{PM} + \\sqrt{1 + \\frac{\\bar{\\lambda}}{\\mathrm{Var}(\\theta^{PM})}} \\cdot (\\hat{\\theta}^{PM}_j - \\bar{\\theta}^{PM})$$ \\(\\bar{\\lambda} = \\frac{1}{K}\\sum_k \\lambda_k\\) mean posterior variance.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_estimates.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute posterior estimates using PM, CB, and GR methods — dpmirt_estimates","text":"Ghosh, M. (1992). Constrained Bayes estimation applications. JASA, 87(418), 533–540. Shen, W., & Louis, T. . (1998). Triple-goal estimates two-stage hierarchical models. JRSS-B, 60(2), 455–471.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_estimates.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute posterior estimates using PM, CB, and GR methods — dpmirt_estimates","text":"","code":"if (FALSE) { # \\dontrun{ sim <- dpmirt_simulate(200, 20, model = \"rasch\", seed = 42) fit <- dpmirt(sim$response, model = \"rasch\", prior = \"normal\",               niter = 5000, nburnin = 1000, seed = 123)  # Compute all three estimators est <- dpmirt_estimates(fit) print(est)  # Access person estimates head(est$theta)  # Access item estimates head(est$beta)  # PM only (faster) est_pm <- dpmirt_estimates(fit, methods = \"pm\") } # }"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_fit-methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Methods for dpmirt_fit Objects — dpmirt_fit-methods","title":"Methods for dpmirt_fit Objects — dpmirt_fit-methods","text":"Print, summarize, extract coefficients fitted DPMirt model.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_fit-methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Methods for dpmirt_fit Objects — dpmirt_fit-methods","text":"","code":"# S3 method for class 'dpmirt_fit' print(x, ...)  # S3 method for class 'dpmirt_fit' summary(object, ...)  # S3 method for class 'dpmirt_fit' coef(object, type = c(\"items\", \"persons\"), ...)"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_fit-methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Methods for dpmirt_fit Objects — dpmirt_fit-methods","text":"x, object dpmirt_fit object dpmirt. ... Additional arguments (currently unused). type coef: character, \"items\" (default) \"persons\".","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_fit-methods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Methods for dpmirt_fit Objects — dpmirt_fit-methods","text":"print summary return input invisibly. coef returns data.frame posterior mean estimates one row per item person.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_fit-methods.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Methods for dpmirt_fit Objects — dpmirt_fit-methods","text":"print displays concise one-screen summary: model type, data dimensions, MCMC settings, WAIC, minimum ESS, DPM cluster summary. summary displays comprehensive report including item parameter posterior means SDs, person ability range, DPM diagnostics, timing. coef extracts posterior mean point estimates items (type = \"items\") persons (type = \"persons\").","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_fit-methods.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Methods for dpmirt_fit Objects — dpmirt_fit-methods","text":"","code":"if (FALSE) { # \\dontrun{ sim <- dpmirt_simulate(200, 20, model = \"rasch\", seed = 42) fit <- dpmirt(sim$response, model = \"rasch\", prior = \"normal\",               niter = 5000, nburnin = 1000, seed = 123)  # Print concise summary print(fit)  # Detailed summary with item parameters summary(fit)  # Extract item difficulty estimates coef(fit, type = \"items\")  # Extract person ability estimates coef(fit, type = \"persons\") } # }"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_loss.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate estimator performance using loss functions — dpmirt_loss","title":"Evaluate estimator performance using loss functions — dpmirt_loss","text":"Computes loss metrics comparing estimated parameters true values. Designed simulation studies true parameter values known.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_loss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate estimator performance using loss functions — dpmirt_loss","text":"","code":"dpmirt_loss(   estimates,   true_theta,   true_beta = NULL,   true_lambda = NULL,   metrics = c(\"msel\", \"mselr\", \"ks\"),   custom_loss = NULL )"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_loss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate estimator performance using loss functions — dpmirt_loss","text":"estimates dpmirt_estimates object. true_theta Numeric vector true person abilities. true_beta Numeric vector true item difficulties (optional). SI parameterization, true gamma (intercept) values. true_lambda Numeric vector true item discriminations (optional). relevant 2PL/3PL models. metrics Character vector metrics compute. Options: \"msel\" (mean squared error loss), \"mselr\" (MSE ranks), \"ks\" (Kolmogorov-Smirnov statistic). custom_loss Optional custom loss function signature function(estimate, true).","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_loss.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate estimator performance using loss functions — dpmirt_loss","text":"data.frame loss values method x parameter combination.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_loss.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate estimator performance using loss functions — dpmirt_loss","text":"Three built-loss metrics measure different aspects estimation quality: MSEL (Mean Squared Error Loss): Measures individual-level accuracy. $$MSEL = \\frac{1}{K} \\sum_{k=1}^{K} (\\hat{\\theta}_k - \\theta_k)^2$$ MSELR (MSE Ranks): Measures ranking accuracy using normalized ranks. $$MSELR = \\frac{1}{K} \\sum_{k=1}^{K} \\left(\\frac{R(\\hat{\\theta}_k)}{K} - \\frac{R(\\theta_k)}{K}\\right)^2$$ KS (Kolmogorov-Smirnov): Measures distributional accuracy. $$KS = \\sup_t |F_{\\hat{\\theta}}(t) - F_{\\theta}(t)|$$ Custom loss functions can supplied via custom_loss; must accept two vectors (estimates, true values) return scalar.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_loss.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Evaluate estimator performance using loss functions — dpmirt_loss","text":"Shen, W., & Louis, T. . (1998). Triple-goal estimates two-stage hierarchical models. JRSS-B, 60(2), 455–471.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_loss.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluate estimator performance using loss functions — dpmirt_loss","text":"","code":"if (FALSE) { # \\dontrun{ sim <- dpmirt_simulate(200, 20, model = \"rasch\", seed = 42) fit <- dpmirt(sim$response, model = \"rasch\", prior = \"normal\",               niter = 5000, nburnin = 1000, seed = 123) est <- dpmirt_estimates(fit)  # Evaluate against true values loss <- dpmirt_loss(est, true_theta = sim$theta, true_beta = sim$beta) print(loss)  # With custom loss function mae <- function(est, true) mean(abs(est - true)) loss2 <- dpmirt_loss(est, true_theta = sim$theta, custom_loss = mae) } # }"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_caterpillar.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Caterpillar (Forest) Plot — dpmirt_plot_caterpillar","title":"Plot Caterpillar (Forest) Plot — dpmirt_plot_caterpillar","text":"Displays sorted point estimates credible intervals items persons. Useful identifying extreme values assessing uncertainty. Requires ggplot2.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_caterpillar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Caterpillar (Forest) Plot — dpmirt_plot_caterpillar","text":"","code":"dpmirt_plot_caterpillar(   fit,   param = c(\"beta\", \"theta\", \"lambda\", \"delta\"),   sort = TRUE,   ci_level = 0.95,   max_show = 50,   ... )"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_caterpillar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Caterpillar (Forest) Plot — dpmirt_plot_caterpillar","text":"fit dpmirt_fit object dpmirt. param Character. Parameter type: \"beta\" (default), \"theta\", \"lambda\", \"delta\". sort Logical. Sort estimate magnitude. Default TRUE. ci_level Numeric. Credible interval level. Default 0.95. max_show Integer. Maximum number parameters display. Default 50. ... Currently unused.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_caterpillar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Caterpillar (Forest) Plot — dpmirt_plot_caterpillar","text":"ggplot object.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_caterpillar.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Caterpillar (Forest) Plot — dpmirt_plot_caterpillar","text":"","code":"if (FALSE) { # \\dontrun{ sim <- dpmirt_simulate(200, 20, model = \"rasch\", seed = 42) fit <- dpmirt(sim$response, model = \"rasch\", prior = \"normal\",               niter = 5000, nburnin = 1000, seed = 123) dpmirt_plot_caterpillar(fit, param = \"beta\") } # }"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_clusters.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Cluster Count Diagnostics — dpmirt_plot_clusters","title":"Plot Cluster Count Diagnostics — dpmirt_plot_clusters","text":"DPM models, displays trace histogram number active clusters across MCMC iterations. Stable oscillation indicates convergence. Requires ggplot2.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_clusters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Cluster Count Diagnostics — dpmirt_plot_clusters","text":"","code":"dpmirt_plot_clusters(fit, ...)"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_clusters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Cluster Count Diagnostics — dpmirt_plot_clusters","text":"fit dpmirt_fit object prior = \"dpm\". ... Currently unused.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_clusters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Cluster Count Diagnostics — dpmirt_plot_clusters","text":"ggplot object.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_clusters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Cluster Count Diagnostics — dpmirt_plot_clusters","text":"","code":"if (FALSE) { # \\dontrun{ sim <- dpmirt_simulate(200, 20, model = \"rasch\",                        latent_shape = \"bimodal\", seed = 42) fit <- dpmirt(sim$response, model = \"rasch\", prior = \"dpm\",               niter = 10000, nburnin = 3000, seed = 123) dpmirt_plot_clusters(fit) } # }"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_density.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Posterior Mean Density — dpmirt_plot_density","title":"Plot Posterior Mean Density — dpmirt_plot_density","text":"Displays kernel density estimate posterior mean person abilities (\\(\\hat{\\theta}^{PM}\\)). Useful assessing shape estimated latent trait distribution. Requires ggplot2.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_density.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Posterior Mean Density — dpmirt_plot_density","text":"","code":"dpmirt_plot_density(fit, ...)"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_density.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Posterior Mean Density — dpmirt_plot_density","text":"fit dpmirt_fit object dpmirt. ... Currently unused.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_density.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Posterior Mean Density — dpmirt_plot_density","text":"ggplot object.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_density.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Posterior Mean Density — dpmirt_plot_density","text":"","code":"if (FALSE) { # \\dontrun{ sim <- dpmirt_simulate(200, 20, model = \"rasch\", seed = 42) fit <- dpmirt(sim$response, model = \"rasch\", prior = \"normal\",               niter = 5000, nburnin = 1000, seed = 123) dpmirt_plot_density(fit) } # }"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_density_compare.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Posterior Density vs Reference Distribution — dpmirt_plot_density_compare","title":"Plot Posterior Density vs Reference Distribution — dpmirt_plot_density_compare","text":"Overlays estimated posterior mean density reference distribution (e.g., true generating density N(0,1)). Useful assessing well model recovers latent trait distribution. Requires ggplot2.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_density_compare.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Posterior Density vs Reference Distribution — dpmirt_plot_density_compare","text":"","code":"dpmirt_plot_density_compare(fit, reference = c(\"normal\"), ...)"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_density_compare.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Posterior Density vs Reference Distribution — dpmirt_plot_density_compare","text":"fit dpmirt_fit object dpmirt. reference Character numeric vector. \"normal\" (default), overlays N(0,1). numeric, treated reference theta values. ... Currently unused.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_density_compare.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Posterior Density vs Reference Distribution — dpmirt_plot_density_compare","text":"ggplot object.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_density_compare.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Posterior Density vs Reference Distribution — dpmirt_plot_density_compare","text":"","code":"if (FALSE) { # \\dontrun{ sim <- dpmirt_simulate(200, 20, model = \"rasch\", seed = 42) fit <- dpmirt(sim$response, model = \"rasch\", prior = \"normal\",               niter = 5000, nburnin = 1000, seed = 123)  # Compare to N(0,1) dpmirt_plot_density_compare(fit)  # Compare to true theta dpmirt_plot_density_compare(fit, reference = sim$theta) } # }"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_dp_density.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot DP Mixture Density — dpmirt_plot_dp_density","title":"Plot DP Mixture Density — dpmirt_plot_dp_density","text":"Displays posterior mean density Dirichlet Process mixture pointwise credible bands. Requires pre-computed dpmirt_dp_density object (computed automatically dpmirt manually via dpmirt_dp_density). Requires ggplot2.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_dp_density.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot DP Mixture Density — dpmirt_plot_dp_density","text":"","code":"dpmirt_plot_dp_density(fit, ...)"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_dp_density.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot DP Mixture Density — dpmirt_plot_dp_density","text":"fit dpmirt_fit object prior = \"dpm\" computed DP density. ... Currently unused.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_dp_density.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot DP Mixture Density — dpmirt_plot_dp_density","text":"ggplot object.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_dp_density.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot DP Mixture Density — dpmirt_plot_dp_density","text":"","code":"if (FALSE) { # \\dontrun{ sim <- dpmirt_simulate(200, 20, model = \"rasch\",                        latent_shape = \"bimodal\", seed = 42) fit <- dpmirt(sim$response, model = \"rasch\", prior = \"dpm\",               niter = 10000, nburnin = 3000, seed = 123) dpmirt_plot_dp_density(fit) } # }"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_icc.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Item Characteristic Curves — dpmirt_plot_icc","title":"Plot Item Characteristic Curves — dpmirt_plot_icc","text":"Displays Item Characteristic Curves (ICCs) items, showing probability correct response function ability. Requires ggplot2.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_icc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Item Characteristic Curves — dpmirt_plot_icc","text":"","code":"dpmirt_plot_icc(fit, items = NULL, theta_range = c(-4, 4), n_points = 201, ...)"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_icc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Item Characteristic Curves — dpmirt_plot_icc","text":"fit dpmirt_fit object dpmirt. items Integer vector item indices plot. Default: items (10). theta_range Numeric vector length 2 ability axis range. Default: c(-4, 4). n_points Integer. Number grid points. Default: 201. ... Currently unused.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_icc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Item Characteristic Curves — dpmirt_plot_icc","text":"ggplot object.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_icc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Item Characteristic Curves — dpmirt_plot_icc","text":"ICC gives probability correct response ability level: Rasch: \\(P(\\theta) = \\mathrm{logistic}(\\theta - \\beta)\\) 2PL: \\(P(\\theta) = \\mathrm{logistic}(\\lambda(\\theta - \\beta))\\) 3PL: \\(P(\\theta) = \\delta + (1 - \\delta) \\cdot \\mathrm{logistic}(\\lambda(\\theta - \\beta))\\)","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_icc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Item Characteristic Curves — dpmirt_plot_icc","text":"","code":"if (FALSE) { # \\dontrun{ sim <- dpmirt_simulate(200, 20, model = \"rasch\", seed = 42) fit <- dpmirt(sim$response, model = \"rasch\", prior = \"normal\",               niter = 5000, nburnin = 1000, seed = 123) dpmirt_plot_icc(fit) dpmirt_plot_icc(fit, items = 1:5) } # }"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_info.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Test Information Function — dpmirt_plot_info","title":"Plot Test Information Function — dpmirt_plot_info","text":"Displays test information function (TIF), shows precision measurement across ability range. Higher information indicates precise measurement. Requires ggplot2.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_info.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Test Information Function — dpmirt_plot_info","text":"","code":"dpmirt_plot_info(   fit,   theta_range = c(-4, 4),   n_points = 201,   show_items = FALSE,   show_density = TRUE,   ... )"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_info.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Test Information Function — dpmirt_plot_info","text":"fit dpmirt_fit object dpmirt. theta_range Numeric vector length 2. Default: c(-4, 4). n_points Integer. Number grid points. Default: 201. show_items Logical. Show individual item information curves. Default FALSE. show_density Logical. Overlay person ability density (scaled). Default TRUE. ... Currently unused.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_info.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Test Information Function — dpmirt_plot_info","text":"ggplot object.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_info.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Test Information Function — dpmirt_plot_info","text":"Fisher information item : Rasch: \\(I_j(\\theta) = P(1-P)\\) 2PL: \\(I_j(\\theta) = \\lambda^2 P(1-P)\\) 3PL: \\(I_j(\\theta) = \\lambda^2 \\frac{(P - \\delta)^2}{(1 - \\delta)^2 P(1 - P)}\\) test information function sum: \\((\\theta) = \\sum_j I_j(\\theta)\\).","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_info.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Test Information Function — dpmirt_plot_info","text":"","code":"if (FALSE) { # \\dontrun{ sim <- dpmirt_simulate(200, 20, model = \"rasch\", seed = 42) fit <- dpmirt(sim$response, model = \"rasch\", prior = \"normal\",               niter = 5000, nburnin = 1000, seed = 123) dpmirt_plot_info(fit) } # }"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_items.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Item Parameter Estimates — dpmirt_plot_items","title":"Plot Item Parameter Estimates — dpmirt_plot_items","text":"Displays item difficulty (beta) estimates posterior credible intervals. 2PL/3PL models, also shows discrimination (lambda) estimates. Requires ggplot2.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_items.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Item Parameter Estimates — dpmirt_plot_items","text":"","code":"dpmirt_plot_items(fit, ...)"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_items.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Item Parameter Estimates — dpmirt_plot_items","text":"fit dpmirt_fit object dpmirt. ... Currently unused.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_items.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Item Parameter Estimates — dpmirt_plot_items","text":"ggplot object.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_items.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Item Parameter Estimates — dpmirt_plot_items","text":"","code":"if (FALSE) { # \\dontrun{ sim <- dpmirt_simulate(200, 20, model = \"rasch\", seed = 42) fit <- dpmirt(sim$response, model = \"rasch\", prior = \"normal\",               niter = 5000, nburnin = 1000, seed = 123) dpmirt_plot_items(fit) } # }"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_parameter_trace.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Individual Parameter MCMC Traces — dpmirt_plot_parameter_trace","title":"Plot Individual Parameter MCMC Traces — dpmirt_plot_parameter_trace","text":"Displays MCMC trace plots individual item person parameters, useful diagnosing mixing convergence specific parameters. Requires ggplot2.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_parameter_trace.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Individual Parameter MCMC Traces — dpmirt_plot_parameter_trace","text":"","code":"dpmirt_plot_parameter_trace(   fit,   param = c(\"beta\", \"theta\", \"lambda\", \"delta\"),   indices = 1:4,   ... )"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_parameter_trace.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Individual Parameter MCMC Traces — dpmirt_plot_parameter_trace","text":"fit dpmirt_fit object dpmirt. param Character. Parameter type: \"beta\", \"theta\", \"lambda\", \"delta\". indices Integer vector parameter indices plot. Default: 1:4. ... Currently unused.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_parameter_trace.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Individual Parameter MCMC Traces — dpmirt_plot_parameter_trace","text":"ggplot object.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_parameter_trace.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Individual Parameter MCMC Traces — dpmirt_plot_parameter_trace","text":"","code":"if (FALSE) { # \\dontrun{ sim <- dpmirt_simulate(200, 20, model = \"rasch\", seed = 42) fit <- dpmirt(sim$response, model = \"rasch\", prior = \"normal\",               niter = 5000, nburnin = 1000, seed = 123) dpmirt_plot_parameter_trace(fit, param = \"beta\", indices = 1:4) } # }"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_pp_check.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Posterior Predictive Check — dpmirt_plot_pp_check","title":"Plot Posterior Predictive Check — dpmirt_plot_pp_check","text":"Compares observed item statistics (proportion correct) posterior predictive distribution. Points falling outside predictive intervals may indicate model misfit. Requires ggplot2.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_pp_check.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Posterior Predictive Check — dpmirt_plot_pp_check","text":"","code":"dpmirt_plot_pp_check(   fit,   stat = c(\"prop_correct\", \"total_score\"),   n_rep = 50,   ... )"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_pp_check.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Posterior Predictive Check — dpmirt_plot_pp_check","text":"fit dpmirt_fit object dpmirt. stat Character. Summary statistic comparison: \"prop_correct\" (default) \"total_score\". n_rep Integer. Number replicated datasets. Default 50. ... Currently unused.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_pp_check.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Posterior Predictive Check — dpmirt_plot_pp_check","text":"ggplot object.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_pp_check.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Posterior Predictive Check — dpmirt_plot_pp_check","text":"","code":"if (FALSE) { # \\dontrun{ sim <- dpmirt_simulate(200, 20, model = \"rasch\", seed = 42) fit <- dpmirt(sim$response, model = \"rasch\", prior = \"normal\",               niter = 5000, nburnin = 1000, seed = 123) dpmirt_plot_pp_check(fit) } # }"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_trace.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Log-Likelihood MCMC Trace — dpmirt_plot_trace","title":"Plot Log-Likelihood MCMC Trace — dpmirt_plot_trace","text":"Displays log-likelihood trace across MCMC iterations convergence assessment. well-mixed chain shows stable oscillation around stationary level. Requires ggplot2.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_trace.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Log-Likelihood MCMC Trace — dpmirt_plot_trace","text":"","code":"dpmirt_plot_trace(fit, ...)"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_trace.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Log-Likelihood MCMC Trace — dpmirt_plot_trace","text":"fit dpmirt_fit object dpmirt. ... Currently unused.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_trace.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Log-Likelihood MCMC Trace — dpmirt_plot_trace","text":"ggplot object.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_trace.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Log-Likelihood MCMC Trace — dpmirt_plot_trace","text":"","code":"if (FALSE) { # \\dontrun{ sim <- dpmirt_simulate(200, 20, model = \"rasch\", seed = 42) fit <- dpmirt(sim$response, model = \"rasch\", prior = \"normal\",               niter = 5000, nburnin = 1000, seed = 123) dpmirt_plot_trace(fit) } # }"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_wright_map.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Person-Item Map (Wright Map) — dpmirt_plot_wright_map","title":"Plot Person-Item Map (Wright Map) — dpmirt_plot_wright_map","text":"Displays Wright map showing joint distribution person abilities item difficulties common logit scale. Useful identifying gaps item coverage. Requires ggplot2.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_wright_map.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Person-Item Map (Wright Map) — dpmirt_plot_wright_map","text":"","code":"dpmirt_plot_wright_map(fit, bins = 30, item_labels = NULL, ...)"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_wright_map.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Person-Item Map (Wright Map) — dpmirt_plot_wright_map","text":"fit dpmirt_fit object dpmirt. bins Integer. Number histogram bins. Default: 30. item_labels Optional character vector item labels. ... Currently unused.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_wright_map.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Person-Item Map (Wright Map) — dpmirt_plot_wright_map","text":"ggplot object.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_plot_wright_map.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Person-Item Map (Wright Map) — dpmirt_plot_wright_map","text":"","code":"if (FALSE) { # \\dontrun{ sim <- dpmirt_simulate(200, 20, model = \"rasch\", seed = 42) fit <- dpmirt(sim$response, model = \"rasch\", prior = \"normal\",               niter = 5000, nburnin = 1000, seed = 123) dpmirt_plot_wright_map(fit) } # }"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_rescale.html","id":null,"dir":"Reference","previous_headings":"","what":"Rescale posterior samples for identification — dpmirt_rescale","title":"Rescale posterior samples for identification — dpmirt_rescale","text":"Applies post-hoc rescaling MCMC posterior samples resolve identification indeterminacy. unconstrained models, centers item difficulties (2PL/3PL) normalizes discriminations.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_rescale.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rescale posterior samples for identification — dpmirt_rescale","text":"","code":"dpmirt_rescale(samples_obj, rescale = TRUE)"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_rescale.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rescale posterior samples for identification — dpmirt_rescale","text":"samples_obj dpmirt_samples object. rescale Logical. TRUE (default), apply rescaling. FALSE, return samples -.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_rescale.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rescale posterior samples for identification — dpmirt_rescale","text":"dpmirt_fit S3 object containing rescaled posterior samples, diagnostics (ESS, WAIC, cluster info), model configuration.  object can passed directly dpmirt_estimates, dpmirt_resume, downstream functions.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_rescale.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Rescale posterior samples for identification — dpmirt_rescale","text":"Post-hoc rescaling resolves identification indeterminacy inherent unconstrained IRT models: Rasch (location ): MCMC iteration \\(s\\): $$\\beta^*_i = \\beta_i - \\bar{\\beta}$$ $$\\theta^*_j = \\theta_j - \\bar{\\beta}$$ 2PL/3PL IRT parameterization (location + scale): Let \\(c_s = \\bar{\\beta}_s\\) \\(d_s = (\\prod_i \\lambda_i)^{-1/}\\): $$\\beta^*_i = (\\beta_i - c_s) / d_s$$ $$\\lambda^*_i = \\lambda_i \\cdot d_s$$ $$\\theta^*_j = (\\theta_j - c_s) / d_s$$ rescaling: \\(\\bar{\\beta}^* = 0\\) \\((\\prod_i \\lambda^*_i)^{1/} = 1\\).","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_rescale.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Rescale posterior samples for identification — dpmirt_rescale","text":"Paganin, S., Paciorek, C. J., Wehrhahn, C., Rodriguez, ., Rabe-Hesketh, S., & de Valpine, P. (2023). Computational strategies estimation performance Bayesian semiparametric item response theory models. Journal Educational Behavioral Statistics, 48(2), 147–188.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_rescale.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rescale posterior samples for identification — dpmirt_rescale","text":"","code":"if (FALSE) { # \\dontrun{ sim <- dpmirt_simulate(200, 20, model = \"rasch\", seed = 42) spec <- dpmirt_spec(sim$response, model = \"rasch\", prior = \"normal\",                     identification = \"unconstrained\") compiled <- dpmirt_compile(spec) samples <- dpmirt_sample(compiled, niter = 5000, nburnin = 1000)  # Apply rescaling rescaled <- dpmirt_rescale(samples) } # }"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_resume.html","id":null,"dir":"Reference","previous_headings":"","what":"Resume MCMC sampling from a previous run — dpmirt_resume","title":"Resume MCMC sampling from a previous run — dpmirt_resume","text":"Continues MCMC sampling without recompilation, using NIMBLE Cmcmc$run(niter, reset = FALSE) pattern.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_resume.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Resume MCMC sampling from a previous run — dpmirt_resume","text":"","code":"dpmirt_resume(fit_or_compiled, niter_more, reset = FALSE, verbose = TRUE, ...)"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_resume.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Resume MCMC sampling from a previous run — dpmirt_resume","text":"fit_or_compiled dpmirt_samples, dpmirt_fit, dpmirt_compiled object. niter_more Integer. Number additional iterations. reset Logical. FALSE continue current state (default), TRUE restart. verbose Logical. Print progress messages. ... Additional arguments.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_resume.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Resume MCMC sampling from a previous run — dpmirt_resume","text":"dpmirt_samples object extended samples.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_resume.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Resume MCMC sampling from a previous run — dpmirt_resume","text":"","code":"if (FALSE) { # \\dontrun{ # Continue from a previous fit for more iterations fit <- dpmirt(sim$response, model = \"rasch\", prior = \"normal\",               niter = 5000, nburnin = 1000) fit2 <- dpmirt_resume(fit, niter_more = 5000) summary(fit2) } # }"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_sample.html","id":null,"dir":"Reference","previous_headings":"","what":"Run MCMC sampling on a compiled DPMirt model — dpmirt_sample","title":"Run MCMC sampling on a compiled DPMirt model — dpmirt_sample","text":"Executes MCMC sampling using compiled model. lightweight step can called repeatedly compiled model (compile-, sample-many pattern).","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_sample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run MCMC sampling on a compiled DPMirt model — dpmirt_sample","text":"","code":"dpmirt_sample(   compiled,   niter = 10000L,   nburnin = 2000L,   thin = 1L,   thin2 = NULL,   seed = NULL,   reset = TRUE,   verbose = TRUE,   ... )  # S3 method for class 'dpmirt_samples' print(x, ...)"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_sample.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run MCMC sampling on a compiled DPMirt model — dpmirt_sample","text":"compiled dpmirt_compiled object dpmirt_compile. niter Integer. Total number MCMC iterations. nburnin Integer. Number burn-iterations discard. thin Integer. Thinning interval main monitors. thin2 Integer NULL. Thinning interval monitors2 (eta/theta). NULL, uses value thin. seed Integer NULL. Random seed reproducibility. reset Logical. TRUE (default), reset MCMC state sampling. Set FALSE chain continuation. verbose Logical. Print progress messages. ... Additional arguments (currently unused). x dpmirt_samples object.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_sample.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run MCMC sampling on a compiled DPMirt model — dpmirt_sample","text":"dpmirt_samples S3 object containing: samples Matrix posterior samples main monitors. samples2 Matrix posterior samples thinned monitors (eta). waic WAIC value computed, otherwise NULL. sampling_time Time taken sampling. mcmc_control List MCMC settings used. model_config Reference model configuration. compiled Reference compiled object (resume).","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_sample.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run MCMC sampling on a compiled DPMirt model — dpmirt_sample","text":"","code":"if (FALSE) { # \\dontrun{ sim <- dpmirt_simulate(200, 20, model = \"rasch\", seed = 42) spec <- dpmirt_spec(sim$response, model = \"rasch\", prior = \"normal\") compiled <- dpmirt_compile(spec)  # Run MCMC sampling samples <- dpmirt_sample(compiled, niter = 5000, nburnin = 1000, seed = 123) print(samples) } # }"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_simulate.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate IRT response data — dpmirt_simulate","title":"Simulate IRT response data — dpmirt_simulate","text":"Generates binary response data known IRT parameters. IRTsimrel available, uses EQC (Empirical Quadrature Calibration) achieve target marginal reliability. Otherwise falls back Paganin-style simulation without reliability targeting.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_simulate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate IRT response data — dpmirt_simulate","text":"","code":"dpmirt_simulate(   n_persons,   n_items,   model = c(\"rasch\", \"2pl\", \"3pl\"),   target_rho = 0.8,   latent_shape = \"normal\",   item_source = \"irw\",   reliability_metric = c(\"msem\", \"info\"),   latent_params = list(),   item_params = list(),   M = 10000L,   seed = NULL,   use_irtsimrel = TRUE,   verbose = FALSE,   ... )  # S3 method for class 'dpmirt_sim' print(x, ...)"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_simulate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate IRT response data — dpmirt_simulate","text":"n_persons Integer. Number persons. n_items Integer. Number items. model Character. IRT model type: \"rasch\" \"2pl\". target_rho Numeric (0, 1). Target marginal reliability. used IRTsimrel available. Default 0.8. latent_shape Character. Shape latent ability distribution. using IRTsimrel, supports 12 shapes: \"normal\", \"bimodal\", \"trimodal\", \"multimodal\", \"skew_pos\", \"skew_neg\", \"heavy_tail\", \"light_tail\", \"uniform\", \"floor\", \"ceiling\", \"custom\". Fallback supports: \"normal\", \"bimodal\", \"skewed\". item_source Character. Source item parameters IRTsimrel. One \"irw\" (default), \"parametric\", \"hierarchical\", \"custom\". reliability_metric Character. Reliability metric EQC calibration. \"msem\" (default) \"info\". latent_params List. Additional parameters passed IRTsimrel::sim_latentG() (e.g., list(shape_params = list(delta = 0.8))). item_params List. Additional parameters passed IRTsimrel::sim_item_params() (e.g., list(discrimination_params = list(rho = -0.3))). M Integer. Quadrature sample size EQC. Default 10000. seed Integer NULL. Random seed reproducibility. use_irtsimrel Logical. TRUE (default), attempt use IRTsimrel reliability-targeted simulation. Falls back internal simulation IRTsimrel installed. verbose Logical. Print progress messages. Default FALSE. ... Additional arguments (currently unused). x dpmirt_sim object.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_simulate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate IRT response data — dpmirt_simulate","text":"dpmirt_sim S3 object containing: response N x binary response matrix theta True person abilities (length N) beta True item difficulties (length ) lambda True discriminations (length 2PL, NULL Rasch) n_persons, n_items, model Simulation settings reliability Achieved marginal reliability target_rho Requested target reliability (NULL fallback) latent_shape Distribution shape used eqc_result EQC calibration result (NULL fallback) method Character: \"irtsimrel\" \"fallback\"","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_simulate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate IRT response data — dpmirt_simulate","text":"","code":"if (FALSE) { # \\dontrun{ # Simple fallback simulation sim <- dpmirt_simulate(200, 25, model = \"rasch\", seed = 42)  # With IRTsimrel (reliability-targeted) sim <- dpmirt_simulate(200, 25, model = \"rasch\",                        target_rho = 0.85,                        latent_shape = \"bimodal\",                        seed = 42)  # Full simulation study workflow sim <- dpmirt_simulate(200, 25, model = \"rasch\",                        target_rho = 0.8,                        latent_shape = \"bimodal\") fit <- dpmirt(sim$response, model = \"rasch\", prior = \"dpm\") est <- dpmirt_estimates(fit) dpmirt_loss(est, true_theta = sim$theta, true_beta = sim$beta) } # }"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_spec.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a DPMirt model specification — dpmirt_spec","title":"Create a DPMirt model specification — dpmirt_spec","text":"Constructs complete specification Bayesian IRT model, including NIMBLE model code, constants, data, initial values, monitor configuration. first step step--step workflow.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_spec.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a DPMirt model specification — dpmirt_spec","text":"","code":"dpmirt_spec(   data,   model = c(\"rasch\", \"2pl\", \"3pl\"),   prior = c(\"normal\", \"dpm\"),   parameterization = c(\"irt\", \"si\"),   identification = NULL,   alpha_prior = NULL,   base_measure = list(s2_mu = 2, nu1 = 2.01, nu2 = 1.01),   item_priors = list(),   M = 50L,   data_format = c(\"auto\", \"matrix\", \"long\"),   ... )  # S3 method for class 'dpmirt_spec' print(x, ...)"},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_spec.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a DPMirt model specification — dpmirt_spec","text":"data matrix data.frame binary (0/1) responses persons rows items columns. Can also long-format data.frame columns person, item, response. model Character. IRT model type: \"rasch\", \"2pl\", \"3pl\". prior Character. Latent trait prior: \"normal\" (parametric) \"dpm\" (Dirichlet Process Mixture). parameterization Character. \"irt\" standard IRT \"si\" slope-intercept. relevant 2PL/3PL. identification Character NULL. Identification strategy: \"constrained_item\", \"constrained_ability\", \"unconstrained\". NULL, uses model-specific default (constrained_item Rasch, unconstrained 2PL/3PL). alpha_prior Alpha hyperprior specification. NULL default (auto-elicit Gamma(1,3)), numeric vector c(, b) Gamma(, b), DPprior_fit object. used prior = \"dpm\". base_measure List DPM base measure hyperparameters: s2_mu, nu1, nu2. Defaults Paganin et al. (2023). item_priors List custom item priors (advanced use). M Integer. Maximum number clusters CRP truncation. used prior = \"dpm\". data_format Character. \"auto\", \"matrix\", \"long\". ... Additional arguments (currently unused). x dpmirt_spec object.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_spec.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a DPMirt model specification — dpmirt_spec","text":"dpmirt_spec S3 object containing: code nimbleCode object. constants List constants (N, , M, etc.). data List response data. inits List initial values. monitors Character vector parameters track. monitors2 Character vector parameters thinned monitoring. config List model configuration options.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/reference/dpmirt_spec.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a DPMirt model specification — dpmirt_spec","text":"","code":"if (FALSE) { # \\dontrun{ sim <- dpmirt_simulate(200, 20, model = \"rasch\", seed = 42)  # Rasch-Normal specification spec <- dpmirt_spec(sim$response, model = \"rasch\", prior = \"normal\") print(spec)  # Rasch-DPM with custom alpha prior spec_dpm <- dpmirt_spec(sim$response, model = \"rasch\", prior = \"dpm\",                         alpha_prior = c(1, 3))  # 2PL specification sim2 <- dpmirt_simulate(300, 25, model = \"2pl\", seed = 42) spec_2pl <- dpmirt_spec(sim2$response, model = \"2pl\", prior = \"normal\",                         parameterization = \"irt\") } # }"},{"path":"https://joonho112.github.io/DPMirt/reference/plot.dpmirt_estimates.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot dpmirt_estimates object — plot.dpmirt_estimates","title":"Plot dpmirt_estimates object — plot.dpmirt_estimates","text":"Plot dpmirt_estimates object","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/plot.dpmirt_estimates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot dpmirt_estimates object — plot.dpmirt_estimates","text":"","code":"# S3 method for class 'dpmirt_estimates' plot(x, type = c(\"estimates\", \"shrinkage\"), param = c(\"theta\", \"beta\"), ...)"},{"path":"https://joonho112.github.io/DPMirt/reference/plot.dpmirt_estimates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot dpmirt_estimates object — plot.dpmirt_estimates","text":"x dpmirt_estimates object. type Character. Plot type: \"estimates\" (caterpillar PM/CB/GR) \"shrinkage\" (PM vs CB scatter). param Character. parameter: \"theta\" \"beta\". ... Additional graphical parameters.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/reference/plot.dpmirt_estimates.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot dpmirt_estimates object — plot.dpmirt_estimates","text":"","code":"if (FALSE) { # \\dontrun{ sim <- dpmirt_simulate(200, 20, model = \"rasch\", seed = 42) fit <- dpmirt(sim$response, model = \"rasch\", prior = \"normal\",               niter = 5000, nburnin = 1000, seed = 123) est <- dpmirt_estimates(fit)  # PM/CB/GR caterpillar plot plot(est, type = \"estimates\")  # Shrinkage plot (PM vs CB) plot(est, type = \"shrinkage\") } # }"},{"path":"https://joonho112.github.io/DPMirt/reference/plot.dpmirt_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a DPMirt fit object — plot.dpmirt_fit","title":"Plot a DPMirt fit object — plot.dpmirt_fit","text":"Produces visualizations fitted IRT models. Supports 12 plot types automatic selection base R ggplot2 backends.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/plot.dpmirt_fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a DPMirt fit object — plot.dpmirt_fit","text":"","code":"# S3 method for class 'dpmirt_fit' plot(   x,   type = c(\"density\", \"items\", \"trace\", \"clusters\", \"dp_density\", \"icc\", \"wright_map\",     \"parameter_trace\", \"caterpillar\", \"density_compare\", \"info\", \"pp_check\"),   engine = c(\"auto\", \"base\", \"ggplot2\"),   ... )"},{"path":"https://joonho112.github.io/DPMirt/reference/plot.dpmirt_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a DPMirt fit object — plot.dpmirt_fit","text":"x dpmirt_fit object. type Character. Plot type. One : \"density\" Kernel density posterior mean theta. \"items\" Item difficulty estimates error bars. \"trace\" Log-likelihood MCMC trace. \"clusters\" Cluster count trace histogram (DPM ). \"dp_density\" DP mixture density credible band (DPM ). \"icc\" Item Characteristic Curves. \"wright_map\" Person-Item map (Wright map). \"parameter_trace\" Individual parameter MCMC traces. \"caterpillar\" Sorted estimates credible intervals. \"density_compare\" Posterior density vs reference overlay. \"info\" Test Information Function. \"pp_check\" Posterior predictive check. engine Character. Plotting backend: \"auto\" (default) uses ggplot2 available, \"base\" forces base R, \"ggplot2\" requires ggplot2. ... Additional arguments passed specific plotting function.","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/plot.dpmirt_fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a DPMirt fit object — plot.dpmirt_fit","text":"Invisibly returns plot object (ggplot) NULL (base R).","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/reference/plot.dpmirt_fit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot a DPMirt fit object — plot.dpmirt_fit","text":"","code":"if (FALSE) { # \\dontrun{ sim <- dpmirt_simulate(200, 20, model = \"rasch\", seed = 42) fit <- dpmirt(sim$response, model = \"rasch\", prior = \"normal\",               niter = 5000, nburnin = 1000, seed = 123)  # Theta density plot(fit, type = \"density\")  # Item difficulty estimates plot(fit, type = \"items\")  # MCMC trace plot(fit, type = \"trace\")  # Force base R backend plot(fit, type = \"density\", engine = \"base\") } # }"},{"path":"https://joonho112.github.io/DPMirt/reference/plot.dpmirt_sim.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot dpmirt_sim object — plot.dpmirt_sim","title":"Plot dpmirt_sim object — plot.dpmirt_sim","text":"Plot dpmirt_sim object","code":""},{"path":"https://joonho112.github.io/DPMirt/reference/plot.dpmirt_sim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot dpmirt_sim object — plot.dpmirt_sim","text":"","code":"# S3 method for class 'dpmirt_sim' plot(x, type = c(\"parameters\", \"response\"), ...)"},{"path":"https://joonho112.github.io/DPMirt/reference/plot.dpmirt_sim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot dpmirt_sim object — plot.dpmirt_sim","text":"x dpmirt_sim object. type Character. Plot type: \"parameters\" (histograms true parameters) \"response\" (heatmap response matrix). ... Additional graphical parameters.","code":""},{"path":[]},{"path":"https://joonho112.github.io/DPMirt/reference/plot.dpmirt_sim.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot dpmirt_sim object — plot.dpmirt_sim","text":"","code":"if (FALSE) { # \\dontrun{ sim <- dpmirt_simulate(200, 20, model = \"rasch\", seed = 42)  # True parameter histograms plot(sim, type = \"parameters\")  # Response matrix heatmap plot(sim, type = \"response\") } # }"},{"path":"https://joonho112.github.io/DPMirt/news/index.html","id":"dpmirt-010","dir":"Changelog","previous_headings":"","what":"DPMirt 0.1.0","title":"DPMirt 0.1.0","text":"Initial release","code":""},{"path":"https://joonho112.github.io/DPMirt/news/index.html","id":"models-0-1-0","dir":"Changelog","previous_headings":"","what":"Models","title":"DPMirt 0.1.0","text":"Rasch, 2PL, 3PL item response theory models. Parametric (Normal) semiparametric (Dirichlet Process Mixture) latent trait priors. IRT slope-intercept (SI) parameterizations 2PL 3PL. Three identification strategies: constrained_item (Rasch default), constrained_ability, unconstrained post-hoc rescaling (2PL/3PL default).","code":""},{"path":"https://joonho112.github.io/DPMirt/news/index.html","id":"workflow-0-1-0","dir":"Changelog","previous_headings":"","what":"Workflow","title":"DPMirt 0.1.0","text":"dpmirt() — --one model fitting (spec → compile → sample → rescale). Modular pipeline: dpmirt_spec() → dpmirt_compile() → dpmirt_sample() → dpmirt_rescale(). dpmirt_resume() — continue sampling compiled model without recompilation.","code":""},{"path":"https://joonho112.github.io/DPMirt/news/index.html","id":"posterior-summaries-0-1-0","dir":"Changelog","previous_headings":"","what":"Posterior Summaries","title":"DPMirt 0.1.0","text":"PM (Posterior Mean) — optimal individual-level MSE. CB (Constrained Bayes; Ghosh, 1992) — moment-matched posterior predictive distribution. GR (Triple-Goal; Shen & Louis, 1998) — simultaneous estimation, ranking, distributional recovery. dpmirt_draws() — extract posterior samples matrix long format. dpmirt_loss() — evaluate MSEL, MSELR, KS, custom loss metrics.","code":""},{"path":"https://joonho112.github.io/DPMirt/news/index.html","id":"diagnostics-0-1-0","dir":"Changelog","previous_headings":"","what":"Diagnostics","title":"DPMirt 0.1.0","text":"dpmirt_diagnostics() — ESS, R-hat, trace summaries, WAIC. dpmirt_compare() — WAIC-based model comparison across fits. dpmirt_dp_density() — posterior density estimation DP mixture.","code":""},{"path":"https://joonho112.github.io/DPMirt/news/index.html","id":"simulation-0-1-0","dir":"Changelog","previous_headings":"","what":"Simulation","title":"DPMirt 0.1.0","text":"dpmirt_simulate() — generate IRT data 12 latent distribution shapes (normal, bimodal, skewed, heavy-tailed, etc.). IRTsimrel integration reliability-targeted simulation via EQC calibration.","code":""},{"path":"https://joonho112.github.io/DPMirt/news/index.html","id":"prior-elicitation-0-1-0","dir":"Changelog","previous_headings":"","what":"Prior Elicitation","title":"DPMirt 0.1.0","text":"dpmirt_alpha_prior() — principled concentration-parameter selection via DPprior, graceful fallback Gamma(1, 3).","code":""},{"path":"https://joonho112.github.io/DPMirt/news/index.html","id":"visualization-0-1-0","dir":"Changelog","previous_headings":"","what":"Visualization","title":"DPMirt 0.1.0","text":"S3 plot() methods dpmirt_fit, dpmirt_estimates, dpmirt_sim objects. 12 standalone ggplot2 functions: dpmirt_plot_trace(), dpmirt_plot_density(), dpmirt_plot_caterpillar(), dpmirt_plot_items(), dpmirt_plot_icc(), dpmirt_plot_info(), dpmirt_plot_dp_density(), dpmirt_plot_clusters(), dpmirt_plot_wright_map(), dpmirt_plot_parameter_trace(), dpmirt_plot_density_compare(), dpmirt_plot_pp_check().","code":""},{"path":"https://joonho112.github.io/DPMirt/news/index.html","id":"documentation-0-1-0","dir":"Changelog","previous_headings":"","what":"Documentation","title":"DPMirt 0.1.0","text":"Eight vignettes covering quick start, models workflow, posterior summaries, prior elicitation, simulation studies, mathematical foundations, NIMBLE internals. 31 manual pages full roxygen2 documentation.","code":""}]
